[{"title":"Golang-Improve","url":"/posts/57803/","content":">Golang的进阶提升\n<!--more-->\n# 包\n## 包的基本使用\n>使用要点\n>* 一个目录下的统计文件归属一个包，package的声明要一致\n>* package声明的包和对应的目录名可以不一致，但习惯上还是要写成一致的\n>* 包可以嵌套\n>* 同包下的函数不需要导入包，可以直接使用\n>* main()所在的包，其他包不能使用\n>* 导入包的时候，路径要从src下开始写\n```go\nimport (\n\t// 给包起别名\n\te \"awesomeProject/entities\"\n\t\"awesomeProject/utils\"\n\t\"fmt\"\n)\n\nfunc main() {\n\tutils.PrintNow()\n\tstu := e.Student{Name: \"文特\", Age: 22, Grade: \"2024\"}\n\tfmt.Println(stu)\n}\n```\n>注意首字母\n```go\n// Student 首字母大写表示外部包可以访问\ntype Student struct {\n\tName  string\n\tAge   int\n\tGrade string\n}\n```\n## init包初始化\n>init函数的执行顺序如下：\n>* 在同一个Go文件中，init函数的执行顺序是从上到下的\n>* 在同一个包，不同的Go文件中，是会将文件名按字符串从小到大排序之后，按从小到大的顺序调用各文件的init函数\n>* 在不同的包，如果不相互依赖的话，按照main包中import的顺序调用其中的init函数\n>* 如果package存在依赖，那最后被依赖的，最先被执行，例如（->表示导入）：main -> pk1 -> pk2 ->pk3，则pk3的init先执行\n>* 存在依赖的包，不能循环导入，比如说 pk1->pk2->pk3,但是pk3->pk1，这样就不行\n>* 一个包可以被导入多次，但是只能被初始化一次\n```go\nimport \"fmt\"\n\nfunc main() {\n\tfmt.Println(\"主函数执行\")\n}\nfunc init() {\n\tfmt.Println(\"第一个init函数\")\n}\nfunc init() {\n\tfmt.Println(\"第二个init函数\")\n}\n// 输出如下：\n第一个init函数\n第二个init函数\n主函数执行\n```\n>init 函数与main函数的区别与联系\n- 都是go语言中的保留函数，init用于初始化信息，main作为程序的入口\n- 都不能有参数和返回值，也不能被引用\n- init函数可以有多个且可以定义在任意的包中，main函数只能在main包下，并且只能有一个\n- 执行顺序：先执行init函数，后执行main函数\n\n>只执行该包下的init操作，并不调用函数\n```go\nimport _ \"awesomeProject/init\"\n\nfunc main() {\n\tfmt.Println(\"主函数执行\")\n}\n```\n\n## 获取远程包\n>获取mysql的包，在go.mod文件所在的目录下执行\n```cmd\ngo get github.com/go-sql-driver/mysql\n```\n>测试mysql包\n```go\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\nfunc Connect() {\n\tdb, err := sql.Open(\"mysql\", \"root:root@tcp(127.0.0.1:3306)/wedo?charset=utf-8\")\n\tif err != nil {\n\t\tfmt.Println(\"连接错误！\")\n\t\treturn\n\t}\n\tfmt.Println(\"链接成功，db信息为：\", db)\n}\n```\n## time包\n> 获取指定的时间\n```go\nfunc main() {\n\tt1 := time.Date(2008, 7, 15, 16, 30, 28, 0, time.Local)\n\tfmt.Println(t1)\n}\n```\n>Time与字符串类型的互换\n```go\nfunc main() {\n\t// Time转字符串：Format\n\tt1 := time.Now()\n\ts1 := t1.Format(\"2006年1月2日 15:04:05\")\n\ts2 := t1.Format(\"2006/1/2\")\n\tfmt.Println(s1)\n\tfmt.Println(s2)\n\t// 字符串转Time：Parse\n\tstr1 := \"2001年12月5日\"\n\tt2, err := time.Parse(\"2006年1月2日\", str1)\n\tif err != nil {\n\t\tfmt.Println(\"err：\", err)\n\t}\n\tfmt.Println(\"时间为：\", t2)\n}\n```\n>根据Time的时间，获取指定的部分时间内容\n```go\nfunc main() {\n\tt1 := time.Now()\n\tyear, month, day := t1.Date()\n\tfmt.Println(\"当前年：\", year)\n\tfmt.Println(\"当前月：\", month)\n\tfmt.Println(\"当前日：\", day)\n\t// 指定部分获取\n\tyear2 := t1.Year()\n\tmonth2 := t1.Month()\n\tday2 := t1.Day()\n\thour := t1.Hour()\n\tminute := t1.Minute()\n\tsecond := t1.Second()\n\tweekday := t1.Weekday()\n\tfmt.Println(year2)\n\tfmt.Println(month2)\n\tfmt.Println(day2)\n\tfmt.Println(hour)\n\tfmt.Println(minute)\n\tfmt.Println(second)\n\tfmt.Println(weekday)\n}\n```\n>获取以毫秒为单位的时间戳\n```go\nfunc main() {\n\tt1 := time.Now()\n\tmilliSecond := t1.UnixMilli()\n\tfmt.Println(milliSecond)\n}\n```\n>将指定的Time加上一定的时间\n```go\nfunc main() {\n\tt1 := time.Now()\n\tt2 := t1.Add(time.Minute)\n\tt3 := t1.AddDate(1, 0, 0)\n\tfmt.Println(\"ti:\", t1)\n\tfmt.Println(\"t2:\", t2)\n\tfmt.Println(\"t3:\", t3)\n}\n```\n>睡眠函数\n```go\nfunc main() {\n\tfmt.Println(\"开始进入睡眠\")\n\trandNum := rand.Intn(10)\n\ttime.Sleep(time.Second * time.Duration(randNum))\n\tfmt.Println(\"睡眠结束，共睡了：\", randNum, \"秒\")\n}\n```\n>计算时间的差值\n```go\nfunc main() {\n\tt1 := time.Now()\n\tt2 := t1.Add(time.Hour)\n\t// t1 - t2的差值\n\tsubTime := t1.Sub(t2)\n\tfmt.Println(subTime)\n\t// 获取差值的小时部分\n\th := subTime.Hours()\n\tfmt.Println(h)\n}\n```\n## file包\n>打开文件\n```go\nfunc main() {\n\tfile, err := os.Stat(\"D:\\\\AAA\\\\txt\\\\door_msg.txt\")\n\tif err != nil {\n\t\tfmt.Println(\"出现错误，err为：\", err)\n\t\treturn\n\t}\n\tfmt.Println(\"打开成功，file名为：\", file.Name())\n\tfmt.Println(\"文件大小为：\", file.Size())\n\tfmt.Println(\"是否是目录：\", file.IsDir())\n\tfmt.Println(\"修改时间为：\", file.ModTime())\n\tfmt.Println(\"文件权限问：\", file.Mode())\n}\n```\n>文件的权限\n>举例：-rw-rw-rw，表示owner，group，others分别拥有读写权限，但是都没有x的可执行权限\n>* r -> 004\n>* w -> 002\n>* x -> 001\n>* '-' -> 000\n\n>文件操作：判断是否是绝对路径并获取其父目录\n```go\nfunc main() {\n\tfileName := \"D:\\\\AAA\\\\txt\\\\dete_org.txt\"\n\tfmt.Println(filepath.IsAbs(fileName))\n\t// 获取父目录\n\tparantDir := filepath.Join(fileName, \"..\")\n\tfmt.Println(parantDir)\n}\n```\n>文件操作：创建目录\n```go\nfunc main() {\n\tfileDir := \"D:\\\\AAA\\\\txt\\\\test\"\n\t// 如果fileDir中需要创建多级目录，或者目录中有一些目录不存在，则需要用到makeDirAll\n\terr := os.Mkdir(fileDir, os.ModePerm)\n\tif err != nil {\n\t\tfmt.Println(\"文件夹创建失败\")\n\t\treturn\n\t}\n\tfmt.Println(\"文件夹创建成功\")\n\n}\n```\n>文件操作：创建一个文件\n```go\nfunc main() {\n\tfileDir := \"D:\\\\AAA\\\\txt\\\\test\\\\text.txt\"\n\tfile, err := os.Create(fileDir)\n\tif err != nil {\n\t\tfmt.Println(\"文件创建失败，err:\", err)\n\t}\n\tfmt.Println(\"文件创建成功，文件名问：\", file.Name())\n}\n```\n>文件操作：打开一个文件，处理完逻辑之后并关闭链接\n```go\nfunc main() {\n\tfileDir := \"D:\\\\AAA\\\\txt\\\\test\\\\text.txt\"\n\tfile1, err := os.Open(fileDir)\n\tif err != nil {\n\t\tfmt.Println(\"打开只读文件失败！\")\n\t}\n\tfmt.Println(\"打开只读文件成功，文件名是：\", file1.Name())\n\t// 第二个参数表示打开文件的权限，第三参数表示如果没有这个文件，则创建这个文件的赋予其的权限是什么\n\tfile2, err := os.OpenFile(fileDir, os.O_WRONLY|os.O_RDONLY, os.ModePerm)\n\tif err != nil {\n\t\tfmt.Println(\"打开读写文件失败！\")\n\t}\n\tfmt.Println(\"打开读写文件成功，文件名是：\", file2.Name())\n\tfile2.Close()\n}\n```\n>文件操作：删除文件或空目录\n```go\nfunc main() {\n\tfileDir := \"D:\\\\AAA\\\\txt\\\\test\\\\text.txt\"\n\t//删除文件\n\terr := os.Remove(fileDir)\n\tif err != nil {\n\t\tfmt.Println(\"删除文件失败！\")\n\t}\n\t// 删除空目录\n\tdir := filepath.Join(fileDir, \"..\")\n\terr2 := os.Remove(dir)\n\tif err2 != nil {\n\t\tfmt.Println(\"删除文件夹失败！\")\n\t}\n\tfmt.Println(\"删除均成功！\")\n}\n```\n>文件操作：删除目录及其下面的所有文件\n```go\nfunc main() {\n\tfileDir := \"D:\\\\AAA\\\\txt\\\\test\"\n\terr := os.RemoveAll(fileDir)\n\tif err != nil {\n\t\tfmt.Println(\"删除目录及所有文件失败！\")\n\t}\n\tfmt.Println(\"删除目录及所有文件成功！\")\n}\n```\n>os.ReadDir递归遍历文件夹\n```go\nfunc main() {\n\tdirPath := \"D:\\\\AAA\\\\txt\"\n\tdiguiVisit(dirPath, 0)\n\n}\nfunc diguiVisit(dirPath string, level int) {\n\tfilesInfos, _ := os.ReadDir(dirPath)\n\t//打印目录前缀\n\tprefix := \"\"\n\tfor i := 0; i < level; i++ {\n\t\tprefix = \"| \" + prefix\n\t}\n\tfor _, file := range filesInfos {\n\t\tif file.IsDir() {\n\t\t\tfmt.Println(prefix+\"|-\", file.Name())\n\t\t\tnextDir := dirPath + \"\\\\\" + file.Name()\n\t\t\tdiguiVisit(nextDir, level+1)\n\t\t\tcontinue\n\t\t}\n\t\tfmt.Println(prefix+\"|-\", file.Name())\n\t}\n}\n```\n\n## IO包\n>读取操作\n```go\nfunc main() {\n\tfilePath := \"D:\\\\AAA\\\\txt\\\\a.txt\"\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\tfmt.Println(\"打开文件失败！\")\n\t\treturn\n\t}\n\tdefer file.Close()\n\tsliceTemp := make([]byte, 512, 512)\n\tfor {\n\t\tn, err := file.Read(sliceTemp)\n\t\tif err != nil && err == io.EOF {\n\t\t\tfmt.Println(\"读取到底了\")\n\t\t\tbreak\n\t\t}\n\t\tfmt.Println(\"本次读取到了\", n, \"个字节\")\n\t\tfmt.Printf(\"本次读取到的数据是：\\n%s\", string(sliceTemp[:n]))\n\t}\n}\n```\n>写入操作\n```go\nfunc main() {\n\tfilePath := \"D:\\\\AAA\\\\txt\\\\w.txt\"\n\tfile, err := os.OpenFile(filePath, os.O_WRONLY|os.O_CREATE|os.O_APPEND, os.ModePerm)\n\tif err != nil {\n\t\tfmt.Println(\"错误已发生！\", err)\n\t}\n\tfmt.Println(file.Name())\n\tstr := \"文特\"\n\tn, err2 := file.Write([]byte(str))\n\tn, err3 := file.WriteString(str)\n\tfmt.Println(\"写了\", n, \"个字节\")\n\tif err2 != nil && err3 != nil {\n\t\tfmt.Println(\"写入失败！\")\n\t}\n\tfmt.Println(\"写入成功！\")\n}\n```\n>复制操作\n```go\nfunc main() {\n\tcopyFile(\"D:\\\\AAA\\\\txt\\\\w.txt\", \"D:\\\\AAA\\\\txt\\\\wc.txt\")\n}\nfunc copyFile(sourceFile string, targetFile string) {\n\tfr, err := os.Open(sourceFile)\n\tif err != nil {\n\t\tfmt.Println(\"打开文件失败！\")\n\t\treturn\n\t}\n\tdefer fr.Close()\n\n\tfw, err := os.OpenFile(targetFile, os.O_WRONLY|os.O_APPEND|os.O_CREATE, os.ModePerm)\n\tif err != nil {\n\t\tfmt.Println(\"打开目标文件失败！\")\n\t\treturn\n\t}\n\tdefer fw.Close()\n\n\tn, err := io.Copy(fw, fr)\n\tif err != nil {\n\t\tfmt.Println(\"输出文件失败！\")\n\t\treturn\n\t}\n\tfmt.Println(\"共输出了\", n, \"个字节！\")\n}\n```\n>通过OpenFile打开的文件，同一次打开的话，如果是写完立刻读的话，无法在同一次链接中读取到，也就是说，当前链接对文件的修改对当前链接是不可见的\n```go\nfunc Test() {\n\ttempPath := \"D:\\\\AAA\\\\txt\\\\tempT.txt\"\n\tfile, err := os.OpenFile(tempPath, os.O_RDWR|os.O_CREATE, 0644)\n\tif err != nil {\n\t\tfmt.Println(\"Error opening file:\", err)\n\t\treturn\n\t}\n\tdefer file.Close() // Defer closing the file until the function returns\n\n\tbuffer := make([]byte, 100) // No need to specify capacity if it's the same as the length\n\n\tfor i := 0; i < 10; i++ {\n\t\tn, err := file.Read(buffer)\n\t\tif err != nil && err != io.EOF {\n\t\t\tfmt.Println(\"Error reading file:\", err)\n\t\t\treturn\n\t\t}\n\t\tfmt.Println(string(buffer[:n]))     // Print only the bytes read\n\t\t_, err = file.WriteString(\"test\\n\") // Write data to the end of the file\n\t\tif err != nil {\n\t\t\tfmt.Println(\"Error writing to file:\", err)\n\t\t\treturn\n\t\t}\n\t}\n}\n```\n>Seek的使用\n```go\n\tfunc main() {\n\tfileName := \"D:\\\\AAA\\\\txt\\\\w.txt\"\n\tfile, err := os.OpenFile(fileName, os.O_RDWR, os.ModePerm)\n\tif err != nil {\n\t\treturn\n\t}\n\tbyteArr := make([]byte, 1, 2)\n\t// 控制光标偏移量在首位后两位\n\tfile.Seek(2, io.SeekStart)\n\tfile.Read(byteArr)\n\tfmt.Println(\"读到的数据是：\", string(byteArr))\n\t// 控制光标偏移量在当前位置再往后移 offset+1 位\n\tfile.Seek(0, io.SeekCurrent)\n\tfile.Read(byteArr)\n\tfmt.Println(\"读到的数据是：\", string(byteArr))\n\t// 控制光标偏移量在末尾，并写入数据，模拟了Append的写入\n\tfile.Seek(0, io.SeekEnd)\n\tfile.WriteString(\"Test\")\n}\n```\n>断点续传：四个步骤\n>* 读临时文件的复制进度\n>* 通过进度，改变源文件的偏移量及其目标文件的偏移量，表示从哪开始复制，粘贴到目标文件的哪个位置\n>* 进行复制操作，先读源文件，然后写到目标文件\n>* 更新进度偏移量\n```go\nfunc main() {\n\tsrcPath := \"D:\\\\AAA\\\\txt\\\\cxy.jpg\"\n\ttempPath := \"D:\\\\AAA\\\\txt\\\\temp.txt\"\n\ttargetPath := \"D:\\\\AAA\\\\txt\\\\target.jpg\"\n\tsrcFile, err := os.Open(srcPath)\n\tHandleErr(err)\n\tdefer srcFile.Close()\n\n\ttempFile, err := os.OpenFile(tempPath, os.O_RDWR|os.O_CREATE, os.ModePerm)\n\tHandleErr(err)\n\tdefer tempFile.Close()\n\n\ttargetFile, err := os.OpenFile(targetPath, os.O_RDWR|os.O_CREATE, os.ModePerm)\n\tHandleErr(err)\n\tdefer targetFile.Close()\n\n\tbufferTemp := make([]byte, 100, 100)\n\t// 读当前的进度\n\tcurrentOffset := 0\n\tread, _ := tempFile.Read(bufferTemp)\n\tif read != 0 {\n\t\tcurrentOffset, err = strconv.Atoi(string(bufferTemp[:read]))\n\t\tHandleErr(err)\n\t}\n\t// 设置读写进度\n\tsrcFile.Seek(int64(currentOffset), io.SeekStart)\n\ttargetFile.Seek(int64(currentOffset), io.SeekStart)\n\tbuffer := make([]byte, 1024, 1024)\n\tfor {\n\t\treadN, err := srcFile.Read(buffer)\n\t\tif err == io.EOF || readN == 0 {\n\t\t\ttargetFile.Close()\n\t\t\tfmt.Println(\"复制完成\")\n\t\t\tbreak\n\t\t}\n\t\twriteN, err := targetFile.Write(buffer[:readN])\n\t\tHandleErr(err)\n\t\t// 更新当前进度\n\t\tcurrentOffset += writeN\n\t\tfmt.Println(\"当前复制进度为：\", currentOffset)\n\t\tif currentOffset > 9000 {\n\t\t\tpanic(\"Test\")\n\t\t}\n\t\ttempFile.Seek(0, io.SeekStart)\n\t\ttempFile.WriteString(strconv.Itoa(currentOffset))\n\t}\n}\nfunc HandleErr(err error) {\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n>bufio的读操作：p的大小最好小于缓冲区的大小，缓冲区才有意义\n```go\n\tfunc main() {\n\tfilePath := \"D:\\\\AAA\\\\txt\\\\a.txt\"\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn\n\t}\n\tbr := bufio.NewReader(file)\n\t// 1,Read()\n\tp := make([]byte, 512, 512)\n\t// 默认缓冲区大小是4kb\n\treadN, _ := br.Read(p)\n\tfmt.Println(\"读到的字节数是：\", readN)\n\tfmt.Println(string(p))\n\t// 2,ReadLine()\n\tline, flag, _ := br.ReadLine()\n\tfmt.Println(string(line))\n\tfmt.Println(flag)\n\t// 3,ReadString()\n\ts1, _ := br.ReadString('\\n')\n\tfmt.Println(s1)\n}\n```\n>bufio的写操作\n```go\nfunc main() {\n\tfilePath := \"D:\\\\AAA\\\\txt\\\\t.txt\"\n\tfile, err := os.OpenFile(filePath, os.O_CREATE|os.O_WRONLY, os.ModePerm)\n\tif err != nil {\n\t\treturn\n\t}\n\tdefer file.Close()\n\t// 写入流\n\tbw := bufio.NewWriter(file)\n\twsBytes, err := bw.WriteString(\"Test\")\n\tif err != nil {\n\t\treturn\n\t}\n\t// 把缓冲区的数据手动刷到文件中\n\tbw.Flush()\n\tfmt.Println(wsBytes)\n}\n```\n","categories":["Golang"],"tags":["Golang"]},{"title":"Golang-Grammar","url":"/posts/42803/","content":">关于Golang的语法学习\n<!--more-->\n# 类型区分\n## 值类型传递\n>概念：每次返回或拿到的都是一个新的值，修改新值不会影响到原值  \n>* int\n>* float\n>* string\n>* bool\n>* array\n>* struct\n## 引用类型传递\n>概念：每次返回或拿到的都是指向原对象的内存地址的引用  \n>* slice\n>* map\n>* chan\n\n# 变量与常量\n## 变量\n```go\n\t// 定义变量后赋值，如果没有赋值，默认为0，字符串的话默认为空串，数组的话默认为空数组。浮点值的默认也是0\n\tvar num1 int\n\tnum1 = 10\n\t// 直接写\n\tvar num2 int = 20\n\t// 类型推断，定义完成之后类型就确定好了\n\tvar num3 = 30\n\t// 简短声明，左侧变量至少得有一个是新的变量,且不能定义全局变量\n\tnum4 := 40\n```\n## 常量\n>常量组\n```go\n\tconst (\n\t\tUnknown = 0\n\t\tFemale = 1\n\t\tMale = 2\n\t)\n```\n>iota默认为0，表示const中定义的常量个数\n```go\n\tconst (\n\t\ta = iota\n\t\tb = iota\n\t\tc = iota\n\t)\n```\n>如果常量没有指定值，默认为上一行的值\n```go\n    const (\n\t\ta = iota   //0\n\t\tb          //1\n\t\tc          //2\n\t\td = \"ha\"   //独立值，iota += 1\n\t\te          //\"ha\"   iota += 1\n\t\tf = 100    //iota +=1\n\t\tg          //100  iota +=1\n\t\th = iota   //7,恢复计数\n\t\ti          //8\n    )\n```\n\n\n# 运算\n## 按位运算\n- 按位与：&，二元运算，全为1则为1，其他都为0\n- 按位或：|，二元运算，同位有1则为1，全0则为0\n- 异或运算：\n\t- ^，二元运算，相同则为0，不同则为1\n\t- ^，一元运算，包括符号位在内，取反\n- 移位运算\n\t- a << 2，向左移2位，最低位补0\n\t- a >>2，a向右移2位，最高位补符号位\n\n## 运算符优先级（从上到下）\n- ~、!、++、-- \n- *、/、%、<<、>>、&\n- +、-、^\n- ==、!=、<、<=、>=、>\n- <-\n- &&\n- ||\n\n# 输入输出\n## 占位符\n- %v，原样打出\n- %T，打印类型\n- %t，bool类型\n- %s，字符串类型\n- %f，浮点数类型\n- %d，十进制整数类型\n- %b，二进制整数类型\n- %o，八进制整数类型\n- %x，十六进制整数类型\n\t- %x：0-9，a-f\n\t- %X: 0-9，A-F\n- %c，字符类型\n- %p，指针目标对象的内存地址\n## 输入输出样式\n>fmt读取键盘的输入：遇到空格就读取不了了\n```go\n\tvar x int\n\tvar y float64\n\t//读取键盘的输入，通过操作地址，赋值给x和y   阻塞式\n\tfmt.Scanln(&x,&y)\n\tfmt.Printf(\"x的数值：%d，y的数值：%f\\n\",x,y)\n\tfmt.Scanf(\"%d,%f\",&x,&y)\n\t// 输出到终端\n\tfmt.Printf(\"x:%d,y:%f\\n\",x,y)\n```\n>bufio读取键盘的输入：忽略空格继续读取\n```go\nfunc main() {\n\tscanner := bufio.NewReader(os.Stdin)\n\t// 直到读取到回车符\n\treadString, err := scanner.ReadString('\\n')\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Println(readString)\n}\n```\n\n# 逻辑语句\n## IF语句\n>含初始化语句\n```go\n\t// num只在if内可以用到，出了if则用不到\n\tif num := 4;num>0{\n\t\tfmt.Println(\"正数\",num)\n\t}\n\telse if num ==0{\n\t\tfmt.Println(\"为零\",num)\n\t}\n```\n>不含初始化语句\n```go\n\tnum := 1\n\tif num>0{\n\n\t}\n\telse if{\n\n\t}\n\telse{\n\n\t}\n```\n## switch语句\n>标准写法\n```go\n\tswitch num1 {\n\tcase 1:\n\t\tfmt.Println(\"num1是1\")\n\t\tbreak\n\tcase 2:\n\t\tbreak\n\tcase 3:\n\t\tbreak\n\tdefault:\n\t\tbreak\n\t}\n```\n>省略switch后的变量，默认是布尔值\n```go\n\tswitch {\n\tcase true:\n\t\tbreak\n\tcase false:\n\t\tbreak\n\t}\n```\n>case匹配多个\n```go\n\tvar letter = \"B\"\n\tswitch letter {\n\tcase \"A\", \"E\", \"I\", \"O\", \"U\":\n\t\tfmt.Println(\"该字母是元音\")\n\t\tbreak\n\tdefault:\n\t\tfmt.Println(\"该字母不是元音\")\n\t\tbreak\n\n\t}\n```\n>初始化语句\n```go\n\tswitch letter := \"A\";letter {\n\tcase \"A\", \"E\", \"I\", \"O\", \"U\":\n\t\tfmt.Println(\"该字母是元音\")\n\t\tbreak\n\tdefault:\n\t\tfmt.Println(\"该字母不是元音\")\n\t\tbreak\n\n\t}\n```\n>贯通后续的case\n```go\n\tswitch a := 1; a {\n\tcase 1:\n\t\tfmt.Println(\"a=1\")\n\t\tfallthrough\n\tcase 2:\n\t\tfmt.Println(\"执行了贯穿\")\n\tcase 3:\n\t\tfmt.Println(\"如果case2中也有fallthrough，该语句也会被执行\")\n\t}\n```\n## 循环语句\n### for循环\n>标准写法\n```go\nfunc main() {\n\tfor i := 1;i<=5;i++{\n\t\tfmt.Println(\"Hello World\")\n\t}\n}\n```\n>省略分号，模拟while循环\n```go\n\tfor {\n\t\tfmt.Println(\"Hello World\")\n\t}\n\t// 或者如下\n\ti := 1\n\tfor i < 3 {\n\t\tfmt.Println(\"Hello World\")\n\t}\n```\n## 跳转语句\n### goto语句\n>指直接跳转到指定的代码中，注意LOOP标签后面的都属于LOOP中，所以一般标签写在函数的最后面，一般不推荐使用goto语句\n```go\nfunc main() {\n\n\tx := 1\n\tgoto LOOP\n\tfmt.Println(\"该行代码是执行不到的\")\n\nLOOP:\n\tx += 1\n\tfmt.Printf(\"该行代码是可以执行的，x为：%d\", x)\n\n}\n```\n## 随机数\n### 时间戳\n```go\nfunc main() {\n\t// 秒时间戳\n\ttimeStamp := time.Now().Unix()\n\t// 毫秒时间戳\n\ttimeMillisecond := time.Now().UnixMilli()\n\tprintln(timeMillisecond)\n\tprintln(timeStamp)\n}\n```\n### 生成随机数\n```go\n func main() {\n\trand.Intn(100)\n}\n```\n\n# 复合类型\n## 数组\n>数组的基本定义\n```go\n\t// 未赋值的情况下，默认为0\n\tvar arr1[1] int\n\tvar arr2 = [...]int{1, 2, 3}\n\t// 下标为0赋值为1，下标为3的地方赋值为2\n\tvar arr3 = [...]int{0: 1, 3: 2}\n\t// 数组实际存储的元素个数\n\trealLen := len(arr1)\n\t// 数组最大可存储的元素个数\n\tmaxLen := cap(arr1)\n\tfmt.Print(realLen)\n\tfmt.Print(maxLen)\n```\n>数组的range打印\n```go\nfunc main() {\n\tvar arr2 = []int{1, 2, 3}\n\tfor index, value := range arr2 {\n\t\tfmt.Printf(\"下标为：%d \", index)\n\t\tfmt.Printf(\"值为：%d\", value)\n\t\tfmt.Println()\n\t}\n\t// 舍弃下标\n\tfor _, val := range arr2 {\n\t\tfmt.Printf(\"值为：%d\", val)\n\t\tfmt.Println()\n\n\t}\n}\n```\n>数组的复制  \n>数组的复制是深拷贝，修改arr3不会影响到arr2\n```go\nfunc main() {\n\tvar arr2 = [...]int{1, 2, 3}\n\tvar arr3 = arr2\n\tarr3[0] = 9\n\tfmt.Println(arr2)\n\tfmt.Println(arr3)\n}\n```\n>数组的比较  \n>先比较数组长度和类型，然后依次比较数组中的值，及其顺序，是否都相同\n```go\nfunc main() {\n\tvar arr2 = [...]int{1, 2, 3}\n\tvar arr3 = arr2\n\tfmt.Print(arr3 == arr2)\n}\n```\n>数组元素的交换  \n>冒泡排序\n```go\nfunc main() {\n\tvar arr3 = [...]int{2, 1, 3}\n\tfor i := 0; i < len(arr3); i++ {\n\t\tfor j := 0; j < len(arr3)-i-1; j++ {\n\t\t\tif arr3[j] > arr3[j+1] {\n\t\t\t\t// 交换位置\n\t\t\t\tarr3[j], arr3[j+1] = arr3[j+1], arr3[j]\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println(arr3)\n}\n```\n>二维数组\n```go\n// 定义，默认值都为0\nvar arr3 [3][2]int\n// 定义并赋值\narr := [3][2]int{{1, 2}, {3, 4}, {5, 6}}\n```\n## 切片\n>定义如下，不在[]中写长度，则表示切片，切片本身不存数据，存数据的是底层的变长数组\n```go\n\tvar slice []int\n\tslice[0] = 1\n\t\n\ts2 := []int{1,2,3}\n\tfmt.Println(s2)\n\n\t// 第一个参数表示创建的切片初始化为0的元素个数，第二个参数表示该切片目前设置的最大容量\n\ts1 := make([]int, 0, 8)\n\t// 如果添加的元素过多超过定义的原容量，容量就会自动扩容到原来的2倍，会开辟新的空间分配内存地址，则s1需要指向新的地址\n\ts1 = append(s1, 1, 2, 3, 4)\n```\n>切片中添加其他切片\n```go\n\ts1 := make([]int, 0, 4)\n\ts1 = append(s1, 1, 2, 3, 4)\n\ts2 := []int{9,9,9}\n\ts1 = append(s1, s2...)\n```\n>从已有的数组中直接创建切片，操作切片也会影响到已有的数组  \n```go\nfunc main() {\n\tarr := [10]int{1, 2, 3, 4, 5}\n\t// 取下标 2<=x<4的元素\n\tslice := arr[2:4]\n\tfmt.Println(slice)\n}\n```\n>切片超过原数组的右边界\n```go\nfunc main() {\n\tarr := [5]int{5, 2, 3, 4, 5}\n\t// 取下标 2<=x<4的元素\n\tslice := arr[2:4]\n\t// 如果添加的元素未超过数组的右边界，则会改变原数组的值\n\tslice = append(slice, 9)\n\t// 继续添加元素，直到超过数组的右边界，则会复制切片的数据，并重新开辟一个新的空间\n\tslice = append(slice, 9)\n\tfmt.Println(slice)\n\tfmt.Println(arr)\n\tfmt.Println(len(slice), cap(slice))\n}\n```\n>切片的复制，是引用类型的复制，属于浅拷贝\n```go\nfunc main() {\n\ts1 := []int{1,2,3}\n\ts2 := s1\n\tfmt.Println(s1,s2)\n}\n```\n>切片的深拷贝\n```go\nfunc main() {\n\ts1 := []int{1, 2, 3}\n\t// 第二个参数必须大于等于需要copy的元素个数\n\ts2 := make([]int, len(s1), len(s1))\n\ts3 := make([]int, len(s1)-1, len(s1)-1)\n\tcopy(s2, s1)\n\t// 部分拷贝\n\tcopy(s3, s2[:2])\n\tfmt.Println(s3)\n}\n```\n## Map集合\n>Map的定义与创建\n```go\nfunc main() {\n\t// 定义一个空引用，没分配实际的存储地址，所以无法使用，也就是说maap1=nil\n\tvar map1 map[string]int\n\t// 分配实际空间\n\tmap2 := make(map[string]int)\n\t// 直接初始化\n\tmap3 := map[string]int{\"Go\": 100, \"Java\": 100, \"C++\": 90}\n}\n```\n>Map的元素返回\n```go\nfunc main() {\n\tmap1 := make(map[string]int)\n\tmap1[\"test\"] = 0\n\tval, exist := map1[\"test\"]\n\tfmt.Printf(\"key为%d, val为%t\", val, exist)\n}\n```\n>Map元素的删除\n```go\nfunc main() {\n\tmap1 := make(map[string]int)\n\tmap1[\"test\"] = 0\n\tdelete(map1, \"test\")\n\tfmt.Println(len(map1))\n}\n```\n>遍历Map集合\n```go\nfunc main() {\n\tmap1 := map[string]int{\"Golang\": 100, \"Java\": 100, \"C++\": 90}\n\tfor key, val := range map1 {\n\t\tfmt.Print(\"key:\" + key + \" \")\n\t\tfmt.Printf(\"val: %d\", val)\n\t\tfmt.Println()\n\t}\n}\n```\n>Map与切片的结合\n```go\nfunc main() {\n\tuserList := make([]map[string]string, 0, 3)\n\tuserList = append(userList, map[string]string{\"name\": \"谢特智力\"})\n}\n```\n\n## 字符串\n### 字符串的定义\n>顺序访问到的是单字节\n```go\nfunc main() {\n\tstr := \"abcd\"\n\tfor _, va := range str {\n\t\t// 打印出来的是英文字符的ASCALL码\n\t\tfmt.Print(va)\n\t}\n\n\tstr2 := \"谢特智力\"\n\t// 打印结果是12，一个中文字符占三个字节\n\tfmt.Print(len(str2))\n}\n```\n>字符串是字节的集合\n```go\nfunc main() {\n\tslice := []byte{97, 98, 99, 100}\n\t// 字节切片转换成字符串\n\tstr := string(slice)\n\t// 字符串转换成切片\n\tslice2 := []byte(str)\n\t// 遍历新字节切片\n\tfor _, v := range slice2 {\n\t\tfmt.Println(v)\n\t}\n}\n```\n>字符串的内容无法被修改\n```go\nfunc main() {\n\tstr := \"abc\"\n\t// 会报错\n\tstr[0] = 'B'\n}\n```\n### 字符串包的使用\n>子串的API\n```go\nfunc main() {\n\tstr := \"abcda\"\n\tif strings.Contains(str, \"abc\") {\n\t\tfmt.Println(\"str中包括了整个子串\")\n\t}\n\tif strings.ContainsAny(str, \"efga\") {\n\t\tfmt.Println(\"str中包括了子串中的某一个字符，中文字符也可\")\n\t}\n\t// 计算整个子串在str中出现的频次\n\tcountSubstr := strings.Count(str, \"a\")\n\tfmt.Println(countSubstr)\n\tif strings.HasPrefix(str, \"ab\") {\n\t\tfmt.Println(\"str中有\\\"ab\\\"这个子串前缀\")\n\t}\n\n\t// 子串整体第一次出现的下标\n\tfistIndex := strings.Index(str, \"abc\")\n\t// 子串中任一字符第一次出现的下标，取最小下标\n\tanyIndex := strings.IndexAny(str, \"efba\")\n\t// 子串整体第一次出现的下标，如果没有，则返回-1\n\tlastIndex := strings.LastIndex(str, \"e\")\n}\n```\n>字符串的分隔与拼接\n```go\nfunc main() {\n\t// 将字符串切片组成一个新的字符串\n\tstrArr := []string{\"abc\", \"def\", \"ghi\"}\n\tjoiStr := strings.Join(strArr, \",\")\n\t// 输出结果是abc,def,ghi\n\tfmt.Println(joiStr)\n}\n```\n>字符串的分隔\n```go\nfunc main() {\n\tstr := \"abc,edf,hig\"\n\tstrArr := strings.Split(str, \",\")\n\tfmt.Println(strArr)\n}\n```\n>字符串的重复拼接与替换\n```go\nfunc main() {\n\tstr := \"abc\"\n\tstrs := strings.Repeat(str, 5)\n\tfmt.Println(strs)\n\tnewStr := strings.ReplaceAll(str, \"a\", \"d\")\n\tfmt.Println(newStr)\n}\n```\n>大小写转换\n```go\nfunc main() {\n\tstr := \"abc\"\n\tupperStr := strings.ToUpper(str)\n\tlowerStr := strings.ToLower(upperStr)\n\tfmt.Println(upperStr)\n\tfmt.Println(lowerStr)\n}\n```\n>字符串的截取，与切片是同一操作\n```go\nfunc main() {\n\tstr := \"谢特智力\"\n\tsubStr := str[:6]\n\tstrEn := \"wente\"\n\tsubStrEn := strEn[:3]\n\tfmt.Println(subStr)\n\tfmt.Print(subStrEn)\n}\n```\n>字符串与基础类型的转换\n```go\nfunc main() {\n\tstr := \"true\"\n\t// 字符串类型转布尔类型\n\tboolStr, err := strconv.ParseBool(str)\n\tif err == nil {\n\t\tfmt.Println(\"转换成功！\")\n\t\tfmt.Printf(\"转换结果为：%t\\n\", boolStr)\n\t}\n\t// 布尔类型转字符串类型\n\tstrBool := strconv.GBool(true)\n\tfmt.Println(strBool)\n\t// -----------------------与int的转换------\n\tintStr, err2 := strconv.Atoi(\"123\")\n\tif err2 == nil {\n\t\tfmt.Println(\"转换成功\")\n\t\tfmt.Printf(\"转换结果为：%d\\n\", intStr)\n\t}\n\t// int转字符串\n\tstrInt := strconv.Itoa(intStr)\n\tfmt.Println(strInt)\n}\n```\n# 函数\n## 函数的定义与使用\n>函数的定义\n```go\nfunc main() {\n\tres1, res2 := funcName(1)\n\tfmt.Print(res1)\n\tfmt.Print(res2)\n}\n\n/*\n入参为param，类型为int\n返回值可以有多个，这里的返回值有两个\n*/\nfunc funcName(param int) (int,  int) {\n\tres1 := param + 1\n\tres2 := param - 1\n\treturn res1, res2\n}\n/**另一种返回方式，需要返回的结果在方法签名的返回值区域定义 */\nfunc test() (sum int) {\n\tsum = 1\n\treturn\n}\n```\n\n>可变参数入参\n```go\nfunc main() {\n\tfmt.Println(getSum(\"test1\", \"test2\", 1, 2, 3, 4, 5))\n\t// 可用切片作为可变参数的入参\n\tslice := make([]int, 0)\n\tfmt.Println(getSum(\"test1\", \"test2\", slice...))\n}\n\n// 如果不止有可变参数，则可变参数需要放到参数列表的最后，\n// 一个函数的参数列表只能有一个可变参数\nfunc getSum(s1, s2 string, nums ...int) (result int) {\n\tfmt.Println(s1)\n\tfmt.Println(s2)\n\tsum := 0\n\tfor _, v := range nums {\n\t\tsum += v\n\t}\n\treturn sum\n}\n```\n>函数也是个指针变量\n```go\nfunc main() {\n\tvar b func(int)\n\tc := test\n\tb = test\n\tc(1)\n\tb(2)\n\n}\n\nfunc test(param int) {\n\tfmt.Print(param)\n}\n```\n\n## defer函数的使用\n>用于函数的延迟执行，defer的执行顺序是栈的思想，先延迟的后执行，后延迟的先执行\n```go\nfunc main() {\n\tfmt.Print(\"主函数执行\")\n\tdefer deferTestOne()\n\tfmt.Println(\"主函数继续执行\")\n\tdefer deferTestTwo()\n\tfmt.Println(\"主函数执行完毕\")\n}\n\nfunc deferTestOne() {\n\tfmt.Println(\"第一个延迟函数执行\")\n}\n\nfunc deferTestTwo() {\n\tfmt.Println(\"第二个延迟函数执行\")\n}\n```\n>无论参数类型是值传递还是引用传递，defer函数的参数都不会因为主函数在defer函数后的语句对原参数的改变而改变\n```go\nfunc main() {\n\ta := 1\n\tb := make([]int, 0)\n\tfmt.Print(\"主函数执行\")\n\tdefer deferTestOne(a, b)\n\ta++\n\tb = append(b, 1)\n\tfmt.Printf(\"切片b的元素个数为：%d\\n\", len(b))\n\n}\n// 执行到defer的时候，传参就已经确定了，原参数在主函数后面的改变，不会改变执行到此刻的传参\nfunc deferTestOne(param int, param2 []int) {\n\tparam2 = append(param2, 2)\n\tfmt.Printf(\"延迟函数1：切片b的元素个数为：%d\\n\", len(param2))\n\tfmt.Println(\"第一个延迟函数执行，传参为：\" + strconv.Itoa(param))\n}\n```\n## 高级函数的使用\n>匿名函数的使用\n```go\nfunc main() {\n\t//定义带参但是无返回值的匿名函数\n\tfunc(p1 int, p2 int) {\n\t\tfmt.Println(\"参数1：\" + strconv.Itoa(p1))\n\t\tfmt.Println(\"参数2：\" + strconv.Itoa(p2))\n\t}(1, 2)\n\n\t// 带返回值的匿名函数定义，并用f1作为一个函数变量来接收\n\tf1 := func(p1 int, p2 int) int {\n\t\treturn p1 + p2\n\t}\n\tfmt.Println(f1(1, 2))\n\n\t// 带返回值的匿名函数调用，并用res1接收返回值\n\tres1 := func(p1 int, p2 int) int {\n\t\treturn p1 + p2\n\t}(1, 2)\n\tfmt.Println(res1)\n}\n```\n> 回调函数的使用\n```go\nfunc main() {\n\tres := oper(1, 2, func(a int, b int) int {\n\t\treturn a * b\n\t})\n\tfmt.Println(\"结果是：\" + strconv.Itoa(res))\n}\n\n// 使用回调函数来进行乘法操作\nfunc oper(a int, b int, fun func(a int, b int) int) int {\n\tif a == 0 || b == 0 {\n\t\treturn 0\n\t}\n\t// 执行完if的检查逻辑之后，执行回调函数逻辑\n\treturn fun(a, b)\n}\n```\n>闭包的使用  \n>* 闭包的定义：内层函数以及外层函数被内层函数所使用的变量，统称为闭包  \n>* 闭包的生命周期不随外层函数的消失而消失  \n>* 外层函数的返回值就是内层函数，且内层函数使用了外层函数定义的变量，才会形成闭包\n```go\n\tfunc main() {\n\to1 := outside()\n\tfmt.Println(o1())\n\tfmt.Println(o1())\n\tfmt.Println(o1())\n\t// 每次重新调用外层函数都会重新生成一个闭包\n\to2 := outside()\n\tfmt.Println(o2())\n\tfmt.Println(o2())\n\tfmt.Println(o2())\n}\n\n// 外层函数返回值是内层函数类型，且内层函数操作了外层函数的变量\nfunc outside() func() int {\n\ta := 0\n\tf1 := func() int {\n\t\ta++\n\t\treturn a\n\t}\n\treturn f1\n}\n```\n\n# 指针\n## 变量指针\n>指针的定义：存储了另一个变量的内存地址\n```go\nfunc main() {\n\ta := 1\n\tvar aPoint *int\n\t// 指针指向a的内存地址\n\taPoint = &a\n\t// 打印指针指向的内存地址的存放的值\n\tfmt.Println(*aPoint)\n\t// 打印出来的是a的内存地址\n\tfmt.Println(aPoint)\n\t// 通过指针改变变量的值\n\t*aPoint = 2\n\t// 指针的指针\n\tvar ap2 **int\n\tap2 = &aPoint\n\tfmt.Println(**ap2)\n}\n```\n## 数组指针\n>数组指针：指针指向一个数组\n```go\nfunc main() {\n\tarr := [3]int{1, 2, 3}\n\t// 定义数组指针\n\tvar p *[3]int\n\tp = &arr\n\t// 根据数组指针修改数组的值，两种写法均可\n\t(*p)[0] = 9\n\tp[0] = 8\n}\n```\n>指针数组：数组里装的都是指针\n```go\nfunc main() {\n\ta := 1\n\tb := 1\n\tc := 1\n\tarr := [3]*int{&a, &b, &c}\n\tfmt.Println(*arr[0])\n}\n```\n>指针函数，这里的数组是不会被销毁的，应该是闭包的应用吧\n```go\nfunc main() {\n\tarrPoint := f1()\n\tfmt.Println(*arrPoint)\n}\n\nfunc f1() *[3]int {\n\treturn &[3]int{1, 2, 3}\n}\n```\n\n# 结构体\n## 结构体初识\n>结构体的简单定义返回的是普通的结构体变量，普通的结构体变量是值传递\n```go\nfunc main() {\n\t// 声明式\n\tvar wente Person\n\twente.name = \"谢特智力\"\n\twente.age = 22\n\twente.sex = 1\n\t// 按顺序赋值\n\twendy := Person{\"温迪\", 2000, 0}\n\tfmt.Println(wendy)\n\t// 自定义赋值\n\tyuxi := Person{\n\t\tname: \"玉溪\",\n\t\tage:  11,\n\t}\n\t// 定义但不赋值\n\tp2 := Person{}\n\tfmt.Println(yuxi)\n}\n\ntype Person struct {\n\tname string\n\tage  int\n\tsex  byte\n}\n```\n>结构体的指针定义\n```go\nfunc main() {\n\t// p1如果不赋值的情况下，属性都拥有其类型的初始值，而不是nil\n\t// new 字段返回的是一个指针变量\n\tp1 := new(Person)\n\t// 本来应该是*p1.name=\"谢特智力\"，但是结构体指针比较特殊，可以简写为如下\n\tp1.name = \"谢特智力\"\n\tfmt.Println(*p1)\n}\n\ntype Person struct {\n\tname string\n\tage  int\n\tsex  byte\n}\n```\n\n\n\n## 结构体的深入浅出\n>深拷贝和浅拷贝的实现\n```go\nfunc main() {\n\t// 按顺序赋值\n\twendy := Person{\"温迪\", 2000, 0}\n\tfmt.Printf(\"%p\\n\", &wendy)\n\t// 深拷贝\n\twente := wendy\n\t// 与wendy不一样\n\tfmt.Printf(\"%p\\n\", &wente)\n\t// 浅拷贝的实现\n\twp := &wendy\n\tfmt.Printf(\"%p\\n\", wp)\n\tfmt.Println(*wp)\n}\n\ntype Person struct {\n\tname string\n\tage  int\n\tsex  byte\n}\n```\n>结构体的匿名定义\n```go\nfunc main() {\n\ts1 := struct {\n\t\tname string\n\t\tage  int\n\t}{\n\t\tname: \"谢特智力\",\n\t\tage:  22,\n\t}\n\tfmt.Println(s1)\n}\n```\n>结构体的匿名字段：默认使用数据类型作为名字，但是同一个结构体内部的类型不能重复\n```go\nfunc main() {\n\tp1 := new(Person)\n}\n\ntype Person struct {\n\tstring\n\tint\n\tbyte\n}\n```\n>结构体的嵌套\n```go\nfunc main() {\n\tp1 := new(Person)\n\tp1.name = \"文特\"\n\tp1.Book = Book{\"红楼梦\", 29.9}\n\tfmt.Println(*p1)\n}\n\ntype Person struct {\n\tname string\n\tBook Book\n}\n\ntype Book struct {\n\tname  string\n\tprice float64\n}\n```\n>通过匿名结构体，模拟继承关系  \n>* 子类可以访问父类的字段  \n>* 子类可以访问父类已有的方法  \n>* 子类可以重写父类的字段和方法  \n```go\nfunc main() {\n\tstu := new(Student)\n\tstu.name = \"文特\"\n\tstu.work()\n}\n\n// Human 父类\ntype Human struct {\n\tname string\n\tage  int\n}\n\n// Student 子类\ntype Student struct {\n\t// 匿名结构体中的字段叫做提升字段，可以直接被访问\n\tHuman\n\tstuId int64\n}\n// 父类的方法\nfunc (human Human) work() {\n\tfmt.Println(\"Human在工作！名字是：\" + human.name)\n}\n// 子类的方法\nfunc (stu Student) work() {\n\tfmt.Println(\"Student在工作！名字是：\" + stu.name)\n}\n```\n>定义方法，方法是被结构体所拥有的\n```go\nfunc main() {\n\tp1 := new(Human)\n\tp1.name = \"谢特智力\"\n\tp1.work()\n\tp1.rest()\n}\n\ntype Human struct {\n\tname string\n\tage  int\n}\n\n// 结构体的指针变量会直接影响到调用者\nfunc (human *Human) work() {\n\tfmt.Println(human.name + \"在工作！\")\n}\n\n// 结构体变量会复制一份给human，这里是值传递数据\nfunc (human Human) rest() {\n\tfmt.Println(human.name + \"在休息！\")\n}\n```\n\n# 接口\n## 接口初识\n>接口的定义与基本使用\n>* 具有多态的性质\n>* 接口对象不能访问实现类的属性\n```go\nfunc main() {\n\tm1 := new(Mouse)\n\tm1.name = \"罗技鼠标\"\n\ttest(m1)\n}\n\ntype USB interface {\n\tstart()\n\tend()\n}\n\n// 接口的实现类\ntype Mouse struct {\n\tname string\n}\n\n// 具体的实现方法\nfunc (mouse *Mouse) start() {\n\tfmt.Println(\"USB启动，连接对象为：\" + mouse.name)\n}\nfunc (mouse *Mouse) end() {\n\tfmt.Println(\"USB关闭，连接对象为：\" + mouse.name)\n}\n\n// 测试类\nfunc test(usb USB) {\n\tusb.start()\n\tusb.end()\n}\n```\n\n## 接口的应用\n>空接口的使用，常用于传参使用\n```go\nfunc main() {\n\tvar obj Object = struct {\n\t\tname string\n\t\tage  int\n\t}{\n\t\t\"文特\",\n\t\t22,\n\t}\n\ttest(obj)\n\t// 空接口类型的slice\n\tslice := make([]interface{}, 0)\n\tslice = append(slice, \"文特\", 22, false, true, 66.66)\n\ttestSlice(slice)\n}\n// 空接口的外部定义\ntype Object interface {\n}\n\nfunc test(object Object) {\n\tfmt.Println(object)\n}\n\n// 空接口类型的数据：任意类型的数据\nfunc testSlice(slice []interface{}) {\n\tfmt.Println(slice)\n}\n```\n>接口的嵌套与继承\n```go\nfunc main() {\n\tw1 := new(Worker)\n\ttest(w1)\n}\n\ntype interA interface {\n\trest()\n}\ntype interB interface {\n\tinterA\n\twork()\n}\ntype Worker struct {\n\tname string\n}\n\nfunc (worker Worker) work() {\n\tfmt.Println(worker.name + \"正在工作\")\n}\nfunc (worker Worker) rest() {\n\tfmt.Println(worker.name + \"正在休息\")\n}\n\nfunc test(ib interB) {\n\tib.work()\n\tib.rest()\n}\n```\n>接口的断言的使用\n>* 断言的时候，指针类型和值类型不是一回事\n>* 感觉类似用instance of来判断类型\n>* 鼠标放在结构体上，用Ctrl + i然后输入接口的名称，可以快速生成接口的实现方法\n```go\nfunc main() {\n\t// 给个三角形数据\n\tt1 := new(Triangle)\n\tt1.base = 2\n\tt1.high = 2.5\n\t// 给个圆形数据\n\tr1 := new(Round)\n\tr1.radius = 2\n\t// 测试\n\ttest(t1)\n\tswitchTest(r1)\n\n}\n\n// Shape 形状接口\ntype Shape interface {\n\tgetArea() float64\n}\n\n// Triangle 三角形实现类\ntype Triangle struct {\n\tbase float64\n\thigh float64\n}\n\nfunc (t Triangle) getArea() float64 {\n\treturn t.base * t.high\n}\n\n// Round 圆形实现类\ntype Round struct {\n\tradius float64\n}\n\nfunc (r Round) getArea() float64 {\n\treturn math.Pi * r.radius * r.radius\n}\n\n// 断言测试函数：if的实现\nfunc test(shape Shape) {\n\t// 断言的时候，指针类型和值类型不是一回事\n\tif ins, ok := shape.(*Triangle); ok {\n\t\tfmt.Println(\"该形状是三角形，面积为：\" + strconv.FormatFloat(ins.getArea(), 'f', 2, 64))\n\t} else if ins, ok := shape.(*Round); ok {\n\t\tfmt.Println(\"该形状是圆形，面积为：\" + strconv.FormatFloat(ins.getArea(), 'f', 2, 64))\n\t} else {\n\t\tfmt.Println(\"我也不知道了\")\n\t}\n}\n\n// 断言测试函数：switch的实现\nfunc switchTest(shape Shape) {\n\t// 这里的type 关键字在 switch 语句中才具有意义，它用于匹配接口的动态类型\n\tswitch ins := shape.(type) {\n\tcase *Triangle:\n\t\tfmt.Println(\"该形状是三角形，面积为：\" + strconv.FormatFloat(ins.getArea(), 'f', 2, 64))\n\tcase *Round:\n\t\tfmt.Println(\"该形状是圆形，面积为：\" + strconv.FormatFloat(ins.getArea(), 'f', 2, 64))\n\tdefault:\n\t\tfmt.Println(\"未知形状！\")\n\t}\n\n}\n```\n# Type的使用\n## 自定义类型\n>在这语法上，自定义类型和经典类型不是一回事，这里是弄了一个新类型\n```go\nfunc main() {\n\tvar i1 myint\n\ti1 = 1\n\tvar i2 int\n\ti2 = 2\n\t// 无法直接将i2赋值给i1\n\ti1 = i2\n}\n\ntype myint int\n```\n>起别名，但是可以通用,Go1.9之后引入\n```go\ntype myint = int\n```\n## 自定义函数类型\n>自定义返回的函数的类型\n```go\nfunc main() {\n\taddF := getAddFun()\n\tres := addF(1, 2)\n\tfmt.Println(res)\n}\n// 自定义函数类型\ntype myfun func(int, int) int\n// 得到一个加法函数\nfunc getAddFun() myfun {\n\tf := func(i1 int, i2 int) int {\n\t\treturn i1 + i2\n\t}\n\treturn f\n}\n```\n>结构体中嵌入结构体\n```go\nfunc main() {\n\ts1 := new(Student)\n\ts1.Person.name = \"谢特智力\"\n\ts1.People.name = \"文特\"\n\ts1.People.show1()\n\ts1.Person.show2()\n}\n\n// People 起一个类型别名\ntype People = Person\n\n// Student 结构体中嵌套其他结构体\ntype Student struct {\n\tPeople\n\tPerson\n}\n\ntype Person struct {\n\tname string\n}\n\n// 别名和本名分别定义不同的实现函数，函数名不能相同\n// 个人认为这样做有点脱裤子放屁的感觉。。。\nfunc (p1 People) show1() {\n\tfmt.Println(\"People：\" + p1.name)\n}\nfunc (p2 Person) show2() {\n\tfmt.Println(\"Person：\" + p2.name)\n}\n```\n# Error的使用\n## 初识Error\n>新建Error\n```go\nfunc main() {\n\te1 := errors.New(\"错误已经发生\")\n\tfmt.Println(e1)\n\te2 := fmt.Errorf(\"错误的信息码为：%d\", 100)\n\tfmt.Println(e2)\n}\n```\n## 查看错误的详细信息\n>文件打开错误\n```go\nfunc main() {\n\tfile, err := os.Open(\"text.txt\")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\tif ins, ok := err.(*os.PathError); ok {\n\t\t\tpath := ins.Path\n\t\t\top := ins.Op\n\t\t\terrMsg := ins.Err\n\t\t\tfmt.Println(\"path:\", path)\n\t\t\tfmt.Println(\"op:\", op)\n\t\t\t// 系统找不到specified文件\n\t\t\tfmt.Println(\"errMsg:\", errMsg)\n\t\t}\n\n\t}\n\tfmt.Println(file.Name(), \"打开成功！\")\n}\n```\n>DNS错误\n```go\nfunc main() {\n\taddr, err := net.LookupHost(\"www.textxtzl.com\")\n\tif err != nil {\n\t\t//错误断言，判断是否是DNSError\n\t\tif ins, ok := err.(*net.DNSError); ok {\n\t\t\tif ins.IsTimeout {\n\t\t\t\tfmt.Println(\"超时错误\")\n\t\t\t}\n\t\t\tif ins.IsNotFound {\n\t\t\t\tfmt.Println(\"访问丢失错误\")\n\t\t\t}\n\t\t\tif ins.IsTemporary {\n\t\t\t\tfmt.Println(\"临时性错误\")\n\t\t\t}\n\t\t}\n\t}\n\tfmt.Println(\"addr为：\", addr)\n}\n```\n>精准匹配错误\n```go\nfunc main() {\n\t//dir := \"../wente/txts\"\n\t//pattern := filepath.Join(dir, \"*.txt\")\n\tfilePaths, err := filepath.Glob(\"[\")\n\tif err != nil && errors.Is(err, filepath.ErrBadPattern) {\n\t\tfmt.Println(\"文件映射路径错误！\")\n\t\treturn\n\t}\n\t// 打印文件路径列表\n\tfmt.Println(filePaths)\n\n}\n```\n## 自定义错误\n>自定义错误类型\n```go\nfunc main() {\n\tres, err := getArea(-1)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\tif ins, ok := err.(*AreaError); ok {\n\t\t\tfmt.Println(\"半径是\", ins.radius)\n\t\t}\n\t\treturn\n\t}\n\tfmt.Println(res)\n\n}\n\n// AreaError 定义错误结构体\ntype AreaError struct {\n\tmsg    string\n\tradius float64\n}\n\n// 实现Error()方法，即可实现error接口\nfunc (e *AreaError) Error() string {\n\treturn fmt.Sprintf(\"error: 半径：%.2f,错误信息为：%s\", e.radius, e.msg)\n}\n\n// 计算半径\nfunc getArea(radius float64) (float64, error) {\n\tif radius < 0 {\n\t\treturn 0, &AreaError{\"半径非法！\", radius}\n\t}\n\treturn math.Pi * radius * radius, nil\n}\n```\n## defer异常捕获机制\n>输出结果为：2 B d c b a E C 触发异常1 D A 4 3 1\n```go\nfunc main() {\n\t// 手动定义defer函数内容并当场调用，匿名函数的使用\n    defer func() { fmt.Println(1) }()\n    fmt.Println(2)\n    defer func() { fmt.Println(3) }()\n    defer_call1()\n\t// 后续可以可以被执行\n    fmt.Println(4)\n}\n \nfunc defer_call1() {\n    defer func() { fmt.Println(\"A\") }()\n    fmt.Println(\"B\")\n    defer func() {\n        fmt.Println(\"C\")\n\t\t// 异常已经被捕获处理\n        err := recover()\n        if err != nil {\n            fmt.Println(err)\n        }\n        fmt.Println(\"D\")\n    }()\n    defer func() { fmt.Println(\"E\") }()\n    defer_call2()\n\t// 由于defer_call2已经抛出了异常，所以F无法被打印，程序直接进入预终止阶段，执行defer函数\n\t// defer函数执行完毕之后就直接返回到上一层的调用方，也不会继续执行打印F的语句\n    fmt.Println(\"F\")\n}\n \nfunc defer_call2() {\n    defer func() { fmt.Println(\"a\") }()\n    defer func() { fmt.Println(\"b\") }()\n    defer func() { fmt.Println(\"c\") }()\n    fmt.Println(\"d\")\n\t// 手动抛出异常\n    panic(\"触发异常1\")\n\t// 后续代码不会继续执行\n    panic(\"触发异常2\")\n    fmt.Println(\"e\")\n}\n```\n## Error和异常Panic的使用场景\n>Panic异常场景：意料之外，不应该出的问题,比如空指针异常，下标溢出等异常\n>* 空指针引用\n>* 下标越界\n>* 除数为0\n>* switch中出现不应该出现的case或者default\n>* 断言失败\n>* 死锁\n\n> Error的处理场景：意料之内，可能出的问题, 比如网络连接超时，json解析错误等\n>* 函数返回错误，比如说打开文件可能出错","categories":["Golang"],"tags":["Golang"]},{"title":"Golang-qucikStart","url":"/posts/34244/","content":">Golang的初步开发与使用\n<!--more-->\n# Win10的安装\n## 下载\n>访问网站即可下载对应版本  \n>https://golang.google.cn/\n## 配置环境变量\n>* GOROOT\n>* GOPATH\n>* 使用go version 或 go env 判断go是否安装完成\n## 配置镜像地址\n>* 原地址：GOPROXY=https://proxy.golang.org,direct\n>* 国内代理镜像：GOPROXY=https://goproxy.cn,direct\n>* 如果下载Go的依赖超时，考虑使用go env -w GOSUMDB=off来关闭包的安全性校验\n## GO ENV参数部分配置解释\n```go\nset GO111MODULE=on           \t\t//是否以Go modules的模式运行项目  auto,on,off\nset GOARCH=amd64             \t\t//目标可执行程序操作系统构架 包括 386，amd64，arm\nset GOBIN=                   \t\t//项目的第三方可执行文件目录\nset GOCACHE=   \t\t\t\t        //项目的缓存目录\nset GOENV=\t\t\t\t            //项目的env文件目录\nset GOEXE=.exe\t\t\t\t        //项目编译之后的可执行文件后缀名\nset GOHOSTOS=windows\t\t\t    //什么平台下面运行\nset GOMODCACHE=                     //go mod 的缓存地址\nset GONOPROXY=\t\t\t\t        //私有库\nset GONOSUMDB=                      //加载源代码不需要验证的库\nset GOOS=windows\t\t\t     //目标可执行程序运行操作系统。支持darwin,freebsd,linux,windows\nset GOPATH=C:\\Users\\Ch\\go           //go项目的目录\nset GOPRIVATE=                     \t//私有的项目依赖地址\nset GOPROXY=\t\t\t\t        //公共的项目依赖地址\nset GOROOT=C:\\Program Files\\Go\t\t//go的安装目录\nset GOTMPDIR=                       //go的临时文件目录\nset GOTOOLDIR=     \t\t\t        //go的工具包目录\nset GOVCS=\t\t\t\t            //指定了golang用什么版本控制工具下载源代码\nset GOVERSION=go1.16.3              //使用go的版本号\nset GCCGO=gccgo                   \t//golang自带的编辑器目录\n```\n\n# Hello World\n## 目录\n>* gopath -> src -> 项目名\n## 代码\n```go\n// main函数所在的包名必须是main\npackage main\nimport \"fmt\"\nfunc main(){\n    fmt.println(\"Hello Wrold！\")\n}\n```\n## 运行\n>* go run hello.go\n>* go bulid + go install ：会检查包下是否存在多个源码文件，不允许一个包下有多个main文件\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["Golang"],"tags":["Golang"]},{"title":"TechStack-InterfaceDefault","url":"/posts/41697/","content":"> 接口的默认方法解析\n<!--more-->\n# 结论\n>* 接口中可以用default修饰方法，该方法可以写方法体，作为接口的默认方法\n>* 接口中的默认方法的权限范围和public相同，且重写后的方法的修饰符就是public\n>* 当实现类同时继承了其他类，并且实现了接口，而其他类的方法和接口的默认方法都存在的时候，会优先执行于被继承的类的方法\n>* 当实现类同时实现了两个接口，且两个接口有同名的默认方法，则实现类必须重写该方法，可以自定义新的逻辑，也可以复用两个接口中其中一个接口的逻辑\n# 代码\n## 接口中的默认方法\n```java\npublic interface Cat {\n    default void test(){\n        System.out.println(\"接口根实现\");\n    }\n}\n```\n## 实现类的重写方法\n```java\npublic class CatOne implements Cat {\n    @Override\n    public void test() {\n        Cat.super.test();\n    }\n}\n```\n## 类优先于接口\n```java\npublic class MyImplement2 extends MyImplement implements Interface2{\n    public static void main(String[] args) {\n        MyImplement2 myImplement2 = new MyImplement2();\n        // 输出MyImplement类中所定义的逻辑\n        myImplement2.helloWorld();\n    }\n}\n```\n## 多接口同名默认方法\n```java\npublic class MyImplement implements Interface1,Interface2{\n    public static void main(String[] args) {\n        MyImplement myImplement = new MyImplement();\n        // 输出为子类的重写后的逻辑\n        myImplement.helloWorld();\n    }\n\n    @Override\n    public void helloWorld() {\n        // 复用接口1的逻辑，也可以重写逻辑\n        Interface1.super.helloWorld();\n    }\n}\n```\n","categories":["TechStack"],"tags":[]},{"title":"TechStack-ASynchronization","url":"/posts/42352/","content":">关于异步的操作\n<!--more-->\n# CompletableFuture\n## 函数API解析\n### 提交主任务\n>* supplyAsync：有返回值地提交任务给线程池执行\n>* runAsync：无返回值地提交任务给线程池执行\n>* allOf：将多个异步线程组成一组，等待多个异步线程执行完毕之后，返回统一可操作这组线程的对象\n\n### 回调任务\n>* thenApply：若主任务有返回结果，则就有一个参数result，回调函数有返回值\n>* thenAccept：若主任务有返回结果，则就有一个参数result，回调函数无返回值\n>* thenRun：无参数，回调函数无返回值\n>* thenCompose：可无限套娃，执行完上一个回调逻辑之后，才会执行下一个回调逻辑，可控制多个异步线程的回调逻辑的顺序\n\n\n## 实战案例\n### 多线程执行后阻塞主线程\n```java\n    // 添加新任务并执行 \n    List<CompletableFuture<Integer>> taskList = new ArrayList<>();\n    AtomicInteger atomicNum = new AtomicInteger(0);\n    for (int i = 0; i < num; i++) {\n        CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {\n            int increment = atomicNum.getAndIncrement();\n            System.out.println(\"当前执行的线程是：\"+increment);\n            return increment;\n        });\n        taskList.add(future);\n    }\n    // 等待所有任务执行完成，并调用join方法来阻塞主线程，join也可以用get()替代，也会阻塞主线程\n    // 使用allOf的主要目的就是获取到可以控制一组异步线程的对象\n    CompletableFuture.allOf(taskList.toArray(new CompletableFuture[0])).join();\n```\n### 添加异步线程的回调线程\n```java\n  // 添加新任务并执行\n        List<CompletableFuture<Integer>> taskList = new ArrayList<>();\n        AtomicInteger atomicNum = new AtomicInteger(0);\n        for (int i = 0; i < num; i++) {\n            CompletableFuture<Integer> future = CompletableFuture.supplyAsync(() -> {\n                int increment = atomicNum.getAndIncrement();\n                System.out.println(\"当前执行的线程是：\"+increment);\n                return increment;\n            });\n            future.thenRun(()->{\n                try {\n                    System.out.println(\"当前执行完结的异步回调线程是：\"+future.get());\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (ExecutionException e) {\n                    e.printStackTrace();\n                }\n            });\n            taskList.add(future);\n        }\n        // 等待所有任务执行完成，并获取到可控制所有线程的对象\n        CompletableFuture<Void> voidCompletableFuture = CompletableFuture.allOf(taskList.toArray(new CompletableFuture[0]));\n```\n### 控制回调函数的执行顺序\n```java\n    // 添加新任务并执行\n    CompletableFuture<String> futureOne = CompletableFuture.supplyAsync(() -> {\n        System.out.println(\"task-one\");\n        return \"task-one\";\n    });\n    CompletableFuture<String> futureTwo = CompletableFuture.supplyAsync(() -> {\n        System.out.println(\"task-two\");\n        return \"task-two\";\n    });\n    CompletableFuture<String> futureThree = CompletableFuture.supplyAsync(() -> {\n        System.out.println(\"task-three\");\n        return \"task-three\";\n    });\n\n    // 等待所有任务执行完成\n    futureOne.thenCompose(res1->{\n        System.out.println(\"task-one的任务结果为：\"+res1);\n        System.out.println(\"task-one 回调函数已经执行\");\n        return futureTwo.thenCompose(res2->{\n            System.out.println(\"task-two的任务结果为：\"+res2);\n            System.out.println(\"task-two 回调函数已经执行\");\n            return futureThree.thenAccept(res3->{\n                System.out.println(\"task-three的任务结果为\"+res3);\n                System.out.println(\"task-three 回调函数已经执行\");\n            });\n        });\n    });\n\n```\n### 控制主任务的执行顺序（回调函数套娃）\n```java\n    CompletableFuture<String> futureOne = CompletableFuture.supplyAsync(() -> {\n        System.out.println(\"task-one\");\n        return \"task-one\";\n    });\n    CompletableFuture<String> futureTwo = futureOne.thenApply(res1 -> {\n        System.out.println(\"task-two\");\n        return \"task-two\";\n    });\n    CompletableFuture<String> futureThree = futureTwo.thenApply(res2 -> {\n        System.out.println(\"task-three\");\n        return \"task-three\";\n    });\n```","categories":["TechStack"],"tags":[]},{"title":"Online-bug","url":"/posts/45986/","content":">线上bug的排查\n<!--more-->\n# 常见的线上bug\n## 大对象\n>系统一次性加载了过多数据到内存中（比如SQL查询未做分页），导致大对象进入了老年代\n## 内存泄漏\n>频繁创建了大量对象，但是无法被回收（比如IO对象使用完后未调用close方法释放资源），先引发FGC，最后导致OOM\n## JVM参数设置\n>包括总内存大小、新生代和老年代的大小、Eden区和S区的大小，设置的不够合理\n## 程序频繁生成一些长生命周期的对象\n>当这些对象的存活年龄超过分代年龄时便会进入老年代，最后引发FGC\n\n\n\n# JVM参数\n> 打印GC日志：  \n>- XX：+PrintGCDetails\n>- XX：+UseConcMarkSweepGC  \n>堆的最小大小：  \n>- Xms20m  \n>堆的最大大小：  \n>- Xmx20m  \n> 当 OutOfMemoryError 发生时自动生成 Heap Dump 文件  \n>- XX：+HeapDumpOnOutOfMemoryError  \n> 当 JVM 执行 FullGC 前执行 dump  \n>- XX：+HeapDumpBeforeFullGC  \n> 当 JVM 执行 FullGC 后执行 dump    \n>- XX：+HeapDumpAfterFullGC  \n> 指定 dump 文件存储路径\n>- XX：HeapDumpPath=/home/dumps\n\n\n# JVM命令\n## jmap\n### 下载dump文件\n#### 命令解释\n>- 使用jdk的jmp命令导出dump文件\n>- format=b表示文件是二进制文件\n>- file是指定dump文件的下载地址\n#### 命令\n>jmap -dump:format=b,file=/home/dumps 进程pid\n\n### 查看当前的活动对象\n#### 命令解释\n>- histo:live表示生成直方图时只考虑活动对象\n#### 命令\n>jmap -histo:live pid\n>- - - \n## jstat\n### 查看当前堆内存各部分的使用量\n>- gc是查看要监视的是垃圾收集相关的统计信\n>- 1000是指每1000ms输出一次\n>- 10是指一共输出10次\n### 命令\n>jstat -gc 进程pid 1000 10 \n\n### 查看堆内存各部分的使用情况，百分比\n### 命令\n>jstat -gcutil 进程pid 1000 10\n\n### 类加载统计\n#### 输出结果解释\n>- Loaded: 加载class的数量\n>- Bytes：所占用空间大小\n>- Unloaded：未加载数量\n>- Bytes: 未加载占用空间\n>- Time：时间\n#### 命令\n>- jstat -class pid\n\n\n# MAT可视化分析\n## Histogram 对象占用内存直方图\n## Dominator Tree支配树\n\n","categories":["online"],"tags":[]},{"title":"vue-knowledge","url":"/posts/52840/","content":">关于vue的一些知识\n<!--more-->\n# vue脚手架的安装与启动\n1. 安装：yarn global add @vue/cli\n2. 查看版本：vue --version\n3. 创建一个vue项目：vue create project_name\n4. 启动vue项目：yarn serve\n> 注：如果是别人的项目，在启动之前需要npm install一下，安装一下别人项目中的其他依赖\n","categories":["vue"],"tags":[]},{"title":"创业笔记","url":"/posts/2279/","content":"# 创业思路\n## 随记\n- 赚后端的钱，不要赚前端的钱\n    - 比如说软件开发，开发钱很便宜，运营费很贵\n    - 比如说开ktv，300块钱包一个月的酒水，水果免费，但是点陪唱等隐形消费可以带来更多收益\n\n- 可以在职开办公司，在公司收益是个人收益的2倍以上了，就可以考虑all in了\n\n\n","categories":[],"tags":[]},{"title":"AC-cron","url":"/posts/45793/","content":">xxl-job的cron表达式的总结如下\n<!--more-->\n- */5 * * * * ? 每隔5秒执行一次\n- 0 */1 * * * ? 每隔1分钟执行一次\n- 0 0/3 * * * ? 每隔三分钟触发一次\n- 0 0 5-15 * * ? 每天5-15点整点触发\n- 0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发 \n- 0 0/5 14 * * ? 在每天下午2点到下午2:55期间的每5分钟触发\n- 0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发\n- 0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时\n- 0 0 10,14,16 * * ? 每天上午10点，下午2点，4点 \n- 0 0 12 ? * WED 表示每个星期三中午12点\n- 0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点\n- 0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发 \n- 0 15 10 ? * MON-FRI 周一至周五的上午10:15触发\n- 0 0 23 L * ? 每月最后一天23点执行一次\n- 0 15 10 L * ? 每月最后一日的上午10:15触发 \n- 0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 \n- 0 15 10 * * ? 2005 2005年的每天上午10:15触发 \n- 0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发 \n- 0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发\n- \"30 * * * * ?\" 每半分钟触发任务\n- \"30 10 * * * ?\" 每小时的10分30秒触发任务\n- \"30 10 1 * * ?\" 每天1点10分30秒触发任务\n- \"30 10 1 20 * ?\" 每月20号1点10分30秒触发任务\n- \"30 10 1 20 10 ? *\" 每年10月20号1点10分30秒触发任务\n- \"30 10 1 20 10 ? 2011\" 2011年10月20号1点10分30秒触发任务\n- \"30 10 1 ? 10 * 2011\" 2011年10月每天1点10分30秒触发任务\n- \"30 10 1 ? 10 SUN 2011\" 2011年10月每周日1点10分30秒触发任务\n- \"15,30,45 * * * * ?\" 每15秒，30秒，45秒时触发任务\n- \"15-45 * * * * ?\" 15到45秒内，每秒都触发任务\n- \"15/5 * * * * ?\" 每分钟的每15秒开始触发，每隔5秒触发一次\n- \"15-30/5 * * * * ?\" 每分钟的15秒到30秒之间开始触发，每隔5秒触发一次\n- \"0 0/3 * * * ?\" 每小时的第0分0秒开始，每三分钟触发一次\n- \"0 15 10 ? * MON-FRI\" 星期一到星期五的10点15分0秒触发任务\n- \"0 15 10 L * ?\" 每个月最后一天的10点15分0秒触发任务\n- \"0 15 10 LW * ?\" 每个月最后一个工作日的10点15分0秒触发任务\n- \"0 15 10 ? * 5L\" 每个月最后一个星期四的10点15分0秒触发任务\n- \"0 15 10 ? * 5#3\" 每个月第三周的星期四的10点15分0秒触发任务","categories":["Accumulate"],"tags":["Cron表达式"]},{"title":"boot-Security-module","url":"/posts/37425/","content":">SpringSecurity的组件集合\n<!--more-->\n- Authentication：表示用户的身份认证信息，包括用户名、密码、权限等信息。\n- AuthenticationManager：用于对用户的身份认证进行管理，包括对用户身份进行认证、验证用户的身份信息等。\n- AccessDecisionManager：用于进行访问决策管理，根据用户的身份信息和访问控制信息，判断用户是否有权限访问该资源。\n- FilterSecurityInterceptor：用于在请求被处理之前进行安全拦截，根据访问控制信息判断用户是否有权限访问该资源。\n- AuthenticationEntryPoint：用于处理未经身份认证的用户访问受保护的资源时的操作，如重定向到登录页面等。\n- AccessDeniedHandler：用于处理用户没有访问权限时的操作，如重定向到错误页面等。\n- AbstractSecurityInterceptor：用于对请求进行拦截和处理，是 FilterSecurityInterceptor 的父类。\n- AuthenticationProvider：用于对用户的身份进行认证，与 AuthenticationManager 类似，但可以实现多种认证方式，如用户名密码认证、LDAP 认证等。\n- UserDetailsService：用于在认证过程中根据用户名加载用户信息，包括用户名、密码、权限等信息。\n- UserDetails：用于存储用户的详细信息，包括用户名、密码、权限等信息。通常由 UserDetailsService 返回，作为 Authentication 对象的一部分。\n- RememberMeServices：用于处理“记住我”功能，当用户勾选“记住我”选项时，该服务将生成一个记住令牌并存储在用户的浏览器中，以便在下次访问该应用程序时自动登录。\n- RememberMeAuthenticationToken：用于在用户登录时，通过“记住我”功能，在用户下次访问该应用程序时，可以直接使用该令牌来自动登录。\n- HttpSessionRequestCache：用于将当前请求缓存到 HttpSession 中，以便在用户登录成功后，从缓存中获取原始请求并重定向。\n- SecurityContextHolder：用于存储当前用户的身份信息，以便在应用程序的任何地方都可以访问用户的身份信息。\n- SessionRegistry：用于管理应用程序中所有用户的会话信息，包括会话 ID、用户名等信息，以便在用户注销或超时时进行清理。\n- CsrfFilter：用于防止 CSRF 攻击，在请求中添加随机生成的 token，并在处理请求时验证该 token。\n- CsrfTokenRepository：用于存储 CSRF 令牌并验证 CSRF 攻击。\n- CsrfToken：用于表示 CSRF 令牌，包括令牌的值、过期时间等信息。\n- HttpSecurity：用于配置应用程序的安全策略，包括访问控制、认证方式、CSRF 防护等。\n- WebSecurityConfigurerAdapter：用于配置应用程序的安全策略，可以通过继承该类并重写其中的方法，来实现自定义的安全策略。\n- UserDetailsPasswordService：用于在用户修改密码时，更新用户的密码信息。\n- PasswordEncoder：用于加密用户的密码，保证用户密码的安全性。\n- GrantedAuthority：用于表示用户的权限信息。\n- SecurityExpressionRoot：用于解析 Spring Security 中的表达式，以便在访问控制中使用。\n- SecurityMetadataSource：用于从应用程序中的配置信息中获取访问控制信息，包括 URL、角色等信息。\n- FilterInvocationSecurityMetadataSource：用于从应用程序中的配置信息中获取访问控制信息，并与请求的 URL 进行匹配，以确定是否允许访问该资源。 这些组件共同构成了 Spring Security 的框架，通过它们的协作，可以实现对应用程序的安全保护。\n","categories":["SpringSecurity"],"tags":[]},{"title":"Recruitment-C-1-1","url":"/posts/10694/","content":">招聘系统C端需求1.0\n<!--more-->\n# 需求描述\n>要求投递简历之后，自动给HR发送提醒邮件，提醒HR及时处理\n","categories":["Requirements"],"tags":[]},{"title":"Recruitment-B-1-1","url":"/posts/59899/","content":">招聘系统B端需求-1.0：添加发送感谢信\n<!--more-->\n# 需求描述\n>当面试拒绝候选者之后，由HR点击发送感谢信按钮，给指定的人发送感谢邮件\n","categories":["Requirements"],"tags":[]},{"title":"StudyPlan","url":"/posts/27686/","content":">指定当前的学习计划！不能被实习影响到秋招！\n<!--more-->\n# 初步计划\n## 时间\n>2023年8.28日起\n## 计划\n- 深入了解设计模式\n- 了解 xxl-job 和 SpringSchdule 的区别\n- 了解 Caffine 和 SpringCache 的区别：http://www.taodudu.cc/news/show-1352640.html?action=onClick\n- 初步了解ES的原理\n- 复习JavaSE、JavaWeb\n- 复习Spring全家桶的知识，尤其是原理性的\n- 复习MySQL、Redis的原理，包括集群配置\n\n\n# 算法计划\n## 时间\n>2023.8.28起\n## 计划\n1. 每周至少3题中等，2题简单\n2. 默写快速排序算法","categories":["Interview"],"tags":["学习计划"]},{"title":"Requirements-Recruitment-System","url":"/posts/38530/","content":">招聘系统更新文档\n<!--more-->\n# C端\n## 玉环C端-1.1\n- 更新内容：\n    - 新增功能：投递简历之后，系统自动发送邮件给HR，提醒HR尽快处理\n\n# B端\n\n\n","categories":["Requirements"],"tags":["Requirements"]},{"title":"AC-Docker","url":"/posts/54426/","content":">关于Docker的相关信息\n<!--more-->\n# 容器基本命令\n- mysql\n    - docker exec -it mysql bash 进入到容器中\n    - docker run -d --name=mysql_container -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root mysql8.0.25 启动mysql\n\n\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'root';\n\nALTER USER root@192.168.43.21 IDENTIFIED WITH mysql_native_password BY 'root';\n\n\n## 实例命令\n- 删除实例：docker rm containerID\n- 查看实例\n  - docker ps 只有当前存活的实例\n  - docker ps -a 所有实例，包括没运行的\n  - 不省略字段信息，全展示：docker ps -a --no-trunc\n\n## 镜像命令\n- 删除镜像\n  - docker rmi imageID\n  - docker rmi -f imageID 强制删除\n- 查看镜像\n  - docker images 查看所有镜像\n\n## 部署SpringBoot项目 \n### 首次部署\n- 打包当前目录，DockerFile就在当前目录：docker build -t 镜像名 . \n- 创建实例并运行,-d是后台运行，-p是指定映射端口号：docker run -d -p 2999:2999 镜像ID\n- 查看日志：docker logs + 镜像ID\n  - --details 显示提供给日志的其他详细信息\n  - --follow , -f 实时跟踪日志输出\n  - --since 显示自某个timestamp之后的日志大于等于某个时间，或相对时间，如1h 就是1h）\n  - --tail , -n all 从日志末尾显示的行数，默认值为all 全部\n  - --timestamps , -t 日志每行显示日志时间戳\n  - --until 显示自某个timestamp之前的日志小于等于某个时间，或相对时间，如30m（即30分钟）\n\n### 替换Jar包\n- docker stop containerID #停止容器实例\n- docker ps -a containerID # 查看docker中的所有容器实例，包括已经停止运行了的\n- docker cp web-erp-1.0-SNAPSHOT.jar containerID:/opt/app/web-erp-1.0-SNAPSHOT.jar #将宿主机的文件复制到容器中\n- docker start containerID #运行容器实例\n\n### nohup部署，可远程JVM来DEBUG \n- nohup java -Xdebug -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -jar web-erp-1.0-SNAPSHOT.jar &\n\n## 部署xxl-job\n>* 拉取：docker pull xuxueli/xxl-job-admin:2.3.1\n>* 运行(mysql也是使用docker部署的，且容器name为mysql)：docker run -d -e PARAMS=\"--spring.datasource.url=jdbc:mysql://mysql:3306/xxl_job?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true --spring.datasource.username=root --spring.datasource.password=060119 --spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\" -p 8282:8080 -v /tmp:/data/applogs --name xxl-job-admin  -d --link mysql:mysql  xuxueli/xxl-job-admin:2.3.1\n>* 运行(mysql可以不使用docker部署)\n```sh\n  docker run -d \\\n  -e PARAMS=\"--spring.datasource.url=jdbc:mysql://jcqing.cc:13306/xxl_job?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true \\\n  --spring.datasource.username=xtzl \\\n  --spring.datasource.password=xtzlabc \\\n  --spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\" \\\n  -p 8282:8080 \\\n  -v /tmp:/data/applogs \\\n  --name xxl-job-admin \\\n  -d \\\n  xuxueli/xxl-job-admin:2.3.1\n```\n\n# 命令图\n<img src= \"http://xtzl.wentexl.cn/docker.png\"/>\n\n# docker数据卷\n## 相关命令\n- 创建数据卷：docker volume create\t\n- 查看所有数据卷：docker volume ls\t\n- 删除指定数据卷：docker volume rm\t\n- 查看某个数据卷的详情：docker volume inspect\t\n- 清除数据卷：docker volume prune\t\n\n\n# 添加docker的镜像\n## 修改daemon.json文件\n## 查看DNS\n> dig @114.114.114.114 registry-1.docker.io\n## 添加hosts解析\n> vim /etc/hosts\n\n34.226.69.105","categories":["Accumulate"],"tags":[]},{"title":"boot-Cache","url":"/posts/21114/","content":">总结关于了Spring自带的Cache缓存的原理及应用\n<!--more-->\n# 原理\n# 应用\n## @Cacheable\n>先从value中获取为key的缓存，如果存在直接返回；如果不存在则执行方法并返回，且把返回输出存入缓存。（注意：保存的数据是return返回的数据）\n- 参数\n    - value : 缓存组件名\n    - key : 缓存Key，支持SpEL\n    - condition： 缓存条件，支持SpEL，要求返回布尔类型\n    - unless: 除了，表示不满足其中的条件才返回true\n\n## @CachePut\n>根据value中获取为key的缓存，如果存在则修改；不存在则新增,保存的数据是return返回的数据\n- 参数\n    - value : 缓存组件名\n    - key : 缓存Key\n    - condition : 缓存条件\n\n## @CacheEvict\n>是用来标注在需要清除缓存元素的方法或类上的，当标记在一个类上时表示其中所有的方法的执行都会触发缓存的清除操作。\n- 参数\n  - value: 缓存组件名\n  - key : 缓存Key\n  - condition : 缓存条件\n  - allEntries: 是否需要清除缓存中所有元素，默认false\n  - beforeInvocation : 当为true的时候，会在执行对应方法之前执行清除缓存的操作\n\n## @Caching\n> @Caching注解可以让我们在一个方法或者类上同时指定多个Spring Cache相关的注解。其拥有三个属性：cacheable、put和evict，分别用于指定@Cacheable、@CachePut和@CacheEvict。","categories":["SpringBoot"],"tags":[]},{"title":"boot-Security-Filter","url":"/posts/30634/","content":">关于SpringSecurity的相关知识点\n<!--more-->\n>Spring Security核心就是一组过滤器链，每个过滤器实现一个独立功能，用户请求通过滤器链进行登录、授权、权限校验等操作，最终执行目标服务。\n<img src=\"https://img-blog.csdnimg.cn/6a3b6638e2d44fbda13c928ad1a56519.png\"/>\n\n# 常用过滤器\n## 基本过滤器\n### SecurityContextPersistenceFilter\n>首当其冲的一个过滤器，非常重要,主要是使用SecurityContextRepository在session中保存或更新一个SecurityContext，并将SecurityContext给以后的过滤器使用，来为后续filter建立所需的上下文，SecurityContext中存储了当前用户的认证和权限信息。 \n## 登录登出过滤器\n### AbstractAuthenticationProcessingFilter\n>处理form登录的过滤器，与form登录有关的所有操作都是在这里进行的，登陆时判断用户名密码是否有效，有效的话就跳转到成功页面\n### LogoutFilter\n>只处理注销请求，在发生注销请求时，销毁注销用户的Session，清空SecurityContextHolder，然后重定向到注销成功页面\n## 权限过滤器\n### FilterSecurityInterceptor\n>用户的权限控制都包含在这个过滤器中\n>功能是：1.如果用户尚未登陆就抛出尚未登录的异常 2.如果用户已经登录但是没有访问当前资源的权限，那么会抛出拒绝访问的异常 3.用户已登录也具有访问当前资源的权限就放行\n### AnonymousAuthenticationFilter\n>用于保证用户没有登录时，为用户分配匿名用户的权限\n","categories":["SpringSecurity"],"tags":[]},{"title":"MQ-Kafka","url":"/posts/9270/","content":">关于Kafka的知识点\n<!--more-->\n# 架构图\n<img src=\"http://xtzl.wentexl.cn/Kafka%E6%9E%B6%E6%9E%84%E5%9B%BE.png\">\n\n","categories":["MessageQueue"],"tags":[]},{"title":"boot-globalExceptionHandler","url":"/posts/600/","content":"> 全局异常处理器\n<!--more-->\n# 枚举类\n> 通过使用枚举类完成对返回错误的统一定义，结合全局异常管理器实现全局的异常处理\n```java\npublic enum ErrorCode {\n    /* 成功 */\n    SUCCESS(200, \"成功\"),\n\n    /* 默认失败 */\n    COMMON_FAIL(999, \"失败\"),\n\n    /* 参数错误：1000～1999 */\n    PARAM_NOT_VALID(1001, \"参数无效\"),\n    PARAM_IS_BLANK(1002, \"参数为空\"),\n    PARAM_TYPE_ERROR(1003, \"参数类型错误\"),\n    PARAM_NOT_COMPLETE(1004, \"参数缺失\"),\n\n    /* 用户错误 */\n    USER_NOT_LOGIN(2001, \"用户未登录\"),\n    USER_ACCOUNT_EXPIRED(2002, \"账号已过期\"),\n    USER_CREDENTIALS_ERROR(2003, \"密码错误\"),\n    USER_CREDENTIALS_EXPIRED(2004, \"密码过期\"),\n    USER_ACCOUNT_DISABLE(2005, \"账号不可用\"),\n    USER_ACCOUNT_LOCKED(2006, \"账号被锁定\"),\n    USER_ACCOUNT_NOT_EXIST(2007, \"账号不存在\"),\n    USER_ACCOUNT_ALREADY_EXIST(2008, \"账号已存在\"),\n    USER_ACCOUNT_USE_BY_OTHERS(2009, \"账号下线\"),\n\n    /* 业务错误 */\n    NO_PERMISSION(3001, \"没有权限\"),\n    Anonymous_Access(3002,\"匿名用户访问异常\");\n    private Integer code;\n    private String message;\n\n    ErrorCode(Integer code, String message) {\n        this.code = code;\n        this.message = message;\n    }\n\n    public Integer getCode() {\n        return code;\n    }\n\n    public void setCode(Integer code) {\n        this.code = code;\n    }\n\n    public String getMessage() {\n        return message;\n    }\n\n    public void setMessage(String message) {\n        this.message = message;\n    }\n}\n```\n# 自定义异常\n> 如果Java.net包下的异常够用也不用自定义异常，自定义异常主要是用于扩展使用\n```java\npublic class AnonymousAccessException extends RuntimeException{\n    private final Integer code = ErrorCode.Anonymous_Access.getCode();\n    private final String message = ErrorCode.Anonymous_Access.getMessage();\n\n    public Integer getCode() {\n        return code;\n    }\n    @Override\n    public String getMessage() {\n        return message;\n    }\n}\n```\n\n# 使用全局异常管理器\n> 在这里可以对捕获的所有的异常进行一个统一的管理和处理\n```java\n@ControllerAdvice\npublic class GlobalExceptionHandler {\n    /**参数校验异常*/\n    @ExceptionHandler(BindException.class)\n    public Result bindException(BindException e) {\n        return  ResultTool.failWithMessage(e.getMessage());\n    }\n    /**自定义匿名异常*/\n    @ExceptionHandler(AnonymousAccessException.class)\n    public Result anonymousException(AnonymousAccessException e){\n        return ResultTool.failWithCodeAndMessage(e.getCode(),e.getMessage());\n    }\n}   \n```","categories":["SpringBoot"],"tags":[]},{"title":"BigData-Spark","url":"/posts/51645/","content":"<!--more-->\n# RDD\n- 创建\n    - val rdd = parallelize(list) 可通过数据结构直接生成RDD\n    - val rdd = textFile(path) 可读取外部文件来生成RDD\n\n","categories":[],"tags":[]},{"title":"sql-optimize","url":"/posts/32679/","content":">关于SQL优化的相关信息，顺便包括了SqlYog的破解流程\n<!--more-->\n# 基础Sql优化\n- 查询SQL尽量不要使用select *，而是具体字段\n- 避免在where子句中使用or来连接条件\n- 使用varchar代替char\n- 尽量使用数值替代字符串类型\n- 查询尽量避免返回大量数据\n- 使用explain分析你SQL执行计划\n- 是否使用了索引及其扫描类型\n- 创建name字段的索引\n- 优化like语句\n- 字符串怪现象\n- 索引不宜太多，一般5个以内\n- 索引不适合建在有大量重复数据的字段上\n- where限定查询的数据\n- 避免在索引列上使用内置函数\n- 避免在where中对字段进行表达式操作\n- 避免在where子句中使用!=或<>操作符\n- 去重distinct过滤字段要少\n- where中使用默认值代替null\n    \n\n# 高级SQL优化\n- 批量插入性能提升\n- 批量删除优化\n- 伪删除设计\n- 提高group by语句的效率\n- 复合索引最左特性\n- 排序字段创建索引\n- 删除冗余和重复的索引\n- 不要有超过5个以上的表连接\n- inner join 、left join、right join，优先使用inner join\n- in子查询的优化\n- 尽量使用union all替代union\n\n\n\n# Expain解析\n## 重点字段\n>possible_keys、key、Extra、type\n## type字段\n>system > const > eq_ref > ref > range > index > all\n## Extra\n- Using index：使用覆盖索引（如果select后面查询的字段都可以从这个索引的树中获取，不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值，这种情况一般可以说是用到了覆盖索引）。\n- Using where：使用 where 语句来处理结果，并且查询的列未被索引覆盖。\n- Using index condition：查询的列不完全被索引覆盖，where条件中是一个查询的范围。\n- Using temporary：MySQL需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的。\n- Using filesort：将使用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序。\n- Select tables optimized away：使用某些聚合函数（比如 max、min）来访问存在索引的某个字段时。\n\n\n\n\n# Sqlyog的破解流程\n## 路径 （注册表编辑器regedit）\n>计算机\\HKEY_CURRENT_USER\\SOFTWARE\\{d58cb4b1-47f3-45cb-a209-f298d0c3f756}\n## 路径变量\n>InD110\n## 修改方案\n>* 直接删除InD110这个变量，即可重置为14天\n>* 将10进制数值修改为2460107，即可重置为14天\n","categories":[],"tags":[]},{"title":"","url":"/posts/0/","content":"","categories":[],"tags":[]},{"title":"Interview","url":"/posts/41865/","content":">面试八股文与项目介绍\n<!--more-->\n# Java八股文\n## Java及Web基础\n1. 元空间: Java 8中引入了元空间的概念，将类元数据存储在本地内存中，而不再是永久代。这种方式使得类元数据的管理更加灵活和高效，可以避免永久代出现的问题，如内存溢出、GC时间过长等。\n\n2. Get、Post、Put的区别\n    - 数据位置：GET方法将请求参数附加在URL的查询字符串中，而POST方法将请求参数放在请求的消息体中。由于URL长度的限制，GET方法的参数传输通常会受到一定的限制。\n    - 安全性：由于GET方法将请求参数暴露在URL中，因此请求的安全性较低，容易被攻击者截获和窃取。而POST方法将请求参数放在消息体中，相对来说更为安全。\n    - 可缓存性：GET方法通常可以被缓存，因为它的请求参数以及URL是不变的。而POST方法的请求参数会影响服务器的状态，不能被缓存。\n    - 幂等性：GET方法是幂等的，即多次请求同一个URL的结果相同，不会对服务器状态产生影响。而POST方法通常不是幂等的，多次请求同一个URL可能会导致服务器状态的改变。\n    - 用途：GET方法主要用于获取资源，POST方法主要用于提交数据。例如，用GET方法可以请求一个HTML页面或图像文件，用POST方法可以提交一个表单。\n    - PUT请求：\n        - 如果服务器上已经存在了一个资源，并且客户端发送了一个PUT请求，那么服务器将用客户端上传的新资源替换原有的资源。如果服务器上不存在该资源，则会创建一个新的资源。\n        - PUT请求通常需要在请求头中指定上传的资源的URI和一些元数据，以便服务器正确处理请求。\n        - 与POST请求不同，PUT请求的请求体中通常包含完整的资源内容，而不是仅包含部分数据或请求参数。\n        - PUT请求可能会导致服务器上的数据被覆盖或删除，因此在使用PUT请求时需要谨慎处理，避免意外修改或删除重要数据。\n    \n3. Cookie和Session的区别\n    - 存储位置：Cookie是保存在客户端浏览器中的，而Session是保存在服务器端的。\n    - 安全性：Cookie中的数据可以被客户端浏览器拦截并篡改，因此不适合保存敏感数据，而Session保存在服务器端，可以保证数据的安全性。\n    - 存储容量：Cookie存储容量比较小，通常只能存储几KB的数据，而Session存储容量较大，可以存储几MB的数据。\n    - 生命周期：Cookie有一个过期时间，如果没有设置过期时间，则默认为浏览器关闭时失效，而Session的生命周期由服务器管理，默认情况下，Session在30分钟内无任何操作时会失效。\n\n4. 动态代理\n    - jdk动态代理 : 首先说适用场景吧，jdk动态代理是适用于代理那些已经实现过接口的类，在执行其方法的前后，可以添加一些额外的逻辑。其具体的实现主要是通过Java的反射机制来动态地创建一个代理对象，这个代理对象需要拿到目标对象的引用及其接口的类信息，它会实现InvocationHandler接口，并通过invoke方法作为进入目标对象的目标方法的入口，由此呢，就可以在调用invoke方法之前实现调用目标方法前的逻辑，在调用invoke方法之后实现调用目标方法后的逻辑。\n    - cglib动态代理: CGLIB动态代理主要用于代理那些没有实现接口的类，它通过生成目标类的子类来实现代理。具体实现是使用了ASM字节码生成技术，来生成字节码并动态创建子类。通过继承目标类，代理类继承了目标类的行为，并重写了目标类的方法，以实现自定义的代理逻辑。\n    - 对比：JDK动态代理适用于代理已经实现了接口的类，而CGLIB动态代理则可以用于代理未实现接口的类，相比JDK动态代理，CGLIB代理通常会稍微慢一些，因为它涉及到动态生成子类的过程。\n    - Spring中的使用\n        - SpringAoP(jdk动态代理)：使用jdk动态代理来实现横切关注点的切入。通过代理生成机制，Spring可以在运行时动态地为目标对象创建代理对象，并在目标对象的方法执行前后插入额外的逻辑，如日志记录、性能监控。\n        - 事务管理(jdk动态代理)：Spring的声明式事务管理就是通过动态代理来实现的。通过在配置文件或注解中声明事务管理的规则，Spring会在运行时为标记了事务注解的方法创建代理对象，在方法执行前后进行事务的开启、提交或回滚操作。\n        - 缓存管理(cglib动态代理)：Spring的缓存管理模块也使用了动态代理。通过在方法上添加缓存注解，Spring会在运行时为带有缓存注解的方法生成代理对象，并在方法执行前先从缓存中查找数据或将执行结果存入缓存中，从而提高系统的性能。\n\n5. 面向对象和面向过程\n    - 面向对象(Java): 将现实世界中的事物抽象成一个个对象，对象包括属性和方法。对象的属性用来描述对象的状态，方法用来描述对象的行为。在面向对象编程中，程序员将不同的对象进行组合，形成一个完整的系统。\n    - 面向过程(C语言): 是一种基于函数的编程方法，将一个大问题分解为一系列小问题，每个小问题都可以使用一个函数来解决。在面向过程编程中，程序员关注的是程序中的函数，函数之间通过参数传递数据，函数中的变量也只在函数内部有效。\n\n6. Java的四大引用\n    - 强引用（Strong Reference）：当程序中存在一个强引用时，垃圾回收器将不会回收该对象，只有在该对象的所有强引用都被释放时，垃圾回收器才会将该对象回收。通常使用的对象都是强引用。\n    - 软引用（Soft Reference）：软引用是一种比较弱化的强引用，当内存不足时，垃圾回收器会根据一定的策略（通常是LRU算法）来回收软引用所指向的对象。软引用通常用于实现内存敏感的缓存。\n    - 弱引用（Weak Reference）：当一个对象只被弱引用引用时，垃圾回收器在进行垃圾回收时，如果该对象没有被任何强引用引用，那么就会将该对象回收。弱引用通常用于解决内存泄漏问题。\n    - 虚引用（Phantom Reference）：虚引用是Java中最弱的一种引用类型，它的作用是在对象被垃圾回收器回收时，收到一个系统通知。虚引用通常用于跟踪对象被垃圾回收器回收的时机，或者在对象被回收时执行一些自定义的清理操作。\n\n7. 重写和重载\n    - 重写\n        - 重写方法的方法名，方法参数要与父类相同，返回类型可以是父类返回值类型的子类\n        - 重写方法的访问修饰符更宽松。例如，如果被重写方法是公共方法，则重写方法不能是私有方法\n        - 重写方法不能抛出更广泛的异常。重写方法必须抛出相同的异常或其子类型异常。但是，重写方法可以抛出未检查的异常，即 RuntimeException 以及其子类型异常\n    - 重载\n        - 同一个类中定义的多个方法，它们具有相同的方法名\n        - 参数列表必须不同，返回类型可以不同\n\n8. String、StringBuffer、StringBuilder\n    - 可变性\n        - String是定长字符串，不可变\n        - StringBuffer和StringBuilder可变\n    - 线程安全性\n        - String是定长字符串，线程安全\n        - StringBuffer线程安全，因为每个操作都用synchronized同步关键字修饰\n        - StringBuilder线程不安全\n    - 性能效率\n        - String的性能最低，因为每次发生字符串拼接和修改的时候，都需要创建新的对象和分配内存\n        - StringBuilder在单线程的性能更高，多线程的性能低于StringBuffer\n    - 存储位置\n        - String存储在字符串常量池\n        - StringBuffer和StringBuilder存储在堆内存中\n9. Java的IO模型\n    - IO 同步阻塞模型（BIO）：当一个线程执行IO操作时，它将被阻塞，直到IO操作完成。在阻塞状态下，线程无法执行其他任务，因此一个线程只能处理一个IO操作。\n    - IO 同步非阻塞模型（NIO）：当进行IO操作时，线程可以继续执行其他任务而不需要等待IO操作的完成，基于selctor，一个线程可以同时处理多个IO操作，需要使用循环轮询的方式不断地检查IO操作的状态，以确定是否已经完成\n    - 异步IO模型(AIO)：IO操作的启动和完成是由系统内核来处理，而不需要应用程序的线程主动参与。当应用程序发起一个异步IO操作后，它可以继续执行其他任务，而无需等待IO操作的完成。\n\n10. Java的三大特性\n    - 封装：封装是指将数据和对数据的操作封装在一个类中，通过访问修饰符来控制对数据的访问。封装可以隐藏数据的实现细节，提供统一的接口来访问和操作数据，增加代码的可维护性和安全性。\n    - 继承：继承是指一个类可以继承另一个类的属性和方法。通过继承，子类可以重用父类的代码，并且可以在父类的基础上进行扩展和修改。继承可以建立类之间的层次关系，提高代码的可重用性和扩展性。  \n    - 多态：多态是指同一个方法可以在不同的对象上表现出不同的行为。多态通过方法的重写（覆盖）和方法的重载来实现。通过多态，可以编写更加灵活和通用的代码，提高代码的可扩展性和可维护性。\n\n11. Java的线程调度\n    - 线程优先级：Java线程可以设置优先级，优先级越高，操作系统在调度时倾向于给予该线程更多的CPU时间片。通过Thread.setPriority(int priority)方法设置线程的优先级。\n    - yield()方法：线程可以调用yield()方法，暗示给操作系统一个提示，表示该线程愿意放弃当前的CPU时间片，让其他线程执行。操作系统可以选择忽略该提示。\n    - sleep()方法：线程可以调用sleep()方法，使线程暂停执行一段时间，让其他线程有机会获得执行。\n\n12. Java的常量池、字符串池、对象池\n    - 常量池：Java中的常量池是一种特殊的存储区域，用于存储编译期间确定的常量。常量池分为两种类型，一种是类常量池，用于存储类中的常量，另一种是运行时常量池，用于存储每个线程的常量。常量池中存储的常量包括基本类型、字符串、类、方法和字段等。\n    - 字符串池：Java中的字符串池是用于存储字符串的缓存区域，它可以避免重复创建相同字符串对象。字符串池可以通过String类的intern()方法来访问，当调用intern()方法时，如果字符串池中已经存在相同的字符串，则返回已存在的字符串对象，否则将该字符串对象添加到字符串池中，并返回该字符串对象的引用。\n    - 对象池：Java中的对象池是一种重复使用对象的机制，它可以减少对象创建和销毁的开销，提高程序的性能。对象池通常用于创建、缓存和重复使用频繁创建和销毁的对象，如线程池、连接池和对象缓存池等。\n    - 总结： 总的来说，常量池、字符串池和对象池都是Java虚拟机中的重要概念，它们都是为了提高Java程序的性能和节省内存而设计的。常量池用于存储常量，字符串池用于缓存字符串对象，对象池用于重复使用对象，以减少创建和销毁对象的开销。\n\n13. Java通配符\n    - <? extends Object> 代表上边界限定通配符\n        - 匹配对象：继承自Object的所有对象，即Object的所有子类对象\n        - 用法：直接使用add()方法受限，但可以使用get方法\n\n    - <? super Object> 代表下边界限定通配符\n        - 匹配对象：Object的所有父类对象\n        - 用法：使用get()方法受限，获取到的应该是Object对象，但可以使用add方法\n14. 静态类、静态内部类\n    - 静态内部类\n        - 可以使用权限修饰符来修饰变量或方法\n        - 可以访问其外部类的静态成员，不能访问其外部类的实例成员\n        - 可以独立于其外部类的实例创建\n        - 不会在其封闭类实例被垃圾收集时被自动回收，类加载的时候创建，类销毁的时候销毁\n        - 可以被实例化\n    - 静态类\n        - 关键字不能用static去修饰类，只能用final来表明该类不能被继承，并私有其构造方法，让其不能实例化\n15. 内部类\n    - 共同特性：不能书写静态变量和方法\n    - 成员内部类(写在成员属性的位置)\n        - 可以使用权限修饰符进行修饰\n        - 依附外部类而存在\n\n    - 局部内部类(写在方法内部或者代码块中)\n        - 不可使用权限修饰符\n        - 只能在方法或者代码块内部实例化对象\n\n    - 匿名内部类\n        - 可以使用权限修饰符\n        - 一个匿名内部类通常是在new的后面，用其隐含实现一个接口或实现一个抽象类。\n\n16. Java异常\n    - 异常类型\n    <img src=\"http://xtzl.wentexl.cn/%E5%BC%82%E5%B8%B8.png\"/>\n    - 类型举例\n        - 非检查异常：RunTimeException下的子类，比如空指针异常、类型转换异常、数组越界异常\n        - 检查型异常：IOException、SQLException\n        - 错误：程序无法处理的错误，比如说OutOfMemoryError(内存溢出)、TheadDeath(线程死锁)\n    - 异常处理：try-cat-finally框架\n\n## Spring全家桶框架\n1. SpringIOC和SpringAOP的原理\n    - IOC\n        - DI依赖注入: 通过构造函数、属性或方法参数等方式，将一个对象所依赖的其他对象传递给它，而不是由这个对象自己去创建或查找依赖的对象。这样做的好处是，我们可以更灵活地管理和替换这些依赖\n        - IC控制反转: 控制反转的核心思想是将对象的创建和管理交给容器或框架，而不是由程序员自己手动创建和管理对象。这样做的好处是可以将对象的生命周期和作用域管理交给框架或容器，从而避免了一些常见的问题，比如对象的重复创建、对象的生命周期管理等等。\n    - AOP\n        - 面向切面的技术：所谓“切面”，简单说就是那些与业务无关，却被业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。\n        - 通知执行顺序\n            1. 环绕通知前\n            2. @Before通知\n            3. 程序逻辑\n            4. @AfterReturning通知 或者 @AfterThrowing异常通知\n            5. @After通知\n            6. 环绕通知后\n            \n\n2. Spring的三级缓存\n    - 三级缓存\n        - 一级缓存：存放已经创建完成的Bean\n        - 二级缓存：存放早起创建但是未填充属性的Bean，或者是代理对象\n        - 三级缓存：存放ObjectFactory这样的Bean的工厂对象，负责动态的创建和管理Bean\n    - <img src=\"http://xtzl.wentexl.cn/%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98.png\"/>\n    - 解决循环依赖的流程\n        1. A对象实例化并将对象工厂放入到三级缓存\n        2. A对象依赖注入发现B对象也需要创建\n        3. B对象实例化并将对象工厂放入到三级缓存\n        4. B对象依赖注入发现循环依赖(一级和二级缓存都拿不到实例)，调用A对象的对象工厂的getObject方法\n        5. A的工厂对象的getObject方法内部判断A对象是否被代理过，如果未被代理过，则返回A对象的实例，如果被代理过，则返回一个新的代理对象，并将未初始化的实例对象或代理对象放入二级缓存。\n        6. B对象依赖注入成功，进入初始化，初始化完成之后将B对象放入一级缓存，并删除B对象的在三级缓存的工厂对象\n        7. A拿到B的实例对象并继续初始化\n        8. A和B都初始化完成\n    - 为什么一定要是三级缓存，二级缓存不行吗？\n        - 答案：如果A对象没有被代理，则可以。如果A对象被代理过，则不行\n        - 理由：如果A和B，A和C都是循环依赖，那在解决循环依赖的时候，在A的对象工厂调用getObject的时候，就会生成并注入两个不同的A的代理对象，这就造成了对象的重复创建\n\n3. Spring占位符\n    - '#' : #占位符会对输入的参数值进行类型转换，防止SQL注入攻击。\n    - '$' : $占位符在SQL语句中直接替换成输入的参数值，它不会对输入的参数值进行类型转换，也不会防止SQL注入攻击\n\n4. RPC框架\n    - 理解：RPC是一种用于实现分布式系统间通信的协议和技术，通过隐藏底层的网络通信细节，它允许一个服务通过网络请求另一个计算机上的服务或函数，在使应用程序能够像调用本地函数一样调用远程服务,并获取结果，实现协同工作和资源共享。和http不同的是，HTTP是一种用于客户端和服务器之间的通信的协议，主要用于Web应用程序的数据传输。\n    - 好处：\n        - 抽象化通信：RPC隐藏了底层网络通信的细节，使得开发者可以将重点放在业务逻辑上，而不用关心底层的网络通信实现。\n        - 分布式系统的协作：RPC可以方便地在分布式系统中调用远程服务，使得不同的系统能够协同工作，共享资源和功能。\n        - 跨语言和跨平台支持：RPC协议可以在不同的编程语言和平台上使用，使得不同技术栈的系统能够互相通信。\n    \n    - SpringCloud\n        - 注册中心: Ereuka、Zookeeper、Nacos、Consul\n        - 服务调用: restTemplate、OpenFeign\n        - 服务降级：Hystrix、Sentinel\n        - 服务配置：Nacos、Config\n        - 服务网关：GateWay\n        - 服务总线：Bus、Nacos\n    - Hadoop\n        - HDFS\n        - MapReduce\n    - Spark\n        - 执行流程：\n            1. 根据RDD依赖关系 -> DAG流程图 ---(DAGScheduler)--> Stage ----(TaskScheduler)--> tasks\n            2. Executor  ---(申请任务)--> SparkContext、 任务调度器 ----(分发任务)---> Executor\n\n5. 设计模式\n    - 模式\n        - 工厂模式（Factory Pattern）：Spring中使用工厂模式来实现对象的创建和管理，例如BeanFactory和ApplicationContext就是工厂模式的典型实现。\n            - 简单工厂：一个抽象产品类和一个具体工厂类\n            - 工厂方法：一个抽象产品类和一个抽象工厂类\n            - 抽象工厂：多个抽象产品类和一个抽象工厂类\n        - 策略模式：本质上是多态，存在一个根接口，其下的所有实现类都是不同的策略\n        - 代理模式（Proxy Pattern）：Spring中使用代理模式来实现AOP，通过动态代理技术在不改变原有类结构的前提下，对类的方法进行增强或切面操作。\n        - 观察者模式（Observer Pattern）：Spring中使用观察者模式来实现事件监听器的功能，例如ApplicationListener接口就是观察者模式的实现。\n        - 模板模式（Template Pattern）：Spring中使用模板模式来实现JdbcTemplate等模板类，将通用的数据访问逻辑封装在模板类中，提高了代码复用性和可维护性。\n        - 单例模式（Singleton Pattern）：Spring中大量使用了单例模式，确保在整个应用中只有一个实例对象被创建和共享，提高了应用的性能和效率。\n        - 适配器模式（Adapter Pattern）：Spring中使用适配器模式来适配各种数据源，例如JDBC适配器可以将不同厂商的JDBC驱动进行统一适配。\n    - 设计原则\n        - 单一原则：一个类只做同一个类型的事情，更注重于实现的细节\n        - 开放-封闭原则：对修改关闭对扩展开放\n        - 里氏替换原则：子类可以完全替代父类，如果A继承B，但B中有一些方法，对于A来说是没有必要的，则抽一个C作为基类出来提取公共部分，并让A和B去继承C\n        - 接口隔离原则：每个接口都做同一类的事情，尽量按功能来细分，不要写成一个很大的接口\n        - 依赖倒转原则：禁止套娃，直接依赖最初的类，不能A依赖B，B依赖C，希望直接是A依赖C\n    \n        \n\n6. Spring事务\n    - @Transaction 失效场景\n        - 事务方法所在的类没有加载到容器中\n        - 事务方法不是public类型\n        - 同一类中，一个没有添加事务的方法调用另外以一个添加事务的方法，事务不生效\n        - 抛出异常且手动捕获异常\n        - Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务，其他异常需要指定rollbackFor才能回滚事务，如果不指定又抛出了其他异常(IOException)，比如说FileNotFoundException，则事务失效\n    - 传播行为\n        - Required ： 内外事务合为一个\n        - New-Required : 内外事务隔离\n        - Supported : 有事务就按事务执行，没事务就按无事务的方式执行\n        - Not-Supported : 采用非事务的方式执行\n    - 隔离级别\n        - RU\n        - RC\n        - RR\n        - 可串行化\n\n7. Bean的作用域\n    - singleton : 容器中以单实例存在\n    - prototype : 容器中以多实例存在\n    - request   : 在同一个请求内共享\n    - session   : 在同一个Session内存共享\n    - globalSession : 全局的Session都共享同一个Bean实例\n\n8. BeanFactory和FactoryBean\n    - BeanFactory : 所有Bean的根接口，我把它看做制作Bean的图纸的工厂，它在产生Bean的同时也提供了依赖注入的能力 \n    - FactoryBean : 动态生成一个实例Bean的工厂，我把它看做按照图纸生成一个实实在在的组件，可加载到容器中去。\n\n9. Bean的生命周期\n    - 从配置中加载beanDefination\n    - 实例化\n    - 属性赋值\n    - 初始化\n    - 销毁\n\n10. 分布式事务\n    - CAP理论：一致性（数据）C、可用性（整个服务）A、分区容忍性P\n        - 分区：一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。\n        - 分区容忍性：当一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，由于数据项就可能分布到各个区里，所以我们仍然是可以访问的到这个数据的，容忍性就提高了。\n        - 一致性的问题：然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题，因为长时间的阻塞等待会导致我们的服务性能降低，严重的甚至可能导致我们服务崩溃\n\n    - BASE理论：是对 CAP 的一种解决思路，主要包含三个思想\n        - Basically Available （基本可用）：系统在面对故障或部分故障时，仍然能够保持基本的可用性，即系统仍然能够对外提供服务，并能够及时响应请求。\n        - Soft State（软状态）：系统中的数据状态可以在一段时间内是不稳定的，即系统中的数据可能存在中间状态，而不是绝对一致的状态。这种中间状态可能是由于数据复制、缓存等原因导致的。\n        - Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，系统可以通过一定的机制来保证最终数据的一致性，例如异步复制、定期数据同步等，最终达到数据一致。\n    \n    - Seata：https://blog.csdn.net/m0_58600248/article/details/126271252?spm=1001.2014.3001.5506\n\n    - XA模式和AT模式的比较\n        - XA模式是强一致性，因为所有的本地事务都会等待TC发起提交命令之后才会提交自己的事务，对数据的修改才会持久化到磁盘中去\n        - AT模式是最终一致性的，因为本地事务执行完SQL之后，会先提交，然后才会向TC报告自己的状态，如果存在一些本地事务故障，则会导致短暂的不一致的情况，需要第二阶段的回滚这样的补偿机制来保证最终一致性\n\n11. Springboot怎么实现自动配置\n    - 加载了哪些配置\n        - 自动配置类，也就是@Configuration所标识的类\n        - 文件配置，也就是application.yml这种文件\n        - 条件化配置，@Conditional，用来定义了在满足特定条件时才应用该自动配置\n\n12. Springboot为什么能快速构建应用\n    - 内嵌了Web容器，无须依靠外部的Tomcat来启动\n    - 摆脱了大量的xml文件的配置\n    - 自动配置原理，很多配置都是写好了的，直接加载了之后拿来用\n    - 引入了起步依赖，start依赖里提前配置好了该组件被依赖进来需要用到的配置，一旦引用，SpringBoot就会把这些配置自动加载到应用程序中，我们无须为了实现业务逻辑去手动去写它所需要的配置\n\n13. SpringMVC的执行流程\n    1. 客户端发送HTTP请求到前端控制器（DispatcherServlet）。 \n    2. DispatcherServlet 根据请求的URL找到对应的处理器映射器（HandlerMapping）。 \n    3. 处理器映射器根据请求的URL映射到具体的处理器（Controller）。 \n    4. 处理器被调用并处理请求，然后返回一个ModelAndView对象。 \n    5. 处理器将ModelAndView对象传递给DispatcherServlet。 \n    6. DispatcherServlet 调用视图解析器（ViewResolver）来解析 ModelAndView 对象，找到对应的视图。 \n    7. 视图解析器将视图对象返回给 DispatcherServlet。 \n    8. DispatcherServlet 将模型数据传递给视图对象，然后渲染视图。 \n    9. 最终，DispatcherServlet 将响应返回给客户端。 \n    \n\n## JUC\n1. Synchronized \n    - 原理:synchronized是Java中用于实现同步的关键字，它可以应用于方法或代码块中。其主要原理是通过对一个对象或类进行加锁来保证多个线程之间的互斥访问。当一个线程获取了锁，其他线程就必须等待锁被释放后才能进入被锁定的代码块。 \n    - 锁对象\n        - 修饰的是普通方法：锁的是实例对象\n        - 修饰的是静态方法：锁的是类class对象\n        - 修饰的是代码块：锁的是代码块之前，括号之内的实例对象\n    - 锁升级\n        - 偏向锁：线程A第一次竞争到资源，加的是偏向锁,MarkWord存的是偏向线程ID，之后只需检查是否是偏向线程访问即可，效率最高。\n        - 轻量级锁：线程B来和线程A竞争资源且竞争成功，则偏向锁切换偏向线程，竞争失败，则偏向锁升级为轻量级锁,轻量级锁本质就是自旋锁CAS\n        - 重量级锁：大量线程参与竞争或CAS多次自旋未成功，升级为重量级锁，效率最低\n    - 区别于ReentrantLock:\n        - ReentrantLock是Java层面的实现，synchronized是JVM层面的实现。\n        - 使用synchronized关键字实现同步，线程执行完同步代码块会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，而ReentrantLock需要手动释放锁需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁。\n        - synchronized是非公平锁，ReentrantLock可以实现公平和非公平锁。\n        - ReentrantLock 可以设置超时获取锁。在指定的截止时间之前获取锁，如果截止时间到了还没有获取到锁，则返回。配合重试机制更好的解决死锁。\n        - ReentrantLock上等待获取锁的线程是可中断的，线程可以放弃等待锁。而synchonized会无限期等待下去。\n        - ReentrantLock 的 tryLock() 方法可以尝试非阻塞的获取锁，调用该方法后立刻返回，如果能够获取则返回true，否则返回false。\n        - synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁，并且可以主动尝试去获取锁。\n\n2. 线程池\n    - 线程池实际上就是，可以通过预先创建一定数量的线程来管理任务执行，并重用线程以减少创建和销毁线程的开销，从而提高程序的性能和效率。但是如果线程池大小设置不当，可能会导致资源浪费或者系统负载过高的问题。如果任务队列中的任务数量过多，或者线程池中的线程数量过少，也可能会导致任务执行的延迟。  \n    - 七大参数\n        - 核心线程数 corePoolSize \n        - 最大线程数 maximumPoolSize   \n        - 空闲线程的存活时间 keepAliveTime \n        - 存活时间单位 TimeUnit\n        - 阻塞队列 workQueue \n        - 线程工厂 threadFactory \n        - 拒绝策略 handler\n            - 抛出异常\n            - 任务调回\n            - 丢弃任务\n            - 与最老任务竞争\n    - 参数设置\n        - I/O通常是对数据库的操作,线程数如果不多的话，在处理IO的时候不能用CPU，导致CPU的使用率较低。\n        - CPU密集型：\n            - 核心线程 = CPU核心\n            - 最大线程 = CPU核心 + 1\n        - IO密集型\n            - 核心线程 = 2*CPU核心\n            - 最大线程 = 2*CPU核心 + 1\n    - 运行流程\n        - 初始化线程池：需要指定线程池的参数，线程池会根据这些参数创建一定数量的线程，并初始化线程池的内部数据结构。\n        - 接收任务：线程池会一直处于运行状态，等待接收任务。当有任务到达时，线程池会接收任务并将其放入任务队列中。\n        - 线程分配任务：线程池中的线程会从任务队列中取出任务。如果核心线程数尚未达到设定的值，线程池会创建新的线程来处理任务。如果核心线程数已满，但还有任务到达，任务会被放入任务队列中等待执行。\n        - 任务执行：线程不断从任务队列中取出任务，并执行任务的逻辑。\n        - 关闭线程池：当不再需要线程池时，可以显式地关闭线程池。一般是先调用shutdown()方法停止接收新任务，然后再调用awaitTermination()方法等待任务执行完毕，最后再调用shutdownNow()方法强制关闭线程池，以确保任务能够顺利完成\n\n    - 阻塞队列\n        - 如果需要一个有界队列，且并发读写较少，可以选择使用ArrayBlockingQueue\n        - 如果需要一个无界队列，且并发读写较多，可以选择使用LinkedBlockingQueue。\n\n3. volatile(建议从JMM中引入)\n    - 概念：volatile 关键字用于标记变量，指示编译器和运行时系统每次访问该变量时都必须从内存中读取值，而不是使用缓存的值。在多线程编程中\n    - 作用：使用 volatile 可以保证可见性和禁止指令重排，从而保证线程安全。\n    - 补充解释：具体来说，当一个线程修改 volatile 变量的值时，其他线程将立即看到该变量的新值，因为该值是从内存中读取的。此外，由于 volatile 变量不能被缓存，因此在对该变量进行读取和写入操作时，不会发生指令重排，从而避免了线程安全问题。需要注意的是，volatile 仅保证单个操作的原子性，而不是多个操作的原子性。如果需要保证多个操作的原子性，应该使用其他机制，如锁、原子操作等。\n\n4. 线程的创建方式\n    - 继承Thread类并重写run()方法\n    - 实现Runnable接口或者Callable接口\n    - 使用线程池创建接口\n    \n5. CAS可能出现的问题\n    - ABA问题：CAS操作在进行比较时，只会比较原值和期望值是否相等，但是在并发环境下，可能会存在A->B->A的情况，这时候CAS就无法检测出这种情况，导致并发安全问题。\n    - 自旋开销：在使用CAS进行无锁编程时，由于CAS是一个自旋操作，需要不断地进行尝试和比较，从而可能会带来一定的CPU开销和性能损失。\n    - 公平性：CAS操作无法像锁机制一样保证公平性，可能会导致一些线程一直无法获取资源。\n\n6. 线程的同步方式\n    - synchronized: 采用互斥锁的方式来实现同步，当一个线程进入同步方法时，它会自动获取该方法所属对象的锁，其他线程需要等待该线程释放锁后才能进入该方法。\n    - ReentrantLock: 是一个可重入的互斥锁，与 synchronized 相比，ReentrantLock 提供了更灵活的锁定机制和更多的功能，如可实现公平锁、可用condition绑定很多条件等。\n    - Semaphore: 是一种计数信号量，用于控制对共享资源的访问。类似线程池的思想\n    - CountDownLatch: 多个线程并行执行完之后统一地执行主线程\n    - CyclicBarrier: 多线线程并行执行完之后单开一个线程去执行\n\n7. 零拷贝\n    - 概念: 是指在数据传输过程中，数据在不经过中间缓存（如用户态缓存）的情况下，直接从发送端复制到接收端，避免了数据在内存之间的多次复制，从而提高了数据传输的效率。\n\n8. ThreadLocal\n    - 概念：每个线程内部都维护了一个ThreadLocalMap(懒加载的)，key为threadLocal实例，value为要保存的副本，说白了就是保存的线程的私有变量,它允许在多线程环境下，每个线程都拥有自己独立的变量副本，这样就可以避免线程之间的数据互相干扰。\n\t- 问题：\n        - 内存泄漏问题，ThreaLocal本身作为key是弱引用，存放的实例对象是强引用，GC不会回收强引用，从而导致内存没有及时释放\n\t    - 使用 ThreadLocal 可能导致上下文丢失，因为可能会开一些异步线程去做一些操作，而在异步线程就可能丢失掉主线程的变量，从而后续如果需要用到这些变量，就获取不到了\n    - 应用场景\n        - 避免不必要的参数传递：将对象数据存储到ThreadLocal中，在本线程任何位置遇到的时候，都可以直接调用get方法来取\n        - 线程间数据隔离：每个线程在自己线程里使用自己的局部变量，各线程间的ThreadLocal对象互不影响，例子就是Spring在Dao层，单例对象却可以有多个连接，多个连接都是每个线程自己的副本\n\n9. 线程的五种状态\n    - 新建、就绪、运行、阻塞、死亡\n\n10. sleep()和wait()的区别\n    - wait()是Object的方法，sleep()是Thread类的方法\n    - wait()会释放锁，sleep()不会释放锁\n    - wait()要在同步方法或者同步代码块中执行，sleep()没有限制\n    - wait()要调用notify()或notifyall()唤醒,sleep()自动唤醒\n\n11. 线程池 execute 和 submit 的区别\n    - 返回值类型不同：execute() 方法返回值为 void，而 submit() 方法返回一个 Future 对象，可以通过该对象获取任务执行的结果。\n    - 对于提交的任务类型不同：execute() 方法只能提交 Runnable 类型的任务，而 submit() 方法可以提交 Runnable 和 Callable 类型的任务。Runnable 代表一个不带返回值的任务，Callable 则代表一个带返回值的任务。\n    - 阻塞行为不同：execute() 方法是一种无阻塞的提交方式，它会立即返回，并将任务提交给线程池中的一个线程执行；而 submit() 方法是一种阻塞的提交方式，它会等待线程池中有一个线程可用时再执行任务，如果线程池中没有可用线程，则任务会等待，直到有线程可用。\n    - 异常处理方式不同：execute() 方法无法处理任务执行过程中抛出的异常，而 submit() 方法可以捕获任务执行过程中抛出的异常，并将其封装到 Future 对象中，以便后续处理。\n\n12. 锁分类\n    - 乐观锁 ： 通过CAS + 版本号\n    - 悲观锁 : 每次获取到资源之后都加锁\n    - 公平锁 ：多个线程按顺序平均都能分到资源 \n    - 非公平锁： 无顺序一直竞争资源\n    - 自旋锁：当锁被占用时，线程不会被阻塞，而是通过不断重试的方式获取锁\n    - 偏向锁：当只有一个线程访问时，该线程可以直接获得锁，不需要进行同步\n    - 可重入锁: 同一个线程能连续获得同一个资源的锁\n\n13. 对线程安全的理解\n    - 概念：线程安全是指在多线程并发的情况下，共享的资源能够被多个线程同时访问而不会出现不可预期的结果\n    - 考虑方向：\n        - 原子性：原子性是指一个操作是不可被中断的，要么全部执行成功，要么全部失败\n        - 可见性：可见性是指一个线程对共享资源的修改能够被其他线程及时地感知到\n        - 有序性：有序性是指一个线程对共享资源的修改操作在执行顺序上符合程序的逻辑顺序\n        \n    - 实现方案：\n        - 锁机制：通过加锁和解锁来保证共享资源的操作是原子性的，常见的锁包括互斥锁、自旋锁等\n        - 原子变量：原子变量是一种线程安全的变量，它能够保证对共享资源的操作是原子性的，比如说AtomicInteger、AtomicLong等\n        - 线程同步：使用同步器，比如说CountDownLatch、CyclicBarrier、Semaphore等\n\n## JVM\n1. 垃圾回收算法\n    - 标记清除算法: 这是一种最基本的垃圾回收算法。它的核心思想是先标记所有可达对象，然后清除所有未被标记的对象。标记和清除分别需要扫描整个堆，效率较低，同时可能会产生内存碎片。\n    - 标记整理算法: 这种算法在标记阶段与标记-清除算法类似，但在清除阶段不是简单地删除未被标记的对象，而是将所有存活对象都向一端移动，然后将另一端的空间全部释放，从而避免了内存碎片的问题。\n    - 复制算法: 这种算法将堆分为两个区域，每次只使用其中的一部分。当当前区域用完后，将存活对象复制到另一个区域中，然后将当前区域中的所有对象清除。复制算法的特点是效率高，但需要两倍的空间。\n    - 分代算法: 这种算法认为对象的生命周期具有不同的阶段，将堆分为多个代，一般将新生代和老年代分开处理。新生代中的对象生命周期较短，采用复制算法；老年代中的对象生命周期较长，采用标记-整理算法。分代算法充分利用了对象的生命周期分布规律，提高了垃圾回收效率。\n\n2. 垃圾回收器\n    - CMS收集器\n        - 针对老年代，采用标记-清除法，容易产生内存碎片\n        - 以获取最短回收停顿时间为目标\n        - 对CPU资源敏感、无法处理浮动垃圾\n\n    - G1收集器: JDK1.9以后的默认垃圾回收器\n        - 分代收集，针对不同的分代结果，采用不同的收集算法，包括新生代和老年代\n        - 采用标记-整理+复制算法回收内存，使用可达性分析法来判断对象是否可以被回收\n        - 能充分利用多CPU、多核环境下的硬件优势、注重响应速度\n            - 原理：\n                - 并行处理：G1收集器采用了多线程并行处理来加速垃圾回收过程。在收集过程中，G1将整个堆空间分成多个区域（Region），每个区域都可以被多个线程并行处理。这样，每个线程只需要处理一小部分的垃圾，从而减少了单个线程的工作量，提高了垃圾回收的效率。\n\n    - 可作为GCROOT对象\n        - 长期存活的对象：比如线程池、I/O 等系统资源对象，它们通常需要在整个应用生命周期中持续存在。\n        - 静态变量和常量：静态变量和常量是在类加载时被初始化的，它们的生命周期通常很长。\n\n3. 新生代晋升到老年代的策略\n    - 对象年龄阈值策略：JVM中每个对象都有一个年龄计数器，当一个对象在新生代中经历了一定数量的垃圾收集后仍然存活，它的年龄计数器就会增加1。当一个对象的年龄超过一定阈值时，它就会被晋升到老年代中。可以通过调整年龄阈值来控制对象晋升的速度。\n    - 空间不足：如果新生代的可用空间不足以存放新的对象，JVM会先尝试触发一次垃圾回收，如果回收后仍然无法获得足够的空间，JVM就会尝试将部分存活的对象直接晋升到老年代中，以腾出新生代的空间。\n\n\n4. 内存结构\n    - 堆 (线程共享): 存储对象实例、为对象分配内存空间、GC主要作用区域\n    - 方法区(线程共享): 存储类的元数据信息，如类名、方法名、字段名等。方法区还用于存储运行时常量池、静态变量、即时编译器编译后的代码等信息。\n    - Java虚拟机栈: 用于存放 Java 方法执行时的栈帧。每个栈帧包含局部变量表、动态链接、返回地址等信息。当线程调用 Java 方法时，JVM 会在 Java 虚拟机栈中为该方法分配一个栈帧，在方法返回时，该栈帧会被弹出并销毁。\n    - 本地方法栈: 本地方法栈和 Java 虚拟机栈类似，用于存储本地方法(其他语言编写的)的栈帧。\n    - 程序计数器: 用于指示 JVM 正在执行哪个线程的字节码指令\n    - 堆的分区\n        - 新生代(1/3) : Eden(8/10) 幸存区1(1/10) 幸存区2(1/10)  [通常采用复制算法]\n        - 老年代(2/3) : 存放存活时间较长的对象，这些对象可能是长时间存活的业务数据、缓存对象、连接池等 [通常采用标记整理算法]\n\n\n5. 如何减少Full GC\n    - 尽量少创建一些临时对象\n    - 增加堆的大小\n    - 使用对象池,提高对象的利用率\n    - 调整年轻代的S区的大小，\n6. 什么情况下会内存溢出\n    - 堆内存溢出\n        1. 加载的类越来越多时\n        2. 当对象一直创建而不被回收时\n        3. 虚拟机栈的线程越来越多时\n    - 栈溢出\n        - 方法调用次数过多，一般是递归不当造成\n\n\n7. 类加载器\n    - 概念：类加载机制是Java虚拟机（JVM）加载类文件到内存中的过程。\n    - 双亲委派模型: 它首先将这个请求委派给它的父类加载器去完成，如果父类加载器还存在父类加载器，它会将请求一直传递给更高级的父类加载器，直到顶层的父类加载器。\n    - 好处：双亲委派模型保证了类的唯一性，避免了类的重复加载，从而保证Java程序的稳定性和安全性。\n    - 种类\n        - 引导类加载器：也称为根加载器，是最顶层的类加载器，用来加载Java的核心库，如java.lang包中的类。\n        - 扩展类加载器：负责加载Java平台扩展库，默认加载JAVA_HOME/lib/ext目录下的jar包。\n        - 应用程序类加载器：负责加载应用程序classpath目录下的所有类，即我们自己编写的Java类。\n        - 自定义类加载器：我们可以通过继承java.lang.ClassLoader类实现自己的类加载器，用于实现特定的类加载需求，如从网络上加载类文件等。\n        - 总结：每个类加载器都有自己的加载范围，即它能够加载哪些类。当一个类加载器需要加载一个类时，它会先查找自己已经加载的类，如果没有找到，则向上委托给父类加载器，直到顶层的引导类加载器，如果仍然没有找到，先判断自己是否能加载这个类，如果不能，则会向下委托给子类加载器去加载，总结起来就是自下而上去查找，又自上而下来加载。这样的加载方式构成了Java类加载器的双亲委派模型。\n\n8. JVM常用参数\n    - Xms：堆的起始大小\n    - Xmx：堆的最大大小\n    - Xmn：新生代的大小\n    - Xss：每个线程可使用的内存大小\n    - XX:NewRatio：老年代/新生代，默认是2\n\n9. 命令调优\n    - jmap -dump:format=b,file=/home/dumps 进程pid ：手动生成dump文件\n    - jmap -histo:live pid ：手动生成对象使用内存情况的直方图\n    - jstat -gcutil 进程pid ：手动生成进程的gc情况，主要查看堆内各区域的\n\n\n## JMM\n- 概念：JMM是指的是Java内存模型，它是一种规范，它规定了所有的变量都存储在主内存（Main Memory）中。每个线程还有自己的工作内存（Working Memory）,线程的工作内存中保存了该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。同时，不同的线程之间也无法直接访问对方工作内存中的变量，线程之间值的传递都需要通过主内存来完成。\n- 特性\n    - 原子性：一个操作不能被打断，要么全部执行完毕，要么不执行。\n    - 可见性：一个线程对共享变量做了修改之后，其他的线程立即能够看到（感知到）该变量的这种修改（变化）。\n    - 有序性: 在单线程程序里，确实顺序执行；但是在多线程并发时，程序的执行就有可能出现乱序。\n\n- 有序性和可见性的保证\n    - synchronized\n        - 获取锁的时候直接从主存中读取变量，释放锁之前把工作内存的变量数据重新刷回主存\n        - 既保证了多线程的并发有序性，又保证了多线程的内存可见性。\n    - volatile\n        - 每次修改变量都会直接刷到主存\n        - 可以保证内存可见性，不能保证并发有序性(不具有原子性)，可禁止指令重排。\n\n- volatile的原理：会生成一个内存lock前缀指令，相当于一个内存屏障\n    - 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；\n    - 它会强制将对缓存的修改操作立即写入主存；\n    - 如果是写操作，它会导致其他CPU中对应的缓存行无效。\n\n\n## 数据库\n### MySQL\n1. 四大特性(ACID)\n    - 原子性 ： 每个操作不可再分\n    - 一致性 ： 一个事务可以让数据从一种一致状态切换到另一种一致性状态\n    - 隔离性 ： 事务并行执行互不影响，最后结果和串行执行的结果相同\n    - 持久性 : 一个事务一旦被提交，在数据库中的改变就是永久的，提交后就不能再回滚\n\n2. 三大问题\n    - 脏读：读到了未提交的数据\n    - 不可重复读：同一个事务两次读到的数据值不同\n    - 幻读：同一个事务两次读到的数据记录数量不同\n\n3. 隔离级别\n    - READ UNCOMMITTED: 读未提交\n    - READ COMMITTED: 读已提交\n    - REPEATABLE READ: 可重复读\n    - SERIALIZABLE: 可串行化\n\n4. SQL执行顺序\n    - from -> where -> group by -> having -> select -> order by -> limit\n\n5. MVCC原理\n    - 作用:\n        - 解决脏读、不可重复读的事务读写问题\n        - 在保证隔离性的基础上，提升了读取效率和并发性\n    - 描述：在执行 Update 和 Delete 操作的时候，会将每次操作记录记录在 UndoLog 中, 每条记录都有唯一的事务ID,而ReadView记录了数据版本链的一些统计值，包括活跃事务集，当前事务ID等，然后通过四步判断法进行判断，遍历整个版本链，最终得到一个符合所有要求的数据版本。\n    - 四步判断法：\n        - 判断当前遍历到的事务ID是否和ReadView记录的当前事务ID相同\n        - 判断当前遍历到的事务ID是否小于最小活跃事务ID，如果相同则返回true\n        - 判断当前遍历到的事务ID是否大于max_trx_id(下一次分配的事务ID)，如果是则返回false\n        - 判断当前遍历到的事务ID是否在活跃事务集范围内，如果是，则返回false\n    - RC和RR隔离下\n        - RC：每次快照读都会生成一份最新的ReadView\n        - RR：每次快照读所使用的ReadView都是当前事务第一次生成的ReadView\n\n6. 日志Log\n    - bin log（二进制日志）：记录所有对MySQL数据库的更改操作，例如INSERT、UPDATE、DELETE等，以二进制格式存储。binlog文件可以用于数据备份和恢复，数据复制和数据同步。\n    - undo log（回滚日志）：在事务中，如果执行了UPDATE或DELETE操作，MySQL会先将修改前的数据记录到undo log中，然后再对数据进行修改。如果事务回滚，则MySQL可以使用undo log来撤销已经进行的修改。\n    - redo log（重做日志）：在事务中，MySQL会先将对数据的修改记录到redo log中，然后再进行实际的修改。如果MySQL在执行修改操作后崩溃，MySQL可以使用redo log来恢复数据。\n    - 慢查询日志：MySQL的慢查询日志是一种记录执行时间超过一定阈值的查询语句的日志。可以记录查询语句、执行时间、锁等待时间等信息\n\n7. MySQL慢查询\n    - 概念：慢查询是指执行时间较长、响应时间较慢的SQL查询语句。通常来说，如果一条SQL查询语句的执行时间超过了一定的阈值（例如1秒钟），就可以将其视为慢查询。\n    - 定位：可以使用MySQL的慢查询日志文件\n    - 影响：它们可能会导致服务器资源的过度占用，影响系统的响应速度和稳定性。\n    - 解决方案\n        - 使用索引：确保表的索引能够覆盖查询的列，这将使MySQL能够快速找到需要的数据。\n        - 优化查询语句：使用合适的查询语句可以提高性能。使用JOIN时，应该尽可能使用INNER JOIN而不是LEFT JOIN或RIGHT JOIN，因为后者可能会导致较慢的查询速度。\n        - 优化表结构：可以改善查询性能。例如，避免使用过多的JOIN，使用正确的数据类型，避免使用过多的NULL值等等。\n    - 索引优化\n        - 索引选择：根据每个字段的特点来选择、尽量走覆盖索引，减少回表\n        - 代码层面：严禁for循环查表、连接池参数优化、尽量避免联表查询\n        - 架构层面：分库分表、索引定期维护，定期进行索引的重建、重新组织或碎片整理，可以保持索引的良好状态和性能\n\n8. 聚簇索引和非聚簇索引\n    - 区别：\n        - 物理存储方式不同: 前者的数据存在同一块物理存储区域，后者是建立索引值与行记录映射关系，有点像顺序存储和链式存储\n        - 适用范围不同: 聚簇索引适合于频繁查询范围较小的数据、后者适用于频繁查询单个或少量的记录,因为每个索引条目只需要查询一次就可以找到相应的行记录。\n        - 字段数量不同: 每张表前者只能有一个，后者可以有多个\n\n9. MySQL索引\n    - 如何判断MySQL中的索引有没有生效: 在select语句前面加上explain就可以了\n    - 主键索引：一张表只能有一个主键索引，主键索引列不能有空值和重复值\n    - 唯一索引：唯一索引不能有相同值，但允许为空\n    - 普通索引：允许出现重复值\n    - 组合索引：对多个字段建立一个联合索引，减少索引开销，遵循最左匹配原则\n    - 全文索引：通过建立倒排索引提升检索效率，广泛用于搜索引擎\n\n\n10. MySQL索引的应用场景\n- 适合：\n    - 频繁作为查询的字段\n    - 查询作为和其他表关联的字段\n    - 查询中常作为排序条件的字段\n- 不适合：\n    - 频繁更新的字段\n    - 表的记录不多的字段\n    - 数据重复且分布平均的字段\n\n11. 索引是越多越好吗？优缺点在何处？\n    - 优点\n        - 快速访问：索引可以加速数据访问，使得查询数据更快速。\n        - 提高性能：索引可以提高数据库性能，使得数据的读取更快。\n    - 缺点\n        - 索引的成本：索引需要额外的存储空间来存储数据，这可能会占用大量磁盘空间。\n        - 增加写入负担：索引的维护需要一定的时间和计算资源，因此在数据量大且经常写入的情况下，索引的创建和更新可能会带来一定的负担。\n        - 复杂性增加：如果过多的索引被创建，可能会使得数据结构变得更加复杂和难以管理，增加了维护的难度。\n\n12. MySQL索引失效场景\n    - 对索引列使用左模糊或者左右模糊查询\n    - 对索引使用函数\n    - 对索引进行表达式运算\n    - 对索引隐式类型转换的时候\n    - 违背最左匹配原则\n    - or 的左右两边不全是索引字段\n\n\n\n13. 如果索引不合适，会删除吗，是什么流程\n    - 如果索引不合适，通常会进行重新设计和重建索引，而不是直接删除索引。这是因为索引是数据库中非常重要的组成部分，它们帮助加速查询和提高数据库性能。\n    - 重建索引的流程通常包括以下步骤：\n        1. 确定需要重建索引的表和索引：通过分析数据库性能和查询计划，确定哪些表和索引需要重建。\n        2. 停止对表的写操作：停止对需要重建索引的表的写入操作，以确保在重建过程中不会发生数据丢失或数据不一致的情况。\n        3. 删除旧的索引：删除需要重建的索引。\n        4. 重建索引：根据设计好的新索引结构，重新创建索引。\n        5. 重新启用写操作：重建索引完成后，重新启用对表的写入操作。\n\n\n14. MySQL的基本数据类型\n    - 整型（xxxint）\n    - 位类型(bit)\n    - 浮点型（float和double、real）\n    - 日期时间类型（date,time,datetime,year）\n    - 字符串（char,varchar,xxxtext）\n    - 二进制数据（xxxBlob、xxbinary）\n    - 定点数（decimal,numeric）\n    - 枚举（enum）\n    - 集合（set）\n\n15. MySQL回表\n    - 概念：一般是对于非主键索引而言的,查询完得到的结果是主键索引的值，然后不但要遍历非主键索引的B+树，还要重新遍历一遍主键索引的B+树，叫做回表\n    - 解决：可以通过覆盖索引的方式解决，即索引的字段中已经包含了需要查询的字段\n\n16. MySQL锁\n    - 共享锁: 共享锁允许多个事务同时读取同一资源，但是不能进行修改操作。这个语句会给查询的结果集上共享锁，其他事务可以读取这个结果集，但是不能进行修改操作，直到释放锁为止。\n        - ```sql SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE; ```\n    - 排他锁: 排他锁是最高级别的锁，它禁止其他事务对资源的任何读取和写入操作，只有当前事务可以对资源进行读取和写入操作。\n        - ```sql SELECT * FROM table_name WHERE ... FOR UPDATE; ```\n\n17. SQL执行流程\n    - 建立连接校验用户名密码 -> 查询缓存 -> 词法分析语法分析 -> 优化器判断是否有索引 -> 执行器判断是否有权限 -> 执行语句并返回结果集\n\n\n18. SQL优化\n    - 查询SQL尽量不要使用select *，而是具体字段\n    - 避免在where子句中使用or来连接条件\n    - 使用varchar代替char\n    - 查询尽量避免返回大量数据\n    - 尽量使用数值替代字符串类型\n    - 如何结合业务来进行SQL优化\n        - 只查询必要字段：那么查询时只选择业务需要的必要字段，而不要选择所有字段。减少查询返回的数据量有助于提高查询效率\n\t    - 选取合适的候选码：根据控制层传递的参数，考虑选用合适的候选码作为where筛选条件，尽量走覆盖索引\n\t    - 数据分页：如果查询结果太大，可以考虑分页查询，每次只查询一部分结果，这样可以减少一次性返回大量数据所带来的负担\n\t    - 考虑合并多个查询：有时候，可以将多个独立的查询合并为一个查询，减少数据库连接和查询次数，从而提高查询效率。\n\t    - 缓存数据：对于一些频繁查询的数据，可以考虑在应用程序层面进行缓存，避免频繁地访问数据库，提高响应速度。\n\n\n19. 防止SQL注入\n    - 使用mybatis的”#{}“预编译，将传入的值按照字符串的形式进行处理\n    - 利用工具进行SQL注入检测\n    - 对进入数据库的特殊字符进行转义处理，或编码转换\n    - 校验参数的数据格式是否合法(可以使用正则或特殊字符的判断)\n\n20. 存储引擎\n    - Myisam\n        - 不支持事务\n        - 不支持外键\n        - 仅支持表锁\n        - 在并发操作时需要加锁，可能导致读写冲突，有性能瓶颈，并发性能较低\n        - 没有缓冲池机制\n        - 叶子结点保存的是数据的地址\n    - innoDB\n        - 支持事务\n        - 支持外键\n        - 可支持行锁\n        - 具有MVCC机制，可以实现读取操作不阻塞写入操作，提供了更好的并发性能\n        - InnoDB采用了缓冲池机制，将数据和索引缓存到内存中，加快数据的访问速度。\n        - 叶子结点保存的就是数据\n\n21. 数据库主键是否可以用string类型，比如说UUID，优缺点是什么\n    - 断言：可以，有优势有劣势，需要做取舍\n    - 优势\n        - 全局唯一性：UUID 是一个由 128 位数字组成的字符串，几乎可以保证在不同系统和数据库之间的唯一性。这对于分布式系统和多个独立数据库之间的数据一致性非常重要。\n        - 无需数据库自增：可以方便地在分布式环境中生成主键，而无需额外的同步机制\n    - 劣势\n        - 存储空间占用：相比于整数类型的主键，string类型的主键会占用更多的存储空间\n        - 索引效率低下：string类型的主键会导致索引文件变大、需要更多的磁盘IO和内存消耗，会降低我们的索引效率，也就降低了我们的查询效率\n        - 不适合作为聚焦索引：聚集索引的顺序会对数据的存储和访问效率产生影响，而UUID 的无序性会导致频繁的数据页分裂和不均匀的存储\n\n22. Mysql集群\n    - 主从复制\n        - 原理：主服务器上的写操作会立即被记录到binlog日志，从服务器监听binlog日志，当发生写入操作的时候同步复制该操作到从服务器，然后在从服务器上执行相同的操作来复制数据。复制过程是异步的，主服务器上的写操作并不会等待从服务器执行完成。 但是如果主服务器发生故障或网络中断，复制会暂时停止。当主服务器恢复后，从服务器会自动重新连接并继续复制。\n        - 优点\n            - 读写分离：主服务器负责处理写操作，而从服务器可以处理读操作。\n            - 故障恢复：当主服务器发生故障时，可以将其中一个从服务器提升为新的主服务器，实现快速的故障转移和自动恢复，降低业务中断时间。\n            - 扩展性：通过添加更多的从服务器，可以水平扩展数据库系统，处理更大规模的并发请求和数据量。\n        - 缺点：\n            - 数据延迟：由于主从复制是异步的过程，从服务器上的数据复制存在一定的延迟。这意味着从服务器上的数据可能不是实时的，可能存在一小段时间的数据不一致。\n            - 单点故障：从复制架构中的主服务器仍然是单点故障的风险。如果主服务器发生故障，需要手动切换到一个备用的从服务器来代替主服务器，可能导致一定的停机时间和数据丢失。\n            - 无法水平扩展写操作：主从复制只能将写操作限制在主服务器上，从服务器只能进行读操作。这限制了系统的写操作扩展性，主服务器的性能成为瓶颈\n    - 双主模式\n        - 优点\n            - 高可用性：双主模式提供了更高的可用性，因为系统不会出现单点故障。如果其中一个主服务器发生故障，另一个主服务器可以继续处理写操作，从而实现故障转移并保持业务的连续性。\n            - 数据一致性：在双主模式下，每个主服务器都可以接收和处理写操作，写操作会同时在两个主服务器上执行。这意味着数据在两个主服务器之间具有更高的一致性，不会出现主从复制的延迟和不一致性问题。\n        - 缺点\n            - 冲突处理：在双主模式下，同时在两个主服务器上执行写操作可能会导致数据冲突的问题。例如，如果两个主服务器同时修改相同的数据行，就会出现冲突，需要解决冲突并确保数据一致性。\n            - 配置和管理复杂性：双主模式的配置和管理相对复杂。需要确保双主服务器之间的复制设置正确，并处理可能出现的冲突和同步问题。\n\n23. count，sum，avg对null和空串的处理\n\t- count：count(*)会计算null和空串，count具体一个字段会忽略null，不会忽略空串\n\t- sum：不计算null和空串\n\t- avg：不计算null为行，但是会把空串计算成一行\n\n\n### Redis\n1. 缓存故障\n    - 缓存穿透\n        - 概念：是用户访问的数据既不在缓存当中，也不在数据库中。当高并发或有人利用不存在的Key频繁攻击时，数据库的压力骤增，甚至崩溃，这就是缓存穿透问题。\n        - 解决方法：可以通过布隆过滤器等方式，在缓存中添加一个不存在的数据时，先判断其是否存在于布隆过滤器中，如果不存在则直接返回，避免大量的请求直接访问数据库。\n    - 缓存击穿\n        - 概念：指一个存在的 key，在缓存过期的一刻，同时有大量的请求访问这个 key，由于缓存失效，请求会穿透缓存直接访问数据库，造成数据库压力过大。\n        - 解决方案：可以采用永不过期的方式或者在缓存中添加短暂的二级缓存等方式来解决缓存击穿问题。\n    - 缓存雪崩\n        - 概念：指缓存中的大量数据同时过期失效，导致大量请求直接访问数据库，造成数据库压力过大。\n        - 解决方案：可采用数据预热，提前将缓存数据加载到缓存中，还可以设置多级缓存,还可采用使用分布式锁控制只有一个请求来重新加载缓存数据，避免缓存雪崩。\n\n\n2. 数据库缓存一致性\n    - 双写模式: 通常使用的是“先更新数据库，立马更新缓存”的顺序，以确保数据一致性。如果更新缓存失败，可以将缓存标记为失效，让下一次查询时重新从数据库中获取数据。(每次写入都要写入两个地方，可能造成更新操作变慢)\n    - 延时双删：在更新数据库时，先给缓存中的数据设置过期时间，然后等待一定时间后再删除缓存数据。(一定时候后才更新缓存，让数据库读写操作更快一点)\n\n\n3. Redis的持久化策略\n    - RDB持久化 : Redis会周期性地将内存中的数据集快照写入磁盘，即生成一个RDB文件，可能会丢失最后一次快照以后的所有修改。\n    - AOF持久化 : Redis会将执行的每个写命令都记录到一个追加的文件中，在Redis重启时，会重新执行AOF文件中的所有写命令，以便恢复原始数据集，但会导致更高的磁盘空间占用和更慢的写入性能。\n\n4. Redis的数据类型\n    - 字符串类型(string)：\n        - 用于存储单个值，例如整数、浮点数、字符串等。\n    \n    - 列表类型（list）：有序集合\n        - 消息队列：使用lpush和brpop实现阻塞队列\n        - 分页查询：使用lrange和下标来实现分页读取\n\n    - 哈希类型（hash）：映射表\n        - 可以存储一些用户信息，订单信息，用户ID或订单ID作为hashKey\n        - 实现购物车功能，用户ID作为缓存Key，商品编码作为hashKey，商品信息作为hashValue\n    \n    - 集合类型（set）：无序不重复集合\n        - 社交类软件的共同好友，比如说抖音的共同好友\n        - 统计访问我们网站的IP地址\n    \n    - 有序集合类型（sorted set）：有序不重复集合，但每个元素都有一个分数（score）与之关联，并按照分数排序，底层是跳表+压缩列表，当有序集合保存的元素数量小于128个且有序集合保存的所有元素的总大小小于64字节的时候用压缩列表\n        - 排行榜的，带有权重的且不允许重复的，都可以用zset\n\n\n5. Redis的数据淘汰策略\n    - LRU (最近最少使用): Redis会根据键最后一次被访问的时间来删除最近最少使用的键。当内存达到限制时，Redis会优先删除最久未被访问的键，以释放更多的内存空间。\n    - LFU (最不经常使用)：Redis会根据键被访问的次数来删除最不经常使用的键。当内存达到限制时，Redis会优先删除被访问次数最少的键，以释放更多的内存空间。\n    - TTL (生存时间)：Redis会根据键的生存时间来删除过期键。每个键都可以设置一个生存时间，当键的生存时间到期时，Redis会自动删除该键。\n    - Random (随机)：Redis会随机删除一些键来释放内存空间。这种策略没有考虑键的访问时间或频率，因此可能会删除一些有用的键。\n    - Maxmemory-policy（最大内存策略）：这是一种基于多个淘汰策略的组合策略。Redis会根据当前内存使用量和内存限制来选择合适的淘汰策略。例如，在内存使用量接近内存限制时，Redis会使用LRU或LFU策略来删除最近或最不经常使用的键，以保留更多的内存空间。\n\n6. Redis为什么快\n    - 完全基于内存，通过磁盘IO读取到内存这部分的开销\n    - 数据结构简单，对数据操作也简单，主要使用string、list、hash、set、zset这几种数据结构\n    - 采用单线程来处理，省去了很多上下文切换的时间以及CPU消耗\n    - 使用基于IO多路复用机制的线程模型，可以处理并发的连接\n\n7. Redis分布式锁\n    - 背景\n        为什么要有分布式锁：传统的锁，包括sychronized、包括ReentrantLock都只能锁单机，只能控制多线程对单机的访问，但是如果基于分布式架构，比如说在我们的微服务应用当中，不同的服务部署在不同的机器上，且各个服务之间也有交互，则传统的锁就会失效，所以需要一个能够在分布式架构中也能起到访问控制的锁出现，也就是我们的分布式锁，而其中redis分布式锁就是其中的一种\n    - 原理\n        - 基于setNx：setNx 是Redis的一个原子操作，用于设置一个键值对，但只在键不存在时才执行。要获取锁，客户端可以使用SETNX命令在Redis中创建一个特定的键，并设置一个随机的唯一标识作为值。如果SETNX操作返回1，表示客户端成功获取到锁；如果返回0，表示锁已被其他客户端持有。在释放锁时，客户端可以使用DEL命令删除对应的键。\n    - 命令\n        - SET key value [EX seconds] [PX milliseconds] [NX|XX]: 尝试给指定的key设置一个对应的value。该指令可以用于获取锁。参数EX和PX用于设置键的过期时间，NX表示只在键不存在时设置值（用于获取锁），XX表示只在键已经存在时设置值（用于释放锁）。\n        - GETSET key value: 设置给定key的value并返回旧的value。该指令可用于检查并更新锁的值。\n        - DEL key: 删除指定的key。该指令可用于释放锁。\n8. Zookeeper锁\n- 原理\n    - 创建锁节点：当一个进程或线程需要获取锁时，它会在ZooKeeper上创建一个有序临时节点（例如：/locks/lock-000000001）。\n\n    - 检查前一个节点：进程会获取当前创建的有序节点的序号，并检查是否它是当前锁下的最小序号节点。如果是最小节点，表示当前进程获取到了锁，可以执行相关操作。否则，进程会监听前一个节点（例如：/locks/lock-000000000）的删除事件。\n\n    - 监听前一个节点：进程在ZooKeeper上对前一个节点进行注册监听器。如果前一个节点被删除（即前一个进程释放了锁），ZooKeeper会通知当前进程。\n\n    - 锁释放：当进程完成了任务，它会删除自己创建的节点，从而释放锁。这会触发ZooKeeper通知下一个等待的进程。\n- 总结\n    - 通过这个基本的原理，ZooKeeper锁可以实现互斥访问，保证在任意时刻只有一个进程能够获取到锁，其他进程需要等待。同时，ZooKeeper的有序临时节点保证了节点创建的顺序，进程可以根据节点的序号判断自己是否是当前锁下的最小节点。\n\n    - 需要注意的是，使用ZooKeeper锁时要处理会话过期和网络分区等异常情况。当一个进程的会话过期或与ZooKeeper服务器失去连接时，它创建的临时节点会被自动删除，从而释放锁。此外，由于ZooKeeper是一个分布式系统，网络分区或ZooKeeper服务器故障可能会导致锁的不可用性或不确定性。因此，在使用ZooKeeper锁时，需要考虑这些异常情况并进行相应的处理和恢复机制。\n\n\n8. Redis集群\n    - 主从复制\n        - 作用：对读写能力扩展，采用读写分离的方式解决性能瓶颈\n        - 数据同步\n            - 同步策略：主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。\n            - 全量同步\n                - 从服务器连接主服务器，发送SYNC命令；\n                - 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；\n                - 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；\n                - 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；\n                - 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；\n                - 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；\n            - 增量同步\n                - 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\n                - Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。\n\n        - 优势\n            - 读写分离：主从复制，主机会自动将数据同步到从机，实现了读写分离\n            - 分担主服务器压力：从服务器同样可以接受其他从服务器的连接和同步请求，这样可以有效的分载主服务器的同步压力\n            - 非阻塞提供服务：主服务器是以非阻塞的方式为从服务器提供服务，所以在主从同步期间，客户端依然可以提交查询或修改请求，从服务器也是以非阻塞的方式完成数据同步的，在同步期间，如果有客户端提供查询请求，Redis则返回同步之前的数据。\n        - 劣势\n            - 容易发生单点故障的问题，主机宕机之后，则无法进行写请求，需要人工干预来选择新的主节点\n            - 主机宕机后如果有部分数据没有及时同步到从机，更换主机IP后会导致数据不一致的问题\n            - 如果多个从机断线，需要重启的时候，如果在同一时间段进行重启，多个slave重启，都会发送sync请求(redis2.8之后是psync)并进行主机全量同步，那就会导致主机 IO 剧增从而主机宕机\n            - Redis较难支持在线扩容，在集群容量达到上限时在线扩容就会变得艰难\n        - psync和sync的区别：psync是只同步掉线期间的数据，sync是全量同步\n\n    - 哨兵机制\n        - 作用：用一个哨兵来监控所有的服务器状态，一旦发现某个主服务器宕机或故障了，就自动让从服务器顶上去\n        - 原理：哨兵是一个独立的进程，会独立运行，哨兵进程通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器当哨兵进程检测到某个主机宕机后，会自动将slave切换为master，然后通过发布订阅模式同之其他从服务器，修改配置文件，让他们切换主机\n        - 服务器下线认定\n            - 主观下线：如果一个服务器没有在master-down-after-milliseconds选项所指定的时间内，对向它发送PING命令的哨兵返回一个有效的回复，那么哨兵就会将这个服务器标记为主观下线\n            - 客观下线：客观下线的评判由多个哨兵完成，一个主机是否下线，由多个哨兵投票完成，当多个哨兵说该主机下线了，那么它就是下线了\n            - 主观切换到客观标准：如果哨兵在给定范围内，从其他哨兵那里接收到了足够数量的主服务器下线报告，那么哨兵就会将主服务器的状态从主观下线切换为客观下线\n            - 下线标记去除：如果没有足够的哨兵进程同意主服务器下线，那么主服务器的客观下线状态标记就会被移除，如果主服务器重新向哨兵发送的PING命令返回了有效的回复，主服务器的主观下线状态就会被移除\n            - 补充：客观下线只适用于主服务器，对于其他类型的Redis实例，哨兵在将它们判断为下线前不需要进行协商，所以从服务器或其他哨兵不会达到客观下线条件。\n        - 任务\n            - 监控（Monitoring）： 哨兵会不断检查主服务器和从服务以及其他哨兵是否运作正常\n            - 提醒（Notification）: 当被监控的某个服务器出现问题时，哨兵可以通过API向管理员或其他应用程序发送通知\n            - 自动故障迁移（Automatic failover）：当一个主服务器不能正常工作时，哨兵会开始一次自动故障转移操作，它会将失效的主服务器的其中一个从服务器升级为新的主服务器，并让失效的主服务器的其他从服务器知晓新的主服务器。当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。\n        - 优势\n            - 从上文可以看出，哨兵机制集群模式是基于主从复制模式的，所以它有主从复制的所有优点\n            - 主从服务器可以自动切换，系统更加健壮，可用性更高\n        - 劣势\n            - 内存浪费：每台Redis服务器都存储了相同的数据，非常浪费内存\n            - Redis较难支持在线扩容，在集群容量达到上限时在线扩容就会变得很复杂\n            \n    - Cluster模式(Redis内置集群)\n        - 架构图 \n        <img src = \"FF://xtzl.wentexl.cn/redis%E7%9A%84cluster.png\"/>\n        - 作用：每台Redis节点上存储了不同的内容\n        - 原理：任意两个节点之间都是相互连通的（采用的是PING-PONG机制），内部使用二进制协议优化传输速度和带宽。客户端可以与任意一个节点相连，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作，Redis集群使用的是哈希槽的概念，Redis集群有16384个哈希槽，每个Key通过CRC16校验后对16384取模来决定放置在那个槽。集群中的每个节点负责一部分的hash槽，意思是无论有多少个节点，都只有16384个槽来分\n        - 保证高可用：Redis-Cluster集群引入了主从复制模型，一个主节点对应一个或多个从节点，当主节点宕机后，就会启用从节点\n        - 对主机的宕机判断：采用的是投票方式，当其它主节点ping一个主节点时，如果半数以上的主节点与其通信超时，那么就认为该主节点宕机了，为了得出投票结果，主节点个数一般是奇数。\n        - 优势\n            - 使用这种架构很容易添加或删除节点，比如如果想删除某个节点，那么就将该节点的槽移动到其他节点上，然后将没有任何槽的节点移除\n            - 在一定程度上节约了内存空间\n\n9. reids判断键已过期\n    - 定期删除：Redis 服务器会周期性地（默认每秒钟 10 次）随机检查一部分设置了过期时间的键，并删除其中已经过期的键。这个过程是通过 Redis 的『定时器』来完成的，每次执行一小部分过期键的删除操作，以避免对服务器的性能产生明显的影响。\n    - 惰性删除：当客户端访问一个设置了过期时间的键时，Redis 会先检查这个键是否已经过期，如果过期则立即删除。这种方式确保了过期键能够在被访问时立即被删除。\n\n10. redis的key\n    - 热key（hotkey）：访问十分频繁的key\n        - 场景\n            - 爆款商品\n            - 热点新闻\n            - 热门活动\n        - 问题\n            - 缓存击穿\n            - 占用CPU资源，使效率降低，可能会影响到其他业务\n            - 热key所在的节点访问量大，容易造成物理网卡瓶颈\n        - 解决方案\n            - 做二级缓存，添加一个本地缓存来存热key\n            - 熔断限流，可以针对热key做单点限流，限定缓存集群的qps\n    - 大key（bigkey）：存放的数据特别大的key\n        - 场景\n            - String存放的数据大于10k\n            - 集合类型的存放的数据量超过五千个，或者个数不多，但是每个数据都很大，导致整体数据较大\n        - 问题\n            - 网络拥塞：如果一个Key占用的空间很大，那么每次访问都会消耗大量的网络带宽，可能导致机器或局域网的流量被打满，影响其他服务的通信。\n            - 在操作大 key 时会比较耗时，客户端有可能会超时阻塞。\n            - 在删除的时候如果使用del删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。\n        - 解决方案\n            - 将一个大key按逻辑分为若干个小key\n            - 制定合适的内存淘汰策略，及时淘汰和清理掉无效数据\n            - 使用合适的数据结构来存储数据，例如Hash\n\n## 任务调度框架\n### quartz\n* 调用API的的方式操作任务，不人性化；\n* 需要持久化业务QuartzJobBean到底层数据表中，系统侵入性相当严重。\n* 调度逻辑和QuartzJobBean耦合在同一个项目中，这将导致一个问题，在调度任务数量逐渐增多，同时调度任务逻辑逐渐加重的情况加，此时调度系统的性能将大大受限于业务；\n* Quartz关注点在于定时任务而非数据，并无一套根据数据处理而定制化的流程。虽然Quartz可以基于数据库实现作业的高可用，但缺少分布式并行调度的功能。\n* 无管理界面\n* 无任务分片\n### elastic-job\n>elasticjob的初衷是为了面对高并发复杂的业务，即使是在业务量大，服务器多的时候也能做好任务调度，尽可能的利用服务器的资源。使用ZooKeeper使其具有高可用、一致性的，而且还具有良好的扩展性。官网上写elasticjob是无中心化的，通过ZooKeeper的选举机制选举出主服务器，如果主服务器挂了，会重新选举新的主服务器。因此elasticjob具有良好的扩展性和可用性，但是使用和运维有一定的复杂。\n### xxl-job\n>xxl-job则相反，是通过一个中心式的调度平台，调度多个执行器执行任务，调度中心通过DB锁保证集群分布式调度的一致性，这样扩展执行器会增大DB的压力，但是如果实际上这里数据库只是负责任务的调度执行。但是如果没有大量的执行器的话和任务的情况，是不会造成数据库压力的。实际上大部分公司任务数，执行器并不多(虽然面试经常会问一些高并发的问题)。\n相对来说，xxl-job中心式的调度平台轻量级，开箱即用，操作简易，上手快，与SpringBoot有非常好的集成，而且监控界面就集成在调度中心，界面又简洁，对于企业维护起来成本不高，还有失败的邮件告警等等。这就使很多企业选择xxl-job做调度平台。\n\n\n\n## MQ\n### RabbitMQ\n>优秀博文：https://baijiahao.baidu.com/s?id=1737713844357727373&wfr=spider&for=pc\n>- - -\n>* 消息消费失败，由于retry重试机制，重新入队又将消息发送出去。\n>* 消息确认机制影响性能，非必要不使用；\n>* 消费者先保证消息能签收，业务处理失败可以人工补偿。\n>- - -\n1. 交换机类型\n    - FanoutExchange : 广播交换机，适用于简单模式、订阅模式、工作队列模式\n    - DirectExchange : 路由定向交换机，适用于路由模式\n    - HeadersExchange: 头交换机，适用于路由模式, 路由交换机的路由是基于路由键，头交换机的路由值基于消息的 header 数据。\n    - TopicExchange : 主题交换机，适用于通配符模式\n\n2. 重复消费问题\n    - 产生原因   \n        - 消息消费成功: 事务已提交，签收时结果服务器宕机或网络原因导致签收失败，消息状态会由unack转变为ready，重新发送给其他消费方\n        - 消息消费失败: 由于retry重试机制，重新入队又将消息发送出去。\n    - 解决方案\n        - 开启手动ACK的机制，当消费端消费成功之后会给服务端发送一条确定信息，当收到确认信息之后，我们在服务端才让下一个消息进行消费。默认是自动ACK，也就是消费端消费成功了不会发送信息给服务端。\n        - 使用唯一的消息ID，并存到数据库中，每次消费者消费之前都去检查一下这条消息是否被消费过，如果没有才进行消费\n        - 使用分布式锁的方式，比如说redis的分布式锁命令setNX\n\n3. 如何保证消费顺序\n    - 在生产端可以给每个消息一个序号，然后消费端按照排序的序号进行消费\n    - 采用单队列单消费者的模式，将同一消息类型的消息放到一个队列中去，因为消费顺序主要是由于不同消费端对不同消息的处理能力不同导致的\n\n4. 消息丢失\n    - 产生原因\n        - 消息发出后，中途网络故障，服务器没收到；\n        - 消息发出后，服务器收到了，消费方还未处理业务逻辑，服务却挂掉了，而消息也自动签收，等于啥也没干。\n    - 解决方案\n        - confirm模式 ： 保证生产端到交换机这段路，消息无论是否成功被交换机拿到，都要返回一个确认消息\n        - return模式： 保证交换机到队列这段路，消息没能到队列才发送一个返回消息。\n        - 手动ACK模式：消费成功才将消息移除，失败或因异常情况而尚未处理，就重新入队。\n\n### Kafka\n1. 消息丢失\n    - 解决方案\n        - 服务端持久化设置为同步刷盘：消息投递到broker的时候，需要将消息进行持久化，分同步刷盘和异步刷盘，同步刷盘的话可保证消息一定不丢失，就算丢失了也可以选择即时补偿，也就是重新发一次\n        - 生产者设置为同步投递：使用带有回调通知的send方法，并且设置acks = all，则可保证是同步方式，也就是说必须要让服务器确认收到消息之后才会继续往下执行。如果服务器没来得及接收就宕机了，也可以保证消息不丢失，因为生产者在投递消息的时候会有记录日志，等服务器重启之后，可以通过日志信息去完成对消息的补偿\n        - 消费者设置成手动ack提交: kafka中，消息消费完成之后不会立即删除，而是使用定时的清除策略，当我们确保消息成功消费之后，我们要进行手动的ack提交，如果消息失败，则要不断重试\n2. 消息顺序\n    - 触发场景\n        - 一个topic有多个partition，producer生产者将一组有序的消息被分散发送到了不同的partition\n        - 多个消费者消费了同一个partition的消息\n    - 解决方案\n        - 单线程发送消息到MQ，单线程对MQ进行消费，即消费者和生产者都是单线程的，且 Topic中只有一个partition\n3. 重复消费\n    - 触发场景\n        - 消费者宕机且还未来得及向GroupCoordinator的_consumer_offsets提交位移，默认是每5s提交一次，重启后会导致重复消费的问题\n        - 消费端处理性能较低，在默认的5分钟以内没办法处理完消息，则会触发Rebalance机制，原分区交给其他的消费者消费了，但是由于_consumer_offsets的滞后性，所以原分区仍然会存在一部分消息会被新的消费者重复消费\n    - 解决方案\n        - 采用异步的方式处理消息，缩短消息的消费时长\n        - 调整消息处理的默认时间，可以拉长一点，避免触发rebalance机制\n        - 对每个消息都设置一个唯一键，可以保存在mysql或者redis中，在消费消息之前先去mysql或者redis中判断是否该消息已经被消费，如果被消费了则跳过消费\n\n4. Kafka的选举策略\n    - Controller的选举\n        - 原理：所有的broker都尝试去在zookeeper中创建一个临时的节点controller，谁先创建成功，谁就担任了controller的角色，如果挂了或者网络出现问题，则临时节点就会消失，需要按先到先得来重新选举。\n        - 职责：\n            - 监听Broker、Topic、Partition的变化\n            - 获取和管理Broker、Topic、Partition的信息\n            - 获取Partition的主从信息，并参与leader的选举过程\n    - Leader的选举\n        - 原理：在ISR集合中的副本通常是与原leader保持数据同步的副本，具有优先被选择权，默认让ISR的第一个副本成为Leader。但是如果ISR中没有副本，则可以通过调整设置，默认让拥有最新数据的那个副本成为leader\n\n\n\n\n\n## 基础学科\n### 数据结构\n1. HashMap的原理\n    - 负载因子：默认0.75，且键值对都可以为null\n    - 扩容倍数：默认扩容到原来的两倍\n    - 在jdk1.7与jdk1.8的区别：\n        - 数据结构：jdk1.7是数组+链表，jdk1.8引入了红黑树这样一种综合能力强的数据结构\n        - 插入方法：jdk1.7是采用的头插入法来将元素插入进链表，这可能导致链表倒置，形成循环链表，jdk1.8是采用的尾插法来将元素插入进链表\n        - 扩容优化：数组容量大于64且链表长度大于8，会首先将链表转成红黑树，并不会直接扩容\n    - 为什么使用红黑树\n        - 红黑树也是一种平衡二叉树，它各个节点着色方式的限制，确保没有任意一条从根到叶子的路径超过最短路径的两倍。它是一种弱平衡二叉树，但是它有着良好的稳定性和完整的功能，性能表现也很不错，综合实力强。相对于AVL树来说，红黑树的旋转次数少，对于搜索、插入、删除多的操作下用红黑树就更为合适了。\n    - 多线程导致的问题\n        - 线程安全问题：HashMap不是线程安全的，多个线程同时对HashMap进行操作可能会导致数据的不一致性，例如put和remove操作可能导致元素丢失或重复等问题。\n        - 性能问题：当多个线程同时对HashMap进行操作时，由于需要进行锁竞争或者CAS操作，可能会导致性能下降，尤其是在高并发情况下。\n\n2. Concurrenthashmap原理\n    - 键值对：键不可以为null，但是值可以为null，但是HashTable的键值对都不能为null\n    - 数据结构\n        - jdk1.7：JDK 1.7 中的 ConcurrentHashMap 的每个Segment段中的数据结构是数组+链表\n        - jdk1.8：而在 JDK 1.8 中，ConcurrentHashMap 使用了更为高效的数据结构，引入了红黑树。\n    - 并发度\n        - jdk1.7：JDK 1.7 的 ConcurrentHashMap 的并发度是固定的，即段的数量是固定的，由构造函数中的参数指定。\n        - jdk1.8：在 JDK 1.8 中，ConcurrentHashMap 不再使用固定的段，精确到了每个bucket桶，并根据实际数据和并发访问情况来动态地扩展和收缩哈希表的大小，使其并发性能更好。\n    - 锁粒度\n        - jdk1.7：JDK 1.7 的 ConcurrentHashMap 使用分段锁，即每个段都有一个独立的锁来保护它的元素。这意味着不同的线程可以同时访问和修改不同的段，从而提高并发性能。\n        - jdk1.8： JDK 1.8 中，ConcurrentHashMap 引入了更细粒度的锁策略，即将锁的粒度缩小到每个桶（bucket）级别，也就是数组中的每个元素都有一个独立的锁。\n    - 锁策略(针对于put或者remove操作)\n        - jdk1.7：每个segment段是使用的ReentrantLock来加锁的\n        - jdk1.8: 采用CAS+synchronized的机制。如果对应下标处没有结点，说明没有发生哈希冲突，此时直接通过CAS进行插入，若成功，直接返回。若失败，则使用synchronized进行加锁插入。\n\n    - 和HashMap的区别\n        - ConcurrentHashMap采用了分段锁技术来保证并发访问的线程安全性，在加锁的时候不必要锁住整个Map\n        - ConcurrentHashMap在扩容时只需要对Segment段进行扩容，而不需要对整个Map进行扩容，因此扩容的代价相对较小\n        - ConcurrentHashMap对于读操作和写操作进行了分离，对于读操作没有加锁，可以实现读取的高并发性\n\n\n3. B树和B+树之间的区别\n    - B树\n        - 它是一种多路的平衡搜索树。\n        - 它跟普通的平衡二叉树的不同是，B树的每个节点可以存储多个数据，而且每个节点不止有两个子节点，最多可以有上千个子节点。\n        - B树中每个节点都存放着索引和数据，数据遍布整个树结构，搜索可能在非叶子节点结束，最好的情况是O(1)。\n\n    - B+树\n        - B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快。\n        - B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定\n        - B+树区间查询更方便：B+树所有的叶子节点数据构成了一个双向链表，在查询大小区间的数据时候更方便，数据紧密性很高。\n        - B+树全节点遍历更快：B+树遍历整棵树只需要遍历  所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。\n    \n    \n    - InnoDB为什么选择B+树\n        - 扫库、扫表能力更强：如果我们要对表进行全表扫描，只需要遍历叶子节点就可以了，不需要遍历整棵B+树\n        - 数据连续可达：叶子节点上有下一个数据区的指针，数据形成了链表\n        - 效率稳定：B+树永远是在叶子节点拿到数据，所以IO次数是稳定的，而B树运气好的话根节点就能拿到数据，运气不好就要到叶子节点才能拿到数据，所花费的时间会有差异。\n\n4. 队列和堆栈\n    - 队列\n        - 顺序：先入先出\n        - 可在一端插入，另一端删除\n        - 可基于地址指针，从头部或者尾部来遍历，且不需要开辟临时空间，遍历速度更快\n        - 场景：任务调度、消息传递等场景\n    - 栈\n        - 顺序：后入先出\n        - 插入和删除在同一端\n        - 只能从顶部取数据，且需要开辟临时空间，如若要取栈底的元素，得先把所有元素给取出来一遍才行，遍历速度更慢\n        - 场景：回溯、表达式求值\n\n5. 压缩列表\n    - 概念：为了更好的利用数组的优势（排列紧凑，内存连续），同时避免内存浪费，每个节点可以存放不同大小的元素\n    - 组成部分：\n        - zlbytes：记录整个压缩列表占用的内存字节数\n        - zltail：偏移量，记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，可以计算出表尾节点的地址\n        - zllen：压缩列表包含的节点数量\n        - entry：列表节点\n            - previous_entry_length: 记录上一个节点的长度，为了方便反向遍历ziplist\n            - encoding: 当前节点的编码规则，记录了节点的content属性所保存数据的类型以及长度\n            - content: 当前节点的值，可以是数字或字符串。\n        - zlend：用于标记压缩列表的末端\n\n\n### 计算机网络\n1. TCP和UDP (传输层协议)\n    - 比较\n        - 可靠性：TCP是一种面向连接的协议，提供可靠的数据传输。它使用确认、重传和流量控制等机制来确保数据的完整性和顺序。UDP是一种无连接的协议，不提供可靠性保证，数据传输可能丢失、重复或乱序。\n        - 连接过程：TCP建立连接和断开连接的过程较为复杂，包括三次握手和四次挥手，确保通信双方建立可靠的连接。UDP没有连接建立的过程，每个数据包都是独立的，可以直接发送。\n        - 速度和效率：由于TCP提供可靠性保证和连接管理，它的开销较大，传输速度相对较慢。UDP没有这些额外的开销，因此传输速度较快，效率较高。\n        - 数据量限制：TCP对数据包的大小有限制，因为TCP报文段的最大长度受到网络的最大传输单元（MTU）限制。UDP没有这个限制，可以发送更大的数据包。\n\n    - TCP可靠性的保证\n        - 确认机制：TCP将每个发送的数据包进行编号（序列号），接收端通过发送确认消息来确认已经成功接收到的数据。如果发送端没有收到确认消息，就会重新发送数据。\n        - 超时与重传：TCP使用超时重传机制。如果发送端在合理的时间内没有收到确认消息，就会认为数据包丢失，触发重传机制，重新发送数据。\n        - 流量控制：TCP通过使用滑动窗口机制进行流量控制。接收端通过发送窗口大小的信息告知发送端自己的可接收数据量，以避免发送太多数据导致接收端无法处理。\n\n    - TCP粘包问题\n        - 概念：当发送方在短时间内连续发送多个数据包时，接收方在接收数据时可能会将多个数据包合并成一个数据包，从而导致数据包大小超过了接收缓冲区的大小，这就是所谓的粘包问题。\n        - 导致原因：由于数据包的边界不明确或者多个数据包连续发送导致接收端难以正确解析和处理数据\n        - 解决方案：\n            - 采用特定的分隔符。发送方在发送数据包之前，在数据包中加入特定的分隔符，接收方在接收数据包时根据分隔符将数据包进行分割。\n            - 采用消息头和消息体。发送方在发送数据包之前，在数据包中加入消息头和消息体，消息头用于标识消息体的长度和类型，接收方在接收数据包时根据消息头将数据包进行分割。\n            - 定长包格式：可以使用定长的包格式，确保每个数据包都具有相同的长度。接收端按照固定长度进行解析，从而避免了粘包问题。但是这种方法可能会浪费一些空间，因为包中的数据长度不一定总是满载。\n\n2. http与https(应用层协议)\n    - http\n        - 概念：HTTP代表超文本传输协议，它是用于在Web浏览器和Web服务器之间传输数据的协议。\n        - 机制：HTTP协议是明文传输数据的，这种明文传输数据的方式存在一定的风险，特别是在传输敏感信息时。\n    - https\n        - 概念：HTTPS代表安全超文本传输协议，它是HTTP协议的安全版本。\n        - 机制：在HTTPS下，传输的数据是通过SSL或TLS加密的，这样攻击者即使截取到了数据，也无法轻易地解密和阅读其中的内容。HTTPS还能够验证服务器的身份，确保用户正在与其信任的网站通信，而不是被攻击者伪装的恶意网站。\n\n3. Http状态码\n    - 200 OK：请求成功。服务器成功处理了请求，并返回了请求的数据。\n    - 301 Moved Permanently：永久重定向。请求的资源已被永久移动到新的URL。\n    - 302 Found：临时重定向。请求的资源已被临时移动到新的URL。\n    - 400 Bad Request：错误请求。服务器无法理解请求，因为请求中包含语法错误。\n    - 401 Unauthorized：未授权。请求需要用户身份验证，但用户未提供有效的身份验证信息。\n    - 403 Forbidden：禁止访问。服务器拒绝了请求，因为请求者没有访问资源的权限。\n    - 404 Not Found：未找到。服务器无法找到请求的资源。\n    - 500 Internal Server Error：服务器内部错误。服务器遇到了意外的情况，无法完成请求。 \n\n\n4. 不同层级的协议\n    - 物理层\n        - RS-232：用于串行通信的标准接口协议\n        - USB\n    - 数据链路层\n        - WIFI\n        - VLAN：虚拟局域网\n        - PPP协议：点对点协议\n        - ARP协议：地址解析协议，用于将IP地址映射到物理地址\n    - 网络层\n        - IP协议：使用IP地址来标识互联网中的所有设备、也用于在网络中传输数据包，无连接传输\n        - ICMP协议：是一种面向无连接的协议，用于传输出错报告控制信息\n    - 传输层\n        - TCP协议：一种面向连接的、可靠的、基于字节流的传输层通信协议\n        - UDP协议：是无连接的协议，通信双方在传输数据之前不需要建立连接，也不需要进行连接的释放。每个数据包都是独立的，不会建立持久性的连接。\n        - TLS协议：在两个通信应用程序之间提供保密性和数据完整性\n    - 会话层\n        - LDAP协议：(轻型目录访问协议)、通过IP协议提供访问控制和维护分布式信息的目录信息\n    - 表示层\n        - LPP协议：轻量级会话协议、描述了在某些受限条件下提供基于 TCP/IP 网络的 OSI 应用程序服务器的流线支持的方法\n    - 应用层\n        - HTTP协议：超文本传输协议，规定web服务端和客户端的数据传输格式\n        - HTTPS协议：超文本传输安全协议，是HTTP加上TLS/SSL协议构成的可加密传输的网络协议\n        - DNS协议：域名解析协议、将域名解析为IP地址\n        - FTP协议：文件传输协议、网络共享文件传输\n\n5. 输入url到响应的整个过程\n    - 浏览器首先检查输入的URL的格式是否正确。一个完整的URL应包含协议部分（如HTTP或HTTPS）、域名或IP地址、以及查询参数等组成部分。\n    - 如果URL格式正确，浏览器会解析URL获取域名或IP地址。如果用户输入的是域名，浏览器会将其解析为对应的IP地址，这个过程通常通过DNS来完成。\n    - 浏览器建立与服务器的网络连接。它首先通过向目标服务器的IP地址发送一个TCP连接请求来建立一个TCP连接。这个过程通常使用三次握手来确保连接的可靠性。\n    - 一旦建立了TCP连接，浏览器会发送一个HTTP请求到服务器。\n    - 服务器接收到浏览器发送的HTTP请求后，会根据请求的内容进行处理。\n    - 服务器处理完请求后，会生成一个HTTP响应。\n    - 服务器过建立的TCP连接进行传输,将生成的HTTP响应发送回浏览器。\n    - 浏览器接收到HTTP响应后，会根据响应的内容进行处理。\n    - 浏览器将解析后的页面显示给用户，用户可以看到页面内容。\n    - 在HTTP/1中，浏览器与服务器之间的默认行为是在每个请求-响应周期结束后关闭连接。在HTTP/2中，引入了多路复用的概念，允许在同一连接上同时发送多个请求和响应。这样，连接在一个页面加载完成后并不会立即关闭，而是继续保持打开状态，以供后续请求使用。如果在一段时间内没有请求或通信发生，TCP连接就会超时并自动关闭。\n\n\n6. http连接和tcp连接的区别\n    - http是一种应用层协议，它在Web应用中使用，用于在客户端和服务器之间传输超文本数据，HTTP连接是基于TCP连接的。HTTP协议在TCP连接上定义了请求和响应的格式和规则，包括请求方法、请求头、响应状态码等。TCP负责提供可靠的数据传输，而HTTP负责定义应用层的通信规则和数据格式。\n\n7. HTTP缓存\n    - 强制缓存\n        - 概念：只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边\n        - 字段：响应头：CacheControl(优先级大于Expires，记录的是相对时间)、响应头：Expires(记录的是绝对时间)\n        - 流程：浏览器首先判断该资源是否在本地有缓存，如果有，则先去访问浏览器的本地缓存，并通过当前访问时候和CacheControl记录的时间来判断当前资源是否已经过期，如果未过期就直接使用浏览器本地缓存，如果已经过期则重新请求服务器并更新CacheControl的字段\n\n    - 协商缓存\n        - 概念：与服务端协商之后，通过协商结果来判断是否使用本地缓存\n        - 字段: 响应头：Etag，请求头：If-None-Match\n        - 流程：当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在响应头加上ETag唯一标识，这个唯一标识的值是根据当前请求的资源生成的，当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期，如果未过期则直接使用，如果过期了，则在请求头部加上If-None-Match字段，字段是ETag的值，并发送请求到服务端并在服务器端比较该资源的唯一标识是否变化，如果没变化则返回304，如果变化了则返回200并更新ETag，且返回新资源\n\n### 操作系统\n1. 进程和线程的区别\n    - 根本区别：进程是操作系统进行**资源分配**的最小单元，线程是操作系统进行**运算调度**的最小单元。\n    - 从属关系不同：进程中包含了线程，线程属于进程。\n    - 开销不同：进程的创建、销毁和切换的开销都远大于线程。\n    - 拥有资源不同：每个进程有自己的内存和资源，一个进程中的线程会共享这些内存和资源。\n    - CPU利用率不同：进程的CPU利用率较低，因为上下文切换开销较大，而线程的CPU的利用率较高，上下文的切换速度快。\n\n2. 死锁产生原因及解决办法\n    - 死锁指多个线程在执行过程中，因争夺资源造成的一种相互等待的僵局\n    - 解决方案：\n        - 互斥条件：一个资源只能被一个线程占有，当这个资源被占用后其他线程就只能等待。\n        - 不可剥夺条件：当一个线程不主动释放资源时，此资源一直被拥有线程占有。\n        - 请求并持有条件：线程已经拥有一个资源后仍然不满足，又尝试请求新的资源。\n        - 环路等待条件：产生死锁一定是发生了线程资源环路链。\n\n3. 线程之间通信的方式\n    - 共享内存（Shared Memory）：多个线程可以通过访问相同的内存区域来进行通信。线程可以读取和写入共享内存中的数据来进行信息交换。由于多个线程同时访问共享内存，因此需要使用同步机制（如互斥锁）来保证数据的一致性和避免竞态条件。\n    - 信号量（Semaphore）：信号量是一个计数器，用于控制多个线程对共享资源的访问。线程在访问共享资源之前需要获取信号量，如果信号量计数器大于零，则允许访问；如果计数器为零，则线程被阻塞，直到其他线程释放信号量。通过适当的计数器设置，可以控制线程的并发访问量。\n    - 互斥锁（Mutex）：互斥锁用于保护共享资源，确保在同一时间只有一个线程可以访问共享资源。线程在访问共享资源之前需要获取互斥锁，如果锁已被其他线程获取，则线程被阻塞，直到锁被释放。互斥锁可以防止多个线程同时访问共享资源，从而避免数据的不一致性和竞态条件。\n    - 管道（Pipe）：管道是一种单向的、有序的数据通信机制。它可以在父进程与子进程之间或者同一进程的不同线程之间进行通信。一个线程可以将数据写入管道的写端，而另一个线程可以从管道的读端读取数据。管道可以用于在线程之间传递数据或消息。\n    - 消息队列（Message Queue）：消息队列是一种在多个线程之间传递消息的通信方式。线程可以将消息放入队列中，而其他线程可以从队列中获取消息。消息队列可以按照一定的优先级和顺序来处理消息，方便线程之间的协作和通信。\n\n4. 进程之间的调度策略\n    - 先来先服务（FCFS）：按照任务到达的顺序，按照先后次序分配CPU时间片，即先到先服务。这种策略简单直观，但可能导致长作业优先，造成短作业等待时间过长。\n    - 短作业优先（SJF）：根据任务的执行时间长度，优先分配执行时间短的作业。这种策略可以减少平均等待时间，但需要预先知道任务的执行时间，不适用于实时环境。\n    - 优先级调度(剥夺策略)：为每个任务分配一个优先级，按照优先级高低分配CPU时间片。可以根据任务的重要性、紧急程度等来设置优先级。然而，这种策略可能导致优先级较低的任务长时间等待，出现饥饿问题。\n    - 时间片轮转（Round Robin）：将CPU时间分成若干个时间片，每个任务轮流执行一个时间片。当一个时间片用完后，任务被挂起，等待下一个时间片再次执行。这种策略可以确保公平性，但可能导致上下文切换频繁。\n\n\n\n# 实习总结\n## 第一段实习\n### SparkSQL脚本编写\n由于之前有很多统计的数据是运营自行用excel手动统计的，后续希望改成由系统来自动运算并进行统计，所以需要编写的sql脚本来对对海量数据进行统计和聚合，平均一个脚本大约有300行代码，并可将结果导出为excel。在写完脚本之后也会通过这样运营提供的数据进行比较来找出sql脚本的逻辑与运营逻辑的出入，并进行修复\n\n### 支付模块\n需求背景上这样的，当时是品牌方搞了一个品牌新用户的一个活动，这个活动是所有平台共用的，也就是说如果这个用户在淘宝上已经下单购买了，那么他将不能再到我们的小程序中使用这个新用户的资格了。于是我们在开发支付功能的时候，当时大家就在下单的界面访问了第三方系统来判断该用户是否还有新资格，但是在开发过程中，我就发现了一个漏洞，因为我们还有一个二次支付接口，也就是下单但不支付，就会落入到二次支付接口去，也就是说，如果我下单但不支付，就卡在二次支付接口这里，然后去淘宝再下单支付一次，那么我们的小程序就检测不到用户的新资格已经被消耗掉了，所以我便把漏洞讲给了项目经理听，最后我们便在二次支付接口进行了二次校验，来避免这个漏洞带来的损失。\n\n### 线上问题的排查\n- git脏代码上线\n当时的情况是这样的，我们那个时候开发完功能之后，是在周五的时候做了测试，然后本来是预计下周一来上线的，然后等周一下午上线之后，没多久就有人反应说那功能用不了，爆错了，然后我就去看那个日志打印，一看说是unkown colmun，很明显就是mybatisplus去做全查询然后查了数据库中没有的字段，然后我就根据日志找到那个类，发现多了一个app_key的字段，然后一看提交记录，发现有人在周一上午在我们分支提交了代码，然后就找到那个人问他咋回事，他说他不小心切错分支了，也上了灰度环境，然后就在我们的代码里的一个实体类中新增了一个字段，但是我们数据库中还没有执行相应的sql，就导致了我们把他的脏代码也带到了线上的环境，最后就产生了这个线上问题。解决方案：先执行sql语句把线上问题解决了再说，然后在原有的业务分支的基础上，放弃别人提交的版本，在自己最新提交的版本上重新新建一个分支出来，并且将master分支回滚，然后重新将master分支和我们的新分支进行反合，最后重新提交merge-request来重新将代码分支合并到master分支上。\n\n### 排行榜\n当时的需求是需要根据订单的信息来统计分销员的业绩，而订单信息是属于海量信息，不可能直接在mysql中进行处理，那样的处理效率会很慢。而订单信息的源数据也是通过大数据搜集来的，所以在大数据平台的hive表里也存储着订单的信息，所以我就在大数据平台使用了Spark来进行订单表的分销业绩的统计与聚合，最后将计算之后的结果存回mysql的分销员业绩表，并通过order by对指定字段进行排序，从而实现排行榜的功能\n\n## 话费充值系统的开发\n## 第二段实习\n- 架构\n    - 应用框架：SpringBoot\n    - 数据库框架：Mybatis\n    - RPC框架：Dubbo\n    - 监控：Grafana\n    - 接口管理：dubboKeeper\n    - 注册中心：Zookeeper\n    - 配置中心：Apollo\n    - 链路追踪：Pinpoint\n    - 限流框架：Sentinel\n    - 部署：K8S\n    - 任务调度框架：xxl-job、Elastic-job\n    - MySQL语句审核：YearningSQL\n    - 项目管理：禅道\n    - 日志处理：EKL(Elasticsearch+Logstash+Kibana)\n\n- 为什么折线图选用ES而不用MySQL\n    1. 需要频繁地进行时间范围内的聚合、分析，ES可能更适合。ES针对时间序列数据的索引和查询做了优化，使得实时聚合和检索非常高效\n    2. ES在实时搜索和分析方面表现得非常出色。它可以快速索引新数据，并在实时的情况下提供查询结果，非常适合需要及时反馈的场景，MySQL也可以实现实时查询，但在复杂查询的情况下，性能可能受到一定限制。\n    3. ES的扩展性更高，实际上我们业务的计算，可能在筛选条件上经常会变换，如果用mysql那么我们就需要建立组合索引，一旦新增了字段，就要重构索引，这个是比较低效的。而ES由于底层的倒排索引，所以在此业务场景下，就更具有优势了\n    4. Elasticsearch不限于固定的数据模式，适用于半结构化和非结构化数据，它允许动态添加字段，非常灵活，而MySQL要求定义固定的表结构，适合于结构化数据\n\n# 项目积累\n## 校疫通\n### 项目难点及解决方案\n- 二级缓存的设置,将它放在哪比较合适\n    - 要将很多统计维度的数据放到缓存中去，避免每次访问首页都去查一遍DB\n    - 使用Caffine + Redis构建二级缓存，使用SpringAOP将其独立出来\n    - 因为是按天统计的，所以对于一致性的要求只需要按天来同步信息就好\n\n- 如何优雅地使用SpringSecurity来实现用户的鉴权和认证\n    - 采用 RBAC0 权限模型、将管理员用户、角色、权限、受保护的 URL 都放入到 MySQL 中并建立相应联系\n    - 合理使用SpringSecurity的过滤链，使用数据源、管理器等资源实现系统的权限及认证管理\n\n- 如何让前端更方便地测试\n    - Swagger写接口文档\n    - 部署到云服务器\n\n### 项目板块\n## 话费充值系统\n### 架构图\n<img src = \"http://xtzl.wentexl.cn/%E8%AF%9D%E8%B4%B9%E5%85%85%E5%80%BC%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.png\"/>\n\n### 项目难点\n#### 项目简述\n - 流程简述：整个系统是由两大系统组成，一个系统是推单系统，主要负责接收订单、一个系统是配单系统，主要负责处理订单，最开始的流程是这样的：pdd商户将订单推送到推单系统中，推单系统落库之后将订单推送给配单服务，而配单服务会去调用运营商代理提供的第三方接口来获取一个支付凭证，并将这个凭证传给下游，下游拿到这个凭证之后将回调配单系统，然后配单系统重新回调推单系统， 推单系统又会回调pdd商户，但是整个流程都基于同步实现的。\n\n#### 项目并发问题\n- 问题描述：最初整个系统都是同步调用的，如果说由于网络抖动等原因，就可能导致大量线程被阻塞，从而不断滚雪球，导致服务崩溃。而且如果一旦请求出了问题，难以定位到问题所在的地方。\n- 问题解决方案：拆异步，搞批量\n\n**1. OOM问题**\n- 问题描述：在配单系统与运营商代理这块，前期是基于同步调用的，如果发生的网络抖动，哪怕是一两分钟，就可能造成成百上千的线程阻塞，jvm不断的新建线程，就像滚雪球一样，从而导致内存溢出的问题\n- 解决方案：拆一个推送服务出来，异步调用第三方系统的接口\n    - 具体实施：配单系统将订单信息推送到Redis中去，然后推送服务会开启定时任务，我们设置的是1s，也就是说每秒钟都会去拉取我们redis中的订单信息，并批量地向第三方系统发起请求调用，获取支付凭证，并将获取到的支付凭证都统一存回redis中，以便于下游调用\n\n**2. 解决死锁问题**\n- 问题描述：当配单系统回调推单系统的时候，推单系统会做两件事，第一件事是通知上游，第二件事是修改配单系统的回调状态，那就有可能存在，在通知上游成功之后，我们去redis里拉回订单的时候，不是我们推过去 的顺序，就可能导致死锁问题的发生\n- 解决方案：将redis换成消息中间件，保证消息一定是按顺序消费的\n\n**3. token重复刷新问题**\n- 问题描述: 我们去调用运营商接口的时候是有一个密钥token的，这个token是有过期时间的，过期时间是半个小时，过了这个过期时间之后就需要刷新一次，但是如果在过期之后同时有多个请求到达，则会造成不必要的刷新次数\n- 解决方案：使用redis锁控制只有一个请求去刷新，加锁也需要设置其他线程最多等待的时间，并且在控制的时候需要加个时间的判断，又担心如果只有一个线程去刷新，可能意外没有刷新成功，所以我们所有的请求都会自旋三次来获取这个锁\n\n**4. Redis的存储结构**\n- 问题描述：从推单系统到配单系统的redis是set结构，放置推重复的订单。从配单系统到下游的redis是list结构，主要是因为支付凭证是有时间限制的，3min之后将会过期，如果支付凭证都存在list中，供下游一条一条地拉取处理，如果说下游处理能力不够强，或者出现了性能方面的问题，则为了尽可能的保证list中的支付凭证能被及时处理，我们将处理最晚入list的，也就是有效时间最长的那个\n\n","categories":["Interview"],"tags":[]},{"title":"BigData-HBase","url":"/posts/10071/","content":">总结关于了HBase的相关内容\n<!--more-->\n# HBase的启动\n>端口:16010\n\n# HBase的常用Shell命令\n1. jps查看守护进程(Linux的命令)\n2. Ctrl + Delete才能删除输入错误的命令\n3. exit 退出命令窗口\n4. 命名空间\n    - list_namespace : 列举命名空间\n    - create_namespace 'XXX' : 创建命名空间\n    - describe_namespace 'XXX' : 查看某个命名空间的相关信息\n    - alter_namespace 'XXX' ,{METHOD =>'set','hbase.namespace.quota.maxregion'=>'10'}: 修改命名空间的相关信息\n\n5. 表的创建\n    - create 'namespace:tableName','列族名1',....,'列族n'(无参数设置)\n    - create 'namespace:tableName',{name=>'列族1',versions=>1.....},{name=>'列族2'},'列族名3'\n    - create 'namespace:tableName','f1',SPLITS=>['10','20','30','40'] (设置4个分隔点，则是5个region)\n\n6. 查看表\n    - desc 'namespace:tableName' :查看制定表的结构\n    - count 'namespace:tableName' : 查看表中有多少个行键(类比关系型数据库的多少条记录)\n\n7. 修改表\n    - alter 'namespace:tableName',{name=>'列族1',version=>2}  (列族存在则修改，不存在就是添加)\n    - alter 'namespace:tableName',{name=>'列族2',METHOD='Delete'}\n\n8. 删除表\n    - 先disable 'namespace:tableName' :禁用表之后才能删除表\n    - drop 'namespace:tableName' :删除表\n\n9. 表数据增加\n    - put 'namespace:tableName','行键','列族:列限定符','插入值'\n    - put 'namespace:tableName','行键','列族:列限定符','插入值',时间戳\n\n10. 表数据查看\n    - get 'namespace:tableName','行键',{其他参数}\n    - get 'namespace:tableName','行键',{COLUMN=>'course',....} // 只看course列族\n    - get 'namespace:tableName','行键',{COLUMN=>'course:english'} // 只看英语成绩\n    - scan 'namespace:tableName' //全表扫描，全表数据都有\n\n11. 表数据修改\n    - delete 'namespace:tableName','jim','course:chinese' // 删除的默认是最新版本的数据，只能删一个列族的数据\n    - deleteall 'namespace:tableName','行键' //删除的是某个行键所对应的所有列族的数据\n    - truncate 'namespace:tableName' // 删除整个表中的数据,只保留一个region\n    ","categories":["Bigdata"],"tags":[]},{"title":"Algorithm-think","url":"/posts/2170/","content":">总结了关于算法的一些思路\n<!--more-->\n# 最小的连续因子序列  \n> for(inti=2; i*i<n; i++) 应当从2开始找  \n>最多找到i²<n的时候，因为我们要从i开始往后找连续的片段，而当i*i>=n的时候，i*(i+1)必然> 大于n，这时就没有必要继续遍历下去了  \n>大体思路无非是从2开始往后找，找到第一个因子之后，以此为基础嵌入一个循环去找以i为第一个因子，后续能构成一个长度为多大的连续因子序列。","categories":["Algorithm"],"tags":[]},{"title":"WritingPart-Baidu","url":"/posts/10408/","content":">百度的笔试复盘记录\n<!--more-->\n# 1，Cookie和Session\n>* Session的安全性更高\n>* 如果用户禁止cookie，服务器仍会将sessionId以cookie的方式发送给浏览器，但是，浏览器不再保存这个cookie(即sessionId)了如果用户禁止cookie，服务器仍会将sessionId以cookie的方式发送给浏览器，但是，浏览器不再保存这个cookie(即sessionId)了\n>* cookie默认是会话cookie，保存在内存中，浏览器退出就会过期，但是如果持久化cookie后将会保存在磁盘中\n\n# 2，出栈方案\n> f(n) = ∑(i=0;n-1)f(i)*f(n-1-i),  f(0) = f(1) = 1  \n> 若有7个元素，则出栈方案有 f(7) = f(0)f(6)+f(1)*f(5)+....+f(6)*f(0)\n\n# 3，Select\n>* 只要unacid存在数据，则对manager_code表进行全查询  \n```sql\nSELECT * FROM `manager_code` WHERE EXISTS (SELECT 0 FROM `unacid`);\n```\n>* 无须关注表中具体数据，只需知道表中有多少条记录，用以下可以提高查询效率\n```sql\n- 不管输出的是什么，不妨碍exists判断记录条数\nselect 0 from table;\nselect 1 from table;\nselect null from table;\nselect false from table;\n```\n# SQL\n>* avg会自动过滤掉为null的记录\n```sql\nSELECT AVG(work_code) FROM `manager_code`;\n```\n>* NULL不是一个值，只是一个标记\n>* 不能用 =NULL，因为=NULL表示的是某个地方的值为NULL，而isNULL表示某个地方是否是有NULL这个标记\n","categories":["Interview"],"tags":[]},{"title":"AC-windowsWords","url":"/posts/46298/","content":">windows操作命令\n<!--more-->\n# 端口\n## 查看所有端口\n>netstat -ano\n## 查到指定端口占用情况\n>netstat -ano |findstr \"XXXX\"\n## 结束进程\n>taskkill /pid XXXX -f\n","categories":["Accumulate"],"tags":[]},{"title":"BigData-HDFS","url":"/posts/32491/","content":">关于HDFS的相关操作\n<!--more-->\n# 文件操作命令\n- **创建文件**\n  - hdfs dfs -mkdir -p <Path>\n\n- **显示目录**\n  - hdfs dfs -ls /\n\n- **文件上传**\n  - -f是强制覆盖  \n  - hdfs dfs -put [-f][-p] <localsrc> <dst>\n- **文件合并后上传**  \n  - hdfs dfs -appendToFile /root/opt/*.* /user/root/txtdir/merge.txt\n\n- **文件下载**\n  - hdfs中文件合并后下载\n    - hdfs dfs -getmerge /user/root/txtdir/*.* /root/opt/join.txt\n  - 直接从hdfs下载文件到本地\n    - hdfs dfs -get /user/root/a.txt /root/opt/join.txt\n\n\n- **文件内容查询**\n  - hdfs dfs -cat /user/root/txtdir/a.txt\n\n-  **文件删除**\n  - ```txt hdfs dfs -rm <pathURL> ```\n\n\n\n# web界面操作\n## hdfs查看\n>master:50075\n","categories":["Bigdata"],"tags":[]},{"title":"BigData-Hadoop","url":"/posts/30565/","content":">主要介绍了大数据中Hadoop集群的使用\n<!--more-->\n# 时间同步\n## 分节点\n>在3个slave节点上执行命令【service ntpd stop】、【ntpdate master】、【service ntpd start & chkconfig ntpd on】启动与主节点master的时间同步服务。 \n## 主节点\n>在主节点执行/usr/local/sbin/目录下的命令【ntp_update】，可快速启动时间同步服务。\n\n# 集群的启动与关闭\n## 启动\n>执行/usr/local/sbin/hadoop_cluster.start即可\n## 关闭\n>执行/usr/local/sbin/hadoop_cluster stop即可\n\n# Hadoop集群的操作\n## 查看节点进程\n>/usr/local/sbin/hadoop_cluster status\n## 查看当前主机名\n>hostname : 查看当前主机全名  \n>hostname -f : 查找当前主机配置的映射名\n\n# Web界面操作Hadoop\n## HDFS监控\n> http://master:50070\n## 应用监控\n> http://master:8080","categories":["Bigdata"],"tags":[]},{"title":"JavaStream","url":"/posts/44747/","content":">总结了关于Java的Stream流的相关内容\n<!--more-->\n# 中间操作\n1. 过滤\n```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nList<Integer> collect = list.stream().filter(i -> i % 2 == 0).collect(Collectors.toList());  //[2, 4]\n```\n2. 映射\n```java\nList<String> list = Arrays.asList(\"apple\", \"banana\", \"peach\");\nList<String> collect = list.stream().map(s -> s.toUpperCase()).collect(Collectors.toList());  //[APPLE, BANANA, PEACH]\n```\n3. 从小到大排序\n```java\nList<Integer> list = Arrays.asList(3, 1, 4, 1, 5, 9, 2, 6, 5);\nList<Integer> collect = list.stream().sorted().collect(Collectors.toList());  //[1, 1, 2, 3, 4, 5, 5, 6, 9]\n```\n4. 转换成数组\n```java\n//将流中的元素转换为数组\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nInteger[] result = list.stream().toArray(Integer[]::new);   \nSystem.out.print(Arrays.toString(result));   //[1, 2, 3, 4, 5]\n\n```\n\n# 终止操作\n1. forEach\n```java\nList<String> list = Arrays.asList(\"apple\", \"banana\", \"peach\");\nlist.stream().forEach(System.out::println);  //apple banana peach\n```\n\n2. reduce\n```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nint sum = list.stream().reduce(0,(a,b)->a+b);  //15\n```\n\n3. collect\n```java\nList<String> list = Arrays.asList(\"apple\", \"banana\", \"peach\");\nList<String> newList = list.stream().filter(s -> s.startsWith(\"a\")).collect(Collectors.toList());  //[apple]\n```\n\n# findFirst 和 findAny\n1. findFirst：返回流中的第一个元素。\n ```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nOptional<Integer> optional = list.stream().findFirst();   // Optional[1]\n ```\n\n2. findAny：返回流中任意一个元素。\n ```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nOptional<Integer> optional = list.stream().filter(i -> i >= 3).findAny();   // Optional[3] 或 Optional[4] 或 Optional[5]\n```\n# anyMatch、allMatch 和 noneMatch\n1. anyMatch：判断流中是否存在至少一个元素满足指定条件。\n```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nboolean result = list.stream().anyMatch(i -> i > 3);   // true\n ```\n\n2. allMatch：判断流中是否所有元素都满足指定条件。\n ```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nboolean result = list.stream().allMatch(i -> i > 0);   // true\n ```\n\n3. noneMatch：判断流中是否不存在满足指定条件的元素。\n ```java\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nboolean result = list.stream().noneMatch(i -> i < 0);   // true\n```\n\n\n# flatMap：可以将多个流合并成一个流，并去重。\n```java\nList<List<Integer>> list = Arrays.asList(Arrays.asList(1, 2), Arrays.asList(3, 4), Arrays.asList(5, 6));\nList<Integer> result = list.stream().flatMap(Collection::stream).distinct().collect(Collectors.toList());   // [1, 2, 3, 4, 5, 6]\n```\n\n# 分组\n1. groupingBy：将流中的元素按照指定条件分组\n```java\n//将流中的元素按照字符串长度分组。\nList<String> list = Arrays.asList(\"apple\", \"banana\", \"cherry\", \"pear\");\nMap<Integer, List<String>> result1 = list.stream().collect(Collectors.groupingBy(String::length));   // {5=[apple, pear], 6=[banana, cherry]}\n \n//按照自定义的条件进行分组，这里是按首字母分组\nMap<String, List<String>> result2 = list.stream().collect(Collectors.groupingBy(s -> s.substring(0, 1)));   // {a=[apple], b=[banana], c=[cherry], p=[pear]}\n\n```\n\n2. partitioningBy：将流中的元素按照指定条件分成 true 和 false 两组\n```java\n//将流中的元素按照指定条件分成 true 和 false 两组\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nMap<Boolean, List<Integer>> result = list.stream().collect(Collectors.partitioningBy(x -> x > 3));   // {false=[1, 2, 3], true=[4, 5]}\n \n//将结果转换为 Set 类型，并取为true的数据\nSet<Integer> result2 = list.stream().collect(Collectors.partitioningBy(x -> x > 3, Collectors.toSet())).get(true);   // [4, 5]\n```\n\n# 将List变为Map\n1. Collectors.toMap\n```java\n   // 查询岗位Id和Name的映射\n        List<Station> stationList = stationPlusService.list();\n        Map<Long, String> idNameMap = stationList.stream().collect(Collectors.toMap(Station::getId, Station::getStationName));\n```","categories":["JavaStudy"],"tags":[]},{"title":"WebS- 接单平台","url":"/posts/13929/","content":">总结了各大接单平台\n<!--more-->\n# 接单前要\n>* 需要有第三方担保，个人对个人的尽量不要接\n>* 不说具体需求的不要接，需要有具体的需求文档\n>* 尽量442收费方式，开工收40%项目款，项目中期收40%项目款，项目结束收20%项目款\n>* 不给完钱不交完整代码\n\n# 接单网站\n## 开源众包\n> https://zb.oschina.net\n## 猪八戒\n> https://zbj.com\n## 程序员客栈\n> https://www.proginn.com/\n## coding码市\n>https://mart.coding.net\n## 英选\n> http://linktion.cn\n## 开发邦\n>http://www.kaifabang.com\n## freelancer\n>https://www.freelancer.com\n## Stackoverflow\n>https://stackoverflow.com\n## 猿急送\n>https://www.yuanjisong.com\n## 人人开发\n>http://rrkf.com\n## 码易\n>http://mayigeek.com","categories":["WebSites"],"tags":[]},{"title":"MySQL-CRUD","url":"/posts/48277/","content":">介绍了MySQL中对于CRUD的基本操作\n<!--more-->\n# Create(新建)\n## 创建表的时候添加限制\n```sql\n  CREATE TABLE test(\n\tid INT,\n\thcode INT,\n\tCONSTRAINT xtzl FOREIGN KEY (hcode) REFERENCES heal(id)\n\tON UPDATE CASCADE\n    ON DELETE CASCADE);\n```\n## 新增数据\n```sql\nINSERT emp VALUES(NULL,'智力2',2);\nINSERT INTO xtzl(NAME,Birthday,Sex ,Age)VALUES('嘉嘉','2002-6-06','男',10);\n```\n# Read(查询)\n## 全查询 && 条件查询 && 去重查询\n```sql\nselect * from tableA;\nselect * from tableA where XXX;\nSELECT DISTINCT NAME FROM xtzl;\n-- 截取查询\nselect left(username,3) from tableA;\n```\n## 模糊查询\n```sql\n -- 关键词 where-like\n -- 模糊查询，查询名字是小开头的数据\nSELECT * FROM xtzl WHERE NAME LIKE '小%'; \n-- 模糊查询，查询名字是四个字的，有四个下划线\nSELECT * FROM xtzl WHERE NAME LIKE '____'; \n-- 模糊查询，查询名字里面包含有‘特’的数据\nSELECT * FROM xtzl WHERE NAME LIKE '%特%'; \n```\n## 排序查询\n```sql\n-- 先按照前面那个条件升序，如果前面那个条件的值一样的时候，才会按照后面的条件排序\nSELECT * FROM xtzl  ORDER BY Age ASC ,score DESC; \n```\n## 聚合查询\n```sql\n   -- count 计算个数  \n   -- max 计算最大值\n   -- min 计算最小值\n   -- sum 计算和\n   -- avg 计算平均值\nSELECT COUNT(NAME ) FROM xtzl; -- 单行单列的元素个数\n```\n## 分组查询\n```sql\n-- 查询的字段必须在group by 后或者聚合函数内\nSELECT sex FROM xtzl GROUP BY sex;  \nSELECT sex,AVG(score) FROM xtzl GROUP BY sex; \n-- AVG()用于对指定的列或表达式求平均值\nSELECT sex,AVG(score) FROM xtzl WHERE score>=100 GROUP BY sex; \n```\n## 分页查询\n```sql\n-- 0表示第一个数据的索引值，3表示索引从0开始，依次读取3个数据\nSELECT * FROM xtzl LIMIT 0,3; \n-- 第二页了，上面那个是第一页  (2-1)*3 = 3 = 当前页面开始时的索引\nSELECT * FROM xtzl LIMIT 3,4; \n```\n\n# Update(修改)\n## 修改表结构\n### 修改列的数据类型\n```sql\nALTER TABLE stu modify name VARCHAR(20);\nALTER TABLE stu MODIFY NAME VARCHAR(20) UNIQUE;\n```\n### 修改列名或数据类型\n```sql\nALTER TABLE xtzl change Age Myage INT;\n```\n### 删除某列\n```sql\nALTER TABLE xtzl DROP KKK;\n```\n### 添加某列\n```sql\nALTER TABLE xtzl ADD  SEX VARCHAR(1);\n```\n## 修改数据记录\n```sql\nUPDATE xtzl SET NAME='小特特' WHERE Age=10;\n```\n## 修改数据库\n### 修改基本配置\n```sql\nALTER DATABASE\nMODIFY FILE{\n\tNAME=Teacher_Log,\n\tFILENAME='E:\\SQL Server\\DB_Practice\\Test01\\Teacher.ldf',\n\tSIZE=10,\n\tMAXSIZE=500,\n\tFILEGROWTH=10};\n```\n### 修改数据库用户的密码\n```sql\nUPDATE USER SET PASSWORD = PASSWORD ('newpassword') WHERE USER = 'wendy';  \n-- 格式： \nset password for 用户名@localhost = password(‘新密码’);  \n-- 例子：\nset password for root@localhost = password(‘123’);\n```\n# Delete(删除)\n## 删除表和数据库\n```sql\nDROP DATABASE xxx;\nDROP TABLE xxx;\n-- 删除表后重构一个数据结构相同，无数据的表\nTRUNCATE TABLE xtzl;\n```\n## 删除表中数据\n```sql\nDELETE FROM table_name WHERE xxxx;\n```\n\n# Constraint的CRUD\n## 新增\n### 添加主键及其自增\n```sql\nALTER TABLE stu MODIFY id INT PRIMARY KEY AUTO_INCREMENT;\n```\n### 添加外键\n```sql\nALTER TABLE workers ADD CONSTRAINT foreignkeyName FOREIGN KEY (de_id) REFERENCES department(id);\n```\n### 添加某列的约束\n```sql\n-- 添加 WeiXin 唯一值约束 \nalter table Student add constraint WeixinUnique unique(WeiXin);\n-- 添加 check 约束 \nalter table Student add constraint mycheckN check(Gender = ' 男 ' or Gender = ' 女 ')\n```\n## 删除\n### 删除某列的约束\n```sql\n-- 删除表 student 的唯一值约束 \nalter table Student drop WeixinUnique;\n```\n### 删除外键\n```sql\n-- 删除外键 \nalter table Gooos drop foreign key outsidecode\n```\n## 修改\n> 修改其实和新增大同小异，只是要注意constraint的对应名称不能错即可\n```sql\n-- 在表 SaleBill 上增加数量大于 0 的约束。\nalter table SaleBill add constraint numlimit check(Number > 0);\n-- 将表 SaleBill 上数量的约束修改为 0~100。\nalter table SaleBill add constraint changedlimit check(Number >=0 and Number <=100)\n```\n","categories":["DataBase"],"tags":[]},{"title":"MySQL-advanced","url":"/posts/55275/","content":">介绍了关于MySQL中的高级特性\n<!--more-->\n# MVCC的原理\n## MVCC的介绍\n>**MVCC：** 多版本并发控制机制  \n>**作用：**\n>* 可解决脏读、不可重复读的事务读写问题\n>* 在保证隔离性的基础上，提升了读取效率和并发性\n## 保证事务隔离性\n**UndoLog版本链**\n>* 在执行Update和Delete操作的时候，会将每次操作记录记录在UndoLog中,每条记录都有唯一的事务ID\n>* 最新的记录在链头，最老的记录在链尾  \n\n**Readview**\n>记录了数据版本链的统计值: m_ids、min_trx_id、max_trx_id、creator_trx_id\n>* m_ids：ss活跃事务ID集合(未提交的事务)\n>* min_trx_id：最小活跃事务ID\n>* max_trx_id：下一个将被分配的版本ID\n>* creator_trx_id：当前事务ID\n\n**选择版本**  \n> **四步判断法**  \n>在遍历版本链的过程中    \n1，判断当前版本事务ID == 当事务ID\n2，判断当前版本事务ID < 最小活跃事务\n3，判断当前版本事务ID > max_trx_id \n4, 判断当前版本事务ID是否在活跃事务集中，如果是，则不满足条件\n>- - -\n\n# Case When的三种用法\n- 等值转换\n- 范围转换\n- 列转行\n\n\n# 权限操作\n## 查询权限\n```sql\n-- 查询某个用户的权限\n\tSHOW GRANTS FOR 'root'@'%';\n\tSHOW GRANTS FOR 'wendy'@'localhost';\n```\n## 授予权限\n```sql\n-- 格式：grant 权限列表 on 数据库表.表名 to '用户名'@'主机名' :把某张表的哪些权限给某个用户\nGRANT ALL ON *.* TO 'wendy'@'localhost';\n```\n## 撤销权限\n```sql\nREVOKE ALL ON *.* FROM 'wendy'@'localhost';\n```\n\n# 函数的使用\n## if && ifnull\n>* IFNULL函数接受两个参数，如果不是NULL，则返回第一个参数。否则，IFNULL函数返回第二个参数。\n>* is null 函数 is not null 函数与上同理\n```sql\n-- if\nSELECT IF(uuu IS NOT NULL ,'1','2') p FROM users; \n-- ifnull\nSELECT id,IFNULL(uuu,PASSWORD) param FROM users;\n```\n## Case when\n<img src = \"http://xtzl.wentexl.cn/case1.png\"/>\n<img src = \"http://xtzl.wentexl.cn/case2.png\"/>\n\n","categories":["DataBase"],"tags":[]},{"title":"RabbitMQ","url":"/posts/15185/","content":">关于RabbitMQ的知识点积累\n<!--more-->\n# 架构图\n<img src = \"http://xtzl.wentexl.cn/rabbitMQ.png\">\n\n# 工作模式(五种)\n## Simple简单模式\n>一个生产者，一个队列，一个消费者的模式\n\n## Work queues工作队列模式\n>多个消费端共同处理同一个队列中的消息\n>对于任务过重或者任务较多的情况使用,C1和C2的轮询获取的，同一个消息只能被其中一个获取到\n<img src=\"http://xtzl.wentexl.cn/wq.png\"/>\n\n## Pub/Sub 订阅模式\n<img src=\"http://xtzl.wentexl.cn/emq.png\"/>\n\n## Routing路由模式\n>交换机只将消息发送给指定路由key的消息队列中去\n<img src=\"http://xtzl.wentexl.cn/%E8%B7%AF%E7%94%B1%E4%BA%A4%E6%8D%A2%E6%9C%BA.png\"/>\n\n## Topic通配符方式\n>批量匹配之后将消息发送到对应消息队列中\n><img src=\"http://xtzl.wentexl.cn/Topic%E9%80%9A%E9%85%8D%E7%AC%A6%E6%96%B9%E5%BC%8F.png\">\n* topic中#和*的区别\n>符号“#”匹配路由键的一个或多个词，符号'*'只匹配路由键的一个词。  \n>例如：topic.#那么这个队列会会接收topic开头的消息，topic.*.queue那么这个队列会接收topic.aaaa.queue这样格式的消息，不接收能topic.aaaa.bbbb.queue这样格式的消息\n\n# 交换机的类型\n>* fanoutExchange : 广播交换机，适用于简单模式、订阅模式、工作队列模式\n>* directExchange : 路由定向交换机，适用于路由模式\n>* headersExchange: 头交换机，适用于路由模式,路由交换机的路由是基于路由键，头交换机的路由值基于消息的header数据。\n>* topicExchange  : 主题交换机，适用于通配符模式\n\n# SpringBoot集成RabbitMQ\n## 导入依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n## 生产端\n>* 在配置类中配置交换机、消息队列以及它们的绑定关系\n>* 使用RabbitTemplate发送消息,最重要的三个参数是：交换机名称、路由key、消息数据\n### 定义与绑定\n```java\n@Configuration\npublic class RabbitMQConfig {\n    public static final String EXCHANGE_NAME = \"bootExchange\";\n    public static final String QUEUE_NAME_ONE = \"bootQueueOne\";\n    /**一、交换机*/\n    @Bean(\"bootExchange\")\n    public Exchange rabbitExchange(){\n        // durable是众多参数之一，是否持久化\n        return ExchangeBuilder.topicExchange(EXCHANGE_NAME).durable(true).build();\n    }\n    /**二、队列*/\n    @Bean(\"bootQueueOne\")\n    public Queue bootQueue(){\n        // 设置持久化、设置ttl：消息队列中的消息最大存活时间是5s\n        return QueueBuilder.durable(QUEUE_NAME_ONE).ttl(5000).build();\n    }\n\n    /**三、队列和交换机的绑定关系*/\n    @Bean\n    public Binding bindQueueExchange(@Qualifier(QUEUE_NAME_ONE) Queue queue,\n                                     @Qualifier(EXCHANGE_NAME) Exchange exchange){\n        return BindingBuilder.bind(queue).to(exchange).with(\"boot.#\").noargs();\n    }\n}\n```\n\n\n## 消费端\n>* 配置一个Listener,使用 @RabbitListener来自动接收消息并处理，如下代码所示\n```java\n// 这里接收了消息会自动确认，即消息的自动签收\n@Component\npublic class RabbitMQListener {\n    @RabbitListener(queues = \"bootQueueOne\")\n    public void ListenerQueue(Message message){\n        System.out.println(message);\n    }\n}\n```\n\n# 高级特性\n## 消息的可靠性传递\n> 可靠性：作为消息发送方，希望杜绝任何消息丢失或者投递失败的场景\n### Confirm确认模式\n> producer ---> exchange：返回一个confirmCallback，里面为true则成功到达exchange，为false则消息未到达exchange\n```java\n    @Test\n    public void testResponsibility() throws InterruptedException {\n        // 定义回调函数\n        // ask为判断标志位，cause为消息发送失败的原因\n        rabbitTemplate.setConfirmCallback(((correlationData, ask, cause) -> {\n            if (ask){\n                System.out.println(\"消息发送成功\");\n            }\n            else {\n                System.out.println(\"消息发送失败\");\n                System.out.println(cause);\n            }\n        }));\n        // 发送消息\n        rabbitTemplate.convertAndSend(\"directExchange\",\"confirm\",\"消息数据\");\n        Thread.sleep(2000);\n    }\n```\n### return 退回模式\n>   exchange ---> queue： 只有投递失败的时候，才会返回一个returnCallback,说明消息未能从exchange传递到queue中\n```java\n    public void testReturn() throws InterruptedException {\n        // 如果消息从交换机发送到某个队列中失败，则将消息返回给生产者，false为直接丢弃\n        rabbitTemplate.setMandatory(true);\n        rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {\n            /**\n             * @param message 消息对象\n             * @param i 错误码\n             * @param s 错误信息\n             * @param s1 交换机\n             * @param s2 路由键\n             */\n            @Override\n            public void returnedMessage(Message message, int i, String s, String s1, String s2) {\n                System.out.println(message);\n            }\n        });\n        rabbitTemplate.convertAndSend(\"directExchange\",\"confirm\",\"消息数据\");\n        Thread.sleep(2000);\n    }\n```\n## 消息的签收\n>* 消息默认在消费端是自动接收\n>* 如果未确认消息，则消息会以unasked的状态存在于消息队列中\n### Consumer ASK手动签收方式\n```yml\n    listener:\n      simple:\n        # 设置监听器为手动签收\n        acknowledge-mode: manual\n```\n```java\n// 实现接口、重写方法、使用注解添加进容器，并绑定监听的消息队列\n@Component\npublic class RabbitMQListener implements ChannelAwareMessageListener {\n    @Override\n    @RabbitListener(queues = \"directQueueOne\")\n    public void onMessage(Message message, Channel channel) throws Exception {\n        // 接收消息的消息投递序号，在某个管道中，每个消息的序号都不同\n        long deliveryTag = message.getMessageProperties().getDeliveryTag();\n        try {\n            // 接收转换消息\n            String body = new String(message.getBody());\n            // 处理业务逻辑\n            System.out.println(body);\n            int a = 1/0;\n            // 手动签收,true是指：是否接收多条消息\n            channel.basicAck(deliveryTag,true);\n        } catch (Exception e) {\n            // 拒绝签收,b1是指消息是否重回queue来重新发送给消费端\n            channel.basicNack(deliveryTag,true,true);\n        }\n    }\n}\n```\n## 消费端对消息的限流\n```yml\n    listener:\n      simple:\n        # 设置消费端一次最多拉取多少条数据\n        prefetch: 1000\n```\n## 设置消息的过期时间\n>* 如果同时设置了消息的过期时间和队列的过期时间，以消息时间短的为准\n>* 队列设置的消息时间到了之后，会移除掉队列中所有的消息\n>* 如果设置了某条消息的过期时间，则必须要等消息到顶端的时候才会判断其是否失效，若失效这个时候才会移除\n```java\n// 构造队列的时候设置TTL\nQueueBuilder.durable(\"directQueueOne\").ttl(5000).build();\n```\n```java\n// 单独给某些消息设置TTL\n    @Test\n    public void  testMessageTTL(){\n        MessagePostProcessor messagePostProcessor = new MessagePostProcessor() {\n            @Override\n            public Message postProcessMessage(Message message) throws AmqpException {\n                // 设置过期时间为5.2s\n                message.getMessageProperties().setExpiration(\"5200\");\n                return message;\n            }\n        };\n        rabbitTemplate.convertAndSend(\"directExchange\",\"confirm\",\"消息TTL测试数据\",messagePostProcessor);\n    }\n```\n## 死信队列\n> 当队列中的消息成为死信之后，可把死信发送给死信交换机，可发送到对应队列中，被对应的死信消费端所消费\n### 死信消息的三种情况\n>* 队列消息长度达到限制\n>* 消费端拒接消费消息:在手动签收消息的时候，调用了basicNack且设requeue=false\n>* 原队列存在消息过期设置，消息到达超时时间而未被消费\n### 代码配置\n```java\n    @Bean(\"directQueueOne\")\n    public Queue directQueueOne(){\n        // 设置队列中的数据的ttl的和死信交换机和死信路由键\n        return QueueBuilder.durable(\"directQueueOne\").ttl(5000).deadLetterExchange(\"deathExchange\").deadLetterRoutingKey(\"death\").build();}\n```\n## 延迟队列\n>* 当消息进入队列之后不会立即被消费，只有到达指定的时间之后才会被消费\n>* 可使用TTL+死信队列来实现延迟队列 ","categories":["MessageQueue"],"tags":[]},{"title":"RabbitMQ-Install","url":"/posts/59081/","content":"> 对RabbitMQ的安装总结与归纳\n<!--more-->\n## 1. 安装依赖环境\n\n在线安装依赖环境：\n\n```shell\nyum install build-essential openssl openssl-devel unixODBC unixODBC-devel make gcc gcc-c++ kernel-devel m4 ncurses-devel tk tc xz\n\n```\n## 2. 安装Erlang\n上传\nerlang-18.3-1.el7.centos.x86_64.rpm\nsocat-1.7.3.2-5.el7.lux.x86_64.rpm\nrabbitmq-server-3.6.5-1.noarch.rpm\n```sh\n# 安装\nrpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm\nrpm -ivh socat-1.7.3.2-5.el7.lux.x86_64.rpm\nrpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm\n```\n\n## 4. 开启管理界面及配置\n```sh\n# 开启管理界面\nrabbitmq-plugins enable rabbitmq_management\n# 修改默认配置信息\nvim /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.5/ebin/rabbit.app \n# 比如修改密码、配置等等，例如：loopback_users 中的 <<\"guest\">>,只保留guest\n```\n\n## 5. 启动\n\n```sh\nservice rabbitmq-server start # 启动服务\nservice rabbitmq-server stop # 停止服务\nservice rabbitmq-server restart # 重启服务\n```\n\n- 设置配置文件\n```shell\ncd /usr/share/doc/rabbitmq-server-3.6.5/\n\ncp rabbitmq.config.example /etc/rabbitmq/rabbitmq.config\n\n```\n\n## 6. 配置虚拟主机及用户\n>管理台URL：http://120.48.77.232:15672/\n### 6.1. 用户角色\n\nRabbitMQ在安装好后，可以访问`http://ip地址:15672`  \n其自带了guest/guest的用户名和密码。默认账号和默认密码都是guest\n\n**角色说明**：\n\n1、 超级管理员(administrator)\n\n可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。\n\n2、 监控者(monitoring)\n\n可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)\n\n3、 策略制定者(policymaker)\n\n可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。\n\n4、 普通管理者(management)\n\n仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。\n\n5、 其他\n\n无法登陆管理控制台，通常就是普通的生产者和消费者。\n\n### 6.2. Virtual Hosts配置\n\n像mysql拥有数据库的概念并且可以指定用户对库和表等操作的权限。RabbitMQ也有类似的权限管理；在RabbitMQ中可以虚拟消息服务器Virtual Host，每个Virtual Hosts相当于一个相对独立的RabbitMQ服务器，每个VirtualHost之间是相互隔离的。exchange、queue、message不能互通。 相当于mysql的db。Virtual Name一般以/开头。\n\n","categories":["MessageQueue"],"tags":[]},{"title":"AC-websites","url":"/posts/51499/","content":"> 积累了我认为写的比较好的博文的链接\n<!--more-->\n# Spring全家桶相关的\n# 缓存\n## Caffine + Redis 二级缓存\n>https://baijiahao.baidu.com/s?id=1746195877138194250&wfr=spider&for=pc\n\n# 安装教程\n## CentOS7上安装Mysql教程(当前服务器正在使用的)\n>- 配置环境变量\n  - vim ~/.bash_profile\n  - export PATH=$PATH:/home/mysql/mysql-8.0.20-linux-glibc2.12-x86_64/bin\n>- 云服务器的配置：\n  - 安装路径：/home/mysql/mysql-8.0.20-linux-glibc2.12-x86_64/bin\n  - 启动命令：mysqld_safe --defaults-file=/home/mysql/mysql-8.0.20-linux-glibc2.12-x86_64/my.cnf &\n  - 关闭mysql服务：mysqladmin -uroot -p060119 shutdown\n> 配置网站(优秀博文)：https://www.jb51.net/article/251117.htm\n\n\n","categories":["Accumulate"],"tags":[]},{"title":"AC-dataIndex","url":"/posts/13052/","content":"> 对数据指标的相关知识进行了总结和积累\n<!--more-->\n>*  DAU：Daily Active User   \n>日活跃用户量。统计一日（统计日）之内，登陆或使用了某个产品的用户数（去重）\n>- - -\n>* WAU：Weekly Active Users  \n>周活跃用户量。统计一周（统计日）之内，登陆或使用了某个产品的用户数（去重）\n>- - -\n>* MAU：Monthly Active User  \n> 月活跃用户量。统计一月（统计日）之内，登陆或使用了某个产品的用户数（去重）\n>- - -\n>* DNU：Day New User   \n>日新增用户，表示当天的新增用户\n>- - -\n>* DOU：Day Old User  \n>日老用户。当天登陆的老用户，非新增用户\n>- - -\n>* ACU：Average Concurrent Users  \n>平均同时在线人数\n>- - -\n>* PCU：Peak Concurrent Users  \n>最高同时在线人数\n>- - -\n>* UV：Unique Visitor    \n>唯一访问量，即页面被多少人访问过\n>- - -\n>* PV：Page View  \n>页面浏览量，即页面被多少人看过\n>- - -\n>* ARPU：Average Revenue Per User  \n>平均每个活跃用户收益\n>- - -\n>* LTV：Life Time Value  \n>生命周期价值。产品从用户所有互动中获取的全部经济收益的总和\n>- - -\n>* CAC：Customer Acquisition Cost  \n> 用户获取成本\n>- - -\n>* ROI：Return On Investment   \n> 投资回报率,ROI=利润总额/投入成本总额*100%\n>- - -\n>* GMV：Gross Merchandise Volume  \n>成交总额。是指下单产生的总金额,CMV=销售额+取消订单金额+退款金额\n>- - -\n>* 支付UV  \n>下单并成功支付的用户数\n\n\n","categories":["Accumulate"],"tags":[]},{"title":"boot-Configure","url":"/posts/36638/","content":">介绍了关于SpringBoot对Web组件等的配置\n<!--more-->\n# 过滤器&&拦截器的配置\n## 过滤器注解的配置方式\n```java\n// 在过滤器类上使用注解\n@WebFilter(urlPatterns = \"/*\", filterName = \"RestWebFilter\")\n```\n```java\n//在主启动类上添加Servlet扫描注解\n@ServletComponentScan\n```\n## 过滤器在配置类的配置方式\n```java\n/**将该实例注册进容器即可 */\n    @Bean\n    public FilterRegistrationBean filterRegistrationBean(){\n        FilterRegistrationBean<Filter> registrationBean = new FilterRegistrationBean<>();\n        registrationBean.setFilter(new LoginFilter());\n        registrationBean.setName(\"loginFilter\");\n        registrationBean.addUrlPatterns(\"/login\");\n        return registrationBean;\n    }\n```\n\n\n## 拦截器在配置类的配置方式\n```java\n@Configuration\npublic class InterceptorConfig implements WebMvcConfigurer {\n      @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(new LoginInterceptor())\n                .addPathPatterns(\"/**\")  //所有请求都被拦截包括静态资源\n                .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\n                        \"/js/**\",\"/aa/**\"); //放行的请求\n    }\n}\n```","categories":["SpringBoot"],"tags":[]},{"title":"TechStack-SpringMail","url":"/posts/31627/","content":">总结了关于SpringBoot集成发送邮件的服务，主要用于做邮件认证码\n<!--more-->\n> 前提准备是在QQ邮箱开启SMTP服务(简单邮件传输协议)\n# 导入依赖\n```xml\n<dependency>\n   <groupId>org.springframework.boot</groupId>\n   <artifactId>spring-boot-starter-mail</artifactId>\n</dependency>\n```\n# yml配置\n```yml\nspring:\n  #邮箱验证码配置\n  mail:\n    #smtp服务主机  qq邮箱则为smtp.qq.com;163邮箱是smtp.163.com\n    host: smtp.qq.com\n    #服务协议\n    protocol: smtp\n    # 编码集\n    default-encoding: UTF-8\n    #发送邮件的账户\n    username: 123456789@qq.com\n    #授权码\n    password: wpsbapnfmsbocece\n    test-connection: true\n    properties:\n      mail:\n        smtp:\n          auth: true\n          starttls:\n            enable: true\n            required: true\n```\n\n# 具体操作\n```java\n    @Resource\n    private JavaMailSender javaMailSender;\n\n    public String loginAuthCodeBySendMails(String username) {\n        // 验证码自己写代码随机生成\n        String authCode = sb.toString();\n        // 设置邮件内容\n        MimeMessage mimeMessage = javaMailSender.createMimeMessage();\n        MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true,\"utf-8\");\n        helper.setSubject(\"您的验证码为:\"+authCode);\n        helper.setText(\"您好！欢迎登录校疫通管理系统。您的验证码为：\"+\"<h1>\"+authCode+\"</h1>\"+\"请勿将验证码告诉他人！验证码将在3分钟内失效，请尽快输入！\");\n        helper.setTo(targetMail);\n        helper.setFrom(\"393815277@qq.com\");\n        // 发送邮件\n        javaMailSender.send(mimeMessage);\n    }\n```\n","categories":["TechStack"],"tags":[]},{"title":"JavaSE","url":"/posts/14085/","content":"> 主要介绍了关于JavaSE的相关积累和操作\n<!--more-->\n# Tags\n## String.format\n```java\npublic class MainTest {\n    public static void main(String[] args) {\n        String ip = \"120.0.0.7\";\n        String now = \"2022/12/05\";\n        String target = \"www.wentexl.cn\";\n        String format = String.format(\"用户[%s],在[%s],访问了[%s].\", ip, now, target);\n        System.out.println(format);\n    }\n}\n```\n## 反射与注解\n```java\n/**自定义注解 */\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.TYPE, ElementType.METHOD})\npublic @interface testAnnotion {\n    String value() default \"\";\n}\n\n/**使用注解*/\n@testAnnotion(\"test\")\npublic class TestService {\n    @testAnnotion(\"testMethod\")\n    public void sayHello() {\n        System.out.println(\"hello word\");\n    }\n}\n\n/**获取注解 */\n\npublic static void main(String[] args) throws NoSuchMethodException {\n    Class<?> clazz = TestService.class;\n    // 获取类上面标记的所有注解\n    System.out.println(Arrays.toString(clazz.getAnnotations()));\n    // 获取类上的@testAnnotion注解\n    System.out.println(clazz.getAnnotation(testAnnotion.class));\n    //返回一个类上的直接注解信息，如果类上没有直接注解信息，则返回一个空数组\n    System.out.println(Arrays.toString(clazz.getDeclaredAnnotations()));\n\n    // 获取类中某个方法的注解信息\n    Method method = clazz.getMethod(\"sayHello\", null);\n    // 获取方法上所有的注解信息\n    System.out.println(Arrays.toString(method.getAnnotations()));\n    // 获取方法上@testAnnotion的注解\n    System.out.println(method.getAnnotation(testAnnotion.class));\n    // 获取方法上的注解信息\n    System.out.println(Arrays.toString(method.getDeclaredAnnotations()));\n\n}\n\n```\n# 八大数据类型\n## 整型 (四种)\n>* int  \n>长度为4字节32bit，取值-2^31 到 2^31-1，变量初始化默认值为0，包装类Integer\n>- - -\n>* long   \n>长度为8字节64bit，取值-2^63 到 2^63-1，变量初始化默认值为0或0L，包装类Long\n>- - -\n>* short  \n>长度为2字节16bit，取值-32768 到 32767，变量初始化默认值为0，包装类Short\n>- - -\n>* byte  \n>长度为1字节8bit，取值（-128）到（127），变量初始化默认值为0，包装类Byte\n## 浮点型 (二种)\n>* float  \n>单精度浮点型，长度为4字节32bit，变量初始化默认值0.0f，包装类Float\n>- - -\n>* double  \n>双精度浮点型，长度为8字节64bit，变量初始化默认值0.0d，包装类Double\n## 字符型 (一种)\n>* char  \n>占2字节16bit，可以赋值单字符以及整型数值, 变量初始化无默认值，包装类Character。\n## 布尔型 (一种)\n>* boolean  \n>仅有两个值true, false，变量初始化默认值false\n\n# 浅拷贝和深拷贝\n## 浅拷贝\n> * 最简单的浅拷贝：Student s1 = new Student(); Student s2 = s1; \n> * 浅拷贝就是获得拷贝对象的引用,而不是正真意义上的拷贝一个对象  \n> * 如下代码中的Student是JavaBean对象，而School只是实现了Cloneable接口\n> * 实际上这不全是深拷贝，因为原对象中的成员变量若是一个对象引用，则对该成员变量只是浅拷贝而已,但是School本身确实是深拷贝，因为新School对象和原School对象确实不是同一个对象\n```java\n  // 重写的Clone方法中，如果是super.clone()，是无法克隆到本对象的成员变量的，这样的话实际上也是一种浅拷贝\n  @Override\n  protected School clone() throws CloneNotSupportedException {\n    return (School)super.clone();\n  }\n```\n## 深拷贝\n> 深拷贝则是拷贝了源对象的所有值，所以即使源对象的值发生变化时，拷贝对象的值也不会改变。深拷贝则是真正意义上的拷贝\n### 构造函数深拷贝(new关键字)\n```java\npublic void constructorCopy() {\n  Student student = new Student (\"小李\",21,\"男\");\n  School school = new School (\"xx大学\",100, student);\n \n  // 调用构造函数时进行深拷贝\n  School copySchool = new School (school.getSchoolName(),school.getStuNums(), new Student(student.getName(), student.getAge(),student.getSex()));\n \n  // 修改源对象的值\n  copySchool .getStudent().setSex(\"女\");\n \n  // 检查两个对象的值不同\n  System.out.println(school.hashCode()==school2.hasCode())\n}\n```\n### 重载Clone()方法深拷贝\n>在重写School类的clone()方法时，Student对象需要调用stu.clone()重新赋值。\n```java\n// 重写Clone方法里面，需要将被克隆的对象的属性对象也克隆一下\n  @Override\n  protected School clone() throws CloneNotSupportedException {\n    School school = (School) super.clone();\n    school.stu = (Student) stu.clone();\n    return school;\n  }\n```\n### Serializable序列化深拷贝\n```java\n@Data\npublic class User implements Serializable {\n  private String name;\n  private Address2 address;\n\n  public Object deepClone() throws Exception\n  {\n    // 序列化\n    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n    ObjectOutputStream oos = new ObjectOutputStream(bos);\n\n    oos.writeObject(this);\n\n    // 反序列化\n    ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());\n    ObjectInputStream ois = new ObjectInputStream(bis);\n\n    return ois.readObject();\n  }\n}\n```\n```java\n@Data\npublic class Address2 implements Serializable {\n  private String city;\n  private String country;\n}\n```\n# Java类\n## 类的初始化顺序\n### 无父类\n>1. 静态变量初始化\n>2. 静态代码块执行\n>3. 成员变量初始化\n>4. 普通代码块执行\n>5. 构造函数执行\n>6. static main方法执行\n### 有父类\n>1. 父类的静态变量 -> 静态代码块\n>2. 子类的静态变量 -> 静态代码块\n>3. 父类的普通成员变量 -> 普通代码块 -> 构造函数\n>4. 子类的普通成员变量 -> 普通代码块 -> 构造函数\n\n# Java关键字\n## static\n>* 含义：static修饰的变量、方法都是类所有的，该类所对应的所有对象都共享这些变量或方法。\n>* 特点：随着类加载，随着类消失，优先于对象，用类名直接访问\n## finnal\n>* 修饰类：该类不能被继承\n>* 修饰变量：该变量不能被修改且需要初始化\n>* 修饰方法：该方法不能被重写","categories":["JavaStudy"],"tags":[]},{"title":"Python","url":"/posts/43687/","content":"> 关于python的相关知识点\n<!--more-->\n# 数据结构\n## Queue\n### 导入依赖\n```py\nfrom queue import Queue\n```\n### 数据操作\n```py\n# 创建队列\nqueue_obj = Queue()\n# 添加元素\nqueue_obj.put(i)\n# 取出元素\nqueue_obj.get()\n# 判断是否为空\nqueue_obj.empty()\n# 队列长度\nqueue_obj.qsize()\n```\n# 设置下载源\n* pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n* pip config set install.trusted-host mirrors.aliyun.com\n","categories":["TechStack"],"tags":["python"]},{"title":"TechStack-Hikari","url":"/posts/36787/","content":"> 总结了关于Hikari数据库连接池的相关信息与内容\n<!-- more -->\n# 引入依赖\n```xml\n        <dependency>\n            <groupId>com.zaxxer</groupId>\n            <artifactId>HikariCP</artifactId>\n        </dependency>\n```\n\n# dataSource\n```yml\n  datasource:\n    type: com.zaxxer.hikari.HikariDataSource\n```\n# 基本配置及其解释\n```yml\nhikari:\n    # 控制HikariCP尝试在池中维护的最小空闲连接数\n    minimum-idle: 5\n    # 控制允许连接在池中保持空闲状态的最长时间,这里是10min\n    idle-timeout: 600000\n    # 控制允许池达到的最大大小,同时最多允许十个连接\n    maximum-pool-size: 10\n    # 自动提交行为\n    auto-commit: true\n    # 表示连接池的用户定义名称\n    pool-name: MyHikariCP\n    # 控制池中连接的最大生存期\n    max-lifetime: 1800000\n    # 控制客户端等待来自池的连接的最大毫秒数\n    connection-timeout: 30000\n    # 测试数据库连接的语句\n    connection-test-query: SELECT 1\n```\n\n# 配置详解\n## autoCommit\n        此属性控制从池返回的连接的默认自动提交行为。它是一个布尔值。 默认值：true\n\n## connectionTimeout\n        此属性控制客户端（即您）等待来自池的连接的最大毫秒数。如果超过此时间而没有可用的连接，则会抛出SQLException。可接受的最低连接超时为250 ms。 默认值：30000（30秒）\n\n## idleTimeout\n        此属性控制允许连接在池中保持空闲状态的最长时间。 仅当minimumIdle定义为小于maximumPoolSize时，此设置才适用。连接池达到连接后， 空闲连接将不会退出minimumIdle。连接是否以空闲状态退役，最大变化为+30秒，平均变化为+15秒。在此超时之前，连接永远不会因为闲置而退役。值必须比maxLifetime小。值为0表示永远不会从池中删除空闲连接。最小允许值为10000ms（10秒）。 默认值：600000（10分钟）\n\n## maxLifetime\n        此属性控制池中连接的最大生存期。使用中的连接永远不会停止使用，只有在关闭连接后才将其删除。在逐个连接的基础上，应用较小的负衰减以避免池中的质量消灭。 我们强烈建议设置此值，它应该比任何数据库或基础结构施加的连接时间限制短几秒钟。 值0表示没有最大寿命（无限寿命），当然要遵守该idleTimeout设置。最小允许值为30000ms（30秒）。 默认值：1800000（30分钟）\n\n## connectionTestQuery\n        如果您的驱动程序支持JDBC4，我们强烈建议不要设置此属性。这是针对不支持JDBC4的“旧版”驱动程序的Connection.isValid() API。这是将在从池中为您提供连接之前执行的查询，以验证与数据库的连接仍然有效。同样，尝试运行不带该属性的池，如果驱动程序不兼容JDBC4，HikariCP将记录错误。 默认值：无\n\n## minimumIdle\n        此属性控制HikariCP尝试在池中维护的最小空闲连接数。如果空闲连接下降到该值以下，并且池中的总连接数少于maximumPoolSize，则HikariCP将尽最大努力快速而有效地添加其他连接。但是，为了获得最佳性能和对峰值需求的响应能力，我们建议不要设置此值，而应让HikariCP充当固定大小的连接池。 默认值：与maximumPoolSize相同\n\n## maximumPoolSize\n        此属性控制允许池达到的最大大小，包括空闲和使用中的连接。基本上，此值将确定到数据库后端的最大实际连接数。合理的值最好由您的执行环境确定。当池达到此大小并且没有空闲连接可用时，对getConnection（）的调用将connectionTimeout在超时之前最多阻塞毫秒。请阅读有关池大小的信息。 默认值：10\n\n## metricRegistry\n        此属性仅可通过编程配置或IoC容器使用。此属性允许您指定池将用于记录各种指标的Codahale / Dropwizard 的实例MetricRegistry。有关 详细信息，请参见Metrics Wiki页面。 默认值：无\n\n## healthCheckRegistry\n        此属性仅可通过编程配置或IoC容器使用。此属性允许您指定池将用于报告当前健康信息的Codahale / Dropwizard 的实例HealthCheckRegistry。有关 详细信息，请参见运行状况检查 Wiki页面。 默认值：无\n\n## poolName\n        该属性表示连接池的用户定义名称，主要出现在日志记录和JMX管理控制台中，以识别池和池配置。 默认值：自动生成","categories":["TechStack"],"tags":["Hikari"]},{"title":"技术官方文档","url":"/posts/9625/","content":"> 介绍了关于技术栈中的相关技术的官方文档链接\n<!--more-->\n# SpringBoot\n```html\n<a> https://spring.io/projects/spring-boot#learn </a>\n```\n# SpringSecurity\n```html\n<a>https://spring.io/projects/spring-security</a>\n```\n# SpringCloud\n```html\n<a>https://spring.io/projects/spring-cloud</a>\n```\n# SpringData\n```html\n<a>https://spring.io/projects/spring-data</a>\n```\n","categories":["WebSites"],"tags":["document"]},{"title":"JavaJDBC","url":"/posts/19301/","content":">总结了关于SpringJDBC 连接SqlServer和Mysql\n<!--more-->\n\n# 连接SqlServer\n> 仅仅支持 JDK8,11,17,18\n## 导入依赖\n```xml\n  <dependencies>\n<!--  junit版本至少在4.12及其以上-->\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.12</version>\n      <scope>test</scope>\n    </dependency>\n<!--    引入Spring-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-context</artifactId>\n      <version>5.3.18</version>\n    </dependency>\n<!--    使用xml配置来设置JDBC的参数-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-jdbc</artifactId>\n      <version>5.3.18</version>\n    </dependency>\n<!--  模拟Spring环境的测试jar包-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-test</artifactId>\n      <version>5.2.5.RELEASE</version>\n    </dependency>\n<!-- SQLServer的连接jar包-->\n    <dependency>\n      <groupId>com.microsoft.sqlserver</groupId>\n      <artifactId>mssql-jdbc</artifactId>\n      <version>7.4.1.jre8</version>\n    </dependency>\n<!--  使用C3P0连接池-->\n    <dependency>\n      <groupId>c3p0</groupId>\n      <artifactId>c3p0</artifactId>\n      <version>0.9.1.2</version>\n    </dependency>\n  </dependencies>\n```\n## 配置applicationContext.xml\n```xml\n<!--    1，配置数据源-->\n    <bean id=\"datasource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\n<!--        驱动类名，照着写-->\n        <property name=\"driverClass\" value=\"com.microsoft.sqlserver.jdbc.SQLServerDriver\"/>\n<!--        URL地址，根据自己的URL来，端口都是3306,主要可能就改个数据库名-->\n        <property name=\"jdbcUrl\" value=\"jdbc:sqlserver://localhost:1433;DatabaseName=trding\"/>\n<!--        登录sqlserver数据库的用户名和密码-->\n        <property name=\"user\" value=\"sa\"/>\n        <property name=\"password\" value=\"rootxtzl\"/>\n    </bean>\n\n\n<!--    2，配置JDBC模板-->\n    <bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\">\n<!--        将我们自己的数据源配置进这个JDBC模板-->\n        <property name=\"dataSource\" ref=\"datasource\"/>\n    </bean>\n\n\n\n<!--    3,注入JDBC到具体的Dao类-->\n    <bean id=\"userDao\" class=\"second.hand.transactions.dao.userDao\">\n<!--        将自己配置的jdbcTempla注入进具体的Dao类-->\n        <property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"/>\n    </bean>\n```\n\n\n# 连接MySQL\n\n## 引入依赖\n```xml\n  <dependencies>\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.12</version>\n      <scope>test</scope>\n    </dependency>\n<!--    引入Spring-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-context</artifactId>\n      <version>5.3.18</version>\n    </dependency>\n<!--    使用xml配置来设置JDBC的参数-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-jdbc</artifactId>\n      <version>5.3.18</version>\n    </dependency>\n<!--  模拟Spring环境的测试jar包-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-test</artifactId>\n      <version>5.2.5.RELEASE</version>\n    </dependency>\n\n<!--    使用 MySQL 8.X 的连接包-->\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>8.0.21</version>\n    </dependency>\n\n<!--    MySQL5.X 的驱动包-->\n<!--    <dependency>-->\n<!--      <groupId>mysql</groupId>-->\n<!--      <artifactId>mysql-connector-java</artifactId>-->\n<!--      <version>5.1.49</version>-->\n<!--    </dependency>-->\n\n    <!--  使用C3P0连接池-->\n    <dependency>\n      <groupId>c3p0</groupId>\n      <artifactId>c3p0</artifactId>\n      <version>0.9.1.2</version>\n    </dependency>\n  </dependencies>\n\n```\n\n## 配置数据源等实例(application.xml)\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n<!--    1，配置数据源-->\n    <bean id=\"datasource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\n<!--        驱动类名，照着写-->\n        <property name=\"driverClass\" value=\"com.mysql.cj.jdbc.Driver\"/>\n<!--        URL地址，根据自己的URL来，端口都是3306,主要可能就改个数据库名-->\n        <property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/triding?serverTimezone=UTC\"/>\n<!--        登录sqlserver数据库的用户名和密码-->\n        <property name=\"user\" value=\"root\"/>\n        <property name=\"password\" value=\"root\"/>\n    </bean>\n\n\n<!--    2，配置JDBC模板-->\n    <bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\">\n<!--        将我们自己的数据源配置进这个JDBC模板-->\n        <property name=\"dataSource\" ref=\"datasource\"/>\n    </bean>\n\n\n<!--    3,注入JDBC到具体的Dao类-->\n    <bean id=\"userDao\" class=\"second.hand.transactions.dao.userDao\">\n<!--        将自己配置的jdbcTempla注入进具体的Dao类-->\n        <property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"/>\n    </bean>\n</beans>\n```\n\n\n# 实体类User\n```java\npackage second.hand.transactions.entities;\n\nimport java.io.Serializable;\n\n/**\n * @author Wente\n * @date 2022/11/30\n * 普通用户类\n **/\npublic class User implements Serializable {\n    private Long userId;\n    private Long carId;\n    private String userName;\n    private String userPwd;\n    private String userNickname;\n    private String userBirth;\n    private String userPsig;\n    private String userQq;\n    private String userTele;\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"userId=\" + userId +\n                \", carId=\" + carId +\n                \", userName='\" + userName + '\\'' +\n                \", userPwd='\" + userPwd + '\\'' +\n                \", userNickname='\" + userNickname + '\\'' +\n                \", userBirth='\" + userBirth + '\\'' +\n                \", userPsig='\" + userPsig + '\\'' +\n                \", userQq='\" + userQq + '\\'' +\n                \", userTele='\" + userTele + '\\'' +\n                '}';\n    }\n\n    public Long getUserId() {\n        return userId;\n    }\n\n    public void setUserId(Long userId) {\n        this.userId = userId;\n    }\n\n    public Long getCarId() {\n        return carId;\n    }\n\n    public void setCarId(Long carId) {\n        this.carId = carId;\n    }\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public String getUserPwd() {\n        return userPwd;\n    }\n\n    public void setUserPwd(String userPwd) {\n        this.userPwd = userPwd;\n    }\n\n    public String getUserNickname() {\n        return userNickname;\n    }\n\n    public void setUserNickname(String userNickname) {\n        this.userNickname = userNickname;\n    }\n\n    public String getUserBirth() {\n        return userBirth;\n    }\n\n    public void setUserBirth(String userBirth) {\n        this.userBirth = userBirth;\n    }\n\n    public String getUserPsig() {\n        return userPsig;\n    }\n\n    public void setUserPsig(String userPsig) {\n        this.userPsig = userPsig;\n    }\n\n    public String getUserQq() {\n        return userQq;\n    }\n\n    public void setUserQq(String userQq) {\n        this.userQq = userQq;\n    }\n\n    public String getUserTele() {\n        return userTele;\n    }\n\n    public void setUserTele(String userTele) {\n        this.userTele = userTele;\n    }\n}\n```\n\n# userDao(与数据库交互用的模板类)\n```java\npublic class userDao {\n\n    private JdbcTemplate jdbcTemplate;\n\n    public JdbcTemplate getJdbcTemplate() {\n        return jdbcTemplate;\n    }\n\n    public void setJdbcTemplate(JdbcTemplate jdbcTemplate) {\n        this.jdbcTemplate = jdbcTemplate;\n    }\n\n    /**\n     * 向数据库中添加数据\n     */\n    public void addUserCommon(){\n        String sql = \"insert into user_common(user_id,user_name,user_pwd,user_nickname,user_birth,user_psig,user_qq,user_tele)values(42000,'wente','wenteroot','文特','2001/12/05','个性签名','393815277','18423225933')\";\n        // 返回updateResult表示受影响的行数\n        int updateResult = jdbcTemplate.update(sql);\n        System.out.println(updateResult);\n    }\n}\n```\n# 测试类\n```java\n//注解是用来配置Spring的测试环境\n@ContextConfiguration(\"classpath:applicationContext.xml\")\n@RunWith(SpringJUnit4ClassRunner.class)\npublic class TestUser {\n    @Test\n    public void test1(){\n        // 获取userDao的实例\n        ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n        userDao userDao = (userDao) ctx.getBean(\"userDao\");\n        // 执行添加用户方法,该方法是我们自定义的\n        userDao.addUserCommon();\n    }\n}\n```","categories":["JavaStudy"],"tags":["SpringJDBC"]},{"title":"ssm_beanXml","url":"/posts/12964/","content":"> 总结了在SSM中对bean的配置\n<!--more-->\n# 属性是存储类对象\n```xml\n        <bean id=\"userDao\" class=\"User.UserDaoimpl\">\n            <!-- 属性是List类型 -->\n            <property name=\"strList\">\n                <list>\n                    <value>aaa</value>\n                    <value>bbb</value>\n                    <value>ccc</value>\n                </list>\n            </property>\n\n            <!-- 属性是Map类型 -->\n        <property name=\"userMap\">\n            <map>\n                <entry key=\"u1\" value-ref=\"user1\"></entry>\n                <entry key=\"u2\" value-ref=\"user2\"></entry>\n            </map>\n        </property>\n\n             <!-- 属性是Properties类型 -->\n        <property name=\"properties\">\n            <props>\n                <prop key=\"p1\">ppp1</prop>\n                <prop key=\"p2\">ppp2</prop>\n                <prop key=\"p3\">ppp3</prop>\n            </props>\n        </property>\n        </bean>\n```\n\n# 实体类属性注入\n```xml\n    <bean id=\"user1\" class=\"User.User\">\n        <property name=\"name\" value=\"tom\"/>\n        <property name=\"age\" value=\"beijing\"/>\n    </bean>\n\n```\n\n# 对象的构造方法的参数注入\n```xml\n    <!-- 将已有的id为userDao的bean注入到构造方法中参数为userDao的对象中 -->\n    <bean id=\"userService\" class=\"Service.UserServiceimpl\">\n        <constructor-arg name=\"userDao\" ref=\"userDao\"></constructor-arg>\n    </bean>\n```\n# 导入其他XML文件\n```xml\n<import resource=\"applicationContext-user.xml\"/>\n```\n","categories":["SSM"],"tags":["beanXml"]},{"title":"boot-Themleaf","url":"/posts/3251/","content":"> 总结了关于模板引擎themleaf的相关知识\n<!--more-->\n# 引入名称空间\n```txt\n<html xmlns:th=\"http://www.thymeleaf.org\">    \n```\n# 属性介绍\n* th:text：设置当前元素的文本内容，相同功能的还有th:utext，两者的区别在于前者不会转义html标签，后者会。优先级不高：order=7\n\n* th:value：设置当前元素的value值，类似修改指定属性的还有th:src，th:href。优先级不高：order=6\n\n* th:each：遍历循环元素，和th:text或th:value一起使用。注意该属性修饰的标签位置，详细往后看。优先级很高：order=2\n\n* th:if：条件判断，类似的还有th:unless，th:switch，th:case。优先级较高：order=3\n\n* th:insert：代码块引入，类似的还有th:replace，th:include，三者的区别较大，若使用不恰当会破坏html结构，常用于公共代码块提取的场景。优先级最高：order=1\n\n* th:fragment：定义代码块，方便被th:insert引用。优先级最低：order=8\n\n* th:object：声明变量，一般和*{}一起配合使用，达到偷懒的效果。优先级一般：order=4\n\n* th:attr：修改任意属性，实际开发中用的较少，因为有丰富的其他th属性帮忙，类似的还有th:attrappend，th:attrprepend。优先级一般：order=5\n# 表达式 \n* ${...}    变量表达式\n* *{...}    选择变量表达式\n* #{...}    消息表达式\n* @{...}    连接网址表达式\n* ~{...}    片段表达式\n* [[...]]   内联表达式(转义后输出)\n* [(...)]   内联表达式(直接输出原文)\n\n\n","categories":["SpringBoot"],"tags":["themleaf"]},{"title":"boot_yml","url":"/posts/54094/","content":">总结了关于yml配置的格式\n<!--more-->\n```yml\n\nperson:\n#  单引号会将转义字符作为字符串输出，双引号不会改变转义字符原先的意思，这里也就是换行符，执行换行操作\n  username: 'zhangsan \\n'\n  birth: 2001/12/05\n  age: 20\n  boos: true\n#  interests: [篮球，足球]\n  interests:\n    - 篮球\n    - 足球\n    - 18\n  animal: [阿猫，阿狗]\n#  score: {english: 80,math: 90}\n  score:\n    - english: 80\n    - math: 90\n\n#一个-代表集合的一个元素，注意-后面要加一个空格\n  allPets:\n    - sick:\n      - {name: 阿猫,weight: 20.0}\n      - {name: 阿狗,weight: 30.5}\n      - name: 小猫\n        weight: 35.0\n    - health:\n      - {name: 智力,weight: 50}\n      - {name: 力,weight: 15}\n\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/wedo\n    username: root\n    password: root\n    driver-class-name: com.mysql.jdbc.Driver\n  jdbc:\n    template:\n#      查询超时属性:ms是单位\n      query-timeout: 3000\n  redis:\n    url: redis://xtzl:Ljw060119@r-bp1a7csap888l0glj2pd.redis.rds.aliyuncs.com:6379\n    jedis:\n      pool:\n        max-active: 10\n        min-idle: 5\n\n#    lettuce:\n#      pool:\n#        最大活动数\n#        max-active: 10\n#          最小空闲数\n#        min-idle: 5\n\n\n\n#      配置mybatis的规则\nmybatis:\n#  config-location: classpath:mybatis/Mybatis-config.xml\n  mapper-locations: classpath:mapper/*.xml\n  configuration:\n#    开启驼峰配置，解决数据库的命名规则和服务器的\n    map-underscore-to-camel-case: true\nserver:\n  port: 8001\n\n```\n","categories":["SpringBoot"],"tags":["yml"]},{"title":"TechStack_ElasticSearch","url":"/posts/29919/","content":"> 总结了关于ElasticSearch的相关知识\n<!--more--> \n# 信息查看\n<img src = \"http://xtzl.wentexl.cn/ElasticSearch/%E4%BF%A1%E6%81%AF%E6%9F%A5%E7%9C%8B.png\">\n\n# 请求体参数\n```json\n{\n    // 多条件查询\n    \"query\":{\n        // 条件\n        \"bool\":{\n            // must是与操作，should是或操作\n             \"must\":[\n                // 种类为小米文档数据\n                {\n                    // match的底层采用倒排索引\n                    // match_phrase会采用完全匹配\n                    \"match\":{\n                    \"category\":\"小米\"\n                        }\n                },\n                // 价格为3999的数据\n                {\n                    \"match\":{\n                        \"price\" : \"3999\"\n                    }\n                }\n            ]   \n            ,\n            \"filter\" :{\n                // 指定范围\n                \"range\":{\n                    // 指定字段\n                    \"price\" :{\n                            // 大于5000\n                        \"gt\" : \"5000\"\n                    }\n                }\n            }\n        }\n    },\n    // 数组起始位置\n    \"from\" : 1,\n    // 查询的条数\n    \"size\" : 2,\n    // 选择字段 : 只查title\n    \"_source\" : [\"title\"],\n    // 排序\n    \"sort\" :{\n            //根据price字段进行排序 \n        \"price\" : {\n            // 降序排序\n            \"order\" : \"desc\"\n        }\n    },\n    // 对查询出的结果进行高亮显示\n    \"highlight\":{\n        // 指定范围\n        \"fields\":{\n            \"category\":\"小米\"\n        }\n    },\n    // 聚合操作\n    \"aggs\" : {\n        // 随意起一个组名\n        \"price_group\" : {\n            // 分组查询\n            \"terms\":{\n                // 按字段分组\n                \"field\" : \"price\"\n            },\n            // 求平均值\n            \"avg\":{\n                // 求price的平均值\n                \"field\" : \"price\"\n            }\n        }\n    },\n    // 不看原始数据\n    \"size\" : 0,\n\n    // 映射关系\n    \"properties\":{\n        // 支持自动倒排索引查询\n        \"name\":{\n            \"type\" : \"text\",\n            \"index\" : true\n        },\n        // 不支持倒排索引查询\n        \"sex\" :{\n            \"type\" : \"keyword\",\n            \"index\" : true\n        },\n        \"tel\":{\n            \"type\" : \"keyword\",\n            \"index\" : false\n        }\n    }\n}\n```\n\n# 通过Kibana来设置ES\n```json\nPUT novel_engine\n{\n    //设置title字段为completion类型，好让Suggetsion可以使用\n  \"mappings\":{\n      \"properties\": {\n        \"title\": {\n          \"type\": \"completion\",\n          \"analyzer\": \"ik_max_word\"\n        }\n      }\n  },\n  // 设置默认分词器为ik分词器\n  \"settings\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"default\":{\n            \"type\":\"ik_max_word\"\n          }\n        }\n      }\n    }\n}\n```","categories":["TechStack"],"tags":["ElasticSearch"]},{"title":"Code","url":"/posts/54840/","content":">总结了关于算法的一些代码函数\n<!--more-->\n# Functions\n## 长整数加法器 (Java)\n```java\n    // 长整数加法器\n    private static String addLongInteger(String str, int num){\n            int ci = 0;\n        StringBuffer sb = new StringBuffer();\n        for(int i = str.length() -1 ; i>=0 ;i--){\n            // 数字的ASCALL与真值相差48\n            int tempnum = (str.charAt(i) - 48) + ci +num;\n            ci = 0;\n            num = 0;\n            if (tempnum >= 10){\n                ci = tempnum/10;\n                tempnum = tempnum %10;\n            }\n            sb.append(String.valueOf(tempnum));\n        }\n    return sb.reverse().toString();\n    }\n```\n\n## 岛屿数量\n```java\nclass Solution {\n    public int numIslands(char[][] grid) {\n        int numCount = 0;\n        for(int i = 0;i<grid.length;i++){\n            for(int j = 0;j<grid[0].length;j++){\n                if(grid[i][j] == '1'){\n                    numCount++;\n                    dfs(grid,i,j);\n                }\n            }\n        }\n        return numCount;\n    }\n\n    public void dfs(char[][] grid,int r,int c){\n        // 越界\n         if(r<0 || r>= grid.length || c <0 || c>=grid[0].length){\n            return;\n        }\n           // 结束条件\n        if(grid[r][c] == '0'){\n            return;\n        }\n        grid[r][c] = '0';\n        dfs(grid,r-1,c);\n        dfs(grid,r+1,c);\n        dfs(grid,r,c-1);\n        dfs(grid,r,c+1);\n    }\n}\n```\n\n# 排序\n## 快速排序\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int []testArr = {3,5,1,2,9,8,7};\n        quickSort(testArr,0,testArr.length-1);\n        for (int i = 0; i < testArr.length; i++) {\n            System.out.print(testArr[i] + \" \");\n        }\n    }\n    \n    public static void quickSort(int []arr,int low,int high){\n        int mid;\n        if (low < high){\n            mid = quickSortAtom(arr, low, high);\n            quickSort(arr,low,mid-1);\n            quickSort(arr,mid+1, high);\n        }\n    }\n    public static int quickSortAtom(int []arr,int low,int high){\n        int i = low;\n        int j = high;\n        int t = arr[i];\n        while (i < j){\n            // 执行逻辑\n            while (arr[j] >= t && i<j){\n                j--;\n            }\n            if (i<j){\n                // 执行交换操作\n              arr[i] = arr[j];\n               i++;\n            }\n            while (arr[i] <= t && i<j){\n                i++;\n            }\n            if (i<j){\n                arr[j] = arr[i];\n                j--;\n            }\n        }\n        arr[i] = t;\n        return i;\n    }\n}\n```","categories":["Algorithm"],"tags":["algorithm"]},{"title":"Sqlserver-DCL","url":"/posts/37793/","content":"> 描述了关于sql对数据的控制语言\n<!--more-->\n\n# 导入外部文件到表中的命令\n```sql\n-- sqlserver\n-- 列的分隔符为|，行的分隔符为\\n\nbulk insert tea_stu_msg from 'D:\\AAA\\txt\\teastuID.txt' \nwith(fieldterminator='|',rowterminator='\\n')\n\n-- mysql\n-- 批量导入：将csv文件直接导入到数据库中\n  LOAD DATA INFILE \"D:/AAA/txt/teastuID.txt\"\n  INTO TABLE stu_tea \n  FIELDS TERMINATED BY '|' \n  LINES TERMINATED BY '\\n'\n  (peo_id,peo_name,peo_academic,peo_major,peo_tele,peo_idification)\n  SET hea_id = NULL;\n  IGNORE 1 LINES\n```","categories":["DataBase"],"tags":[]},{"title":"importantFunctions","url":"/posts/30183/","content":">对一些值得积累的函数、操作进行了积累\n<!--more-->\n# 长整数加法器 Java\n```java\n    // 长整数加法器\n    private static String addLongInteger(String str, int num){\n            int ci = 0;\n        StringBuffer sb = new StringBuffer();\n        for(int i = str.length() -1 ; i>=0 ;i--){\n            int tempnum = (str.charAt(i) - 48) + ci +num;\n            ci = 0;\n            num = 0;\n            if (tempnum >= 10){\n                tempnum = tempnum %10;\n                ci ++;\n            }\n            sb.append(String.valueOf(tempnum));\n        }\n    return sb.reverse().toString();\n    }\n```\n# 文件上传操作\n```java\n/**\n * @author Wente\n * @date 2023/2/6\n * 和文件有关的操作\n **/\n@RestController\n@RequestMapping(\"/file\")\npublic class FileController {\n    @Value(\"${spring.servlet.multipart.location}\")\n    private String fileSavePath;\n    @Value(\"${server.servlet.context-path}\")\n    private String servletContextPath;\n    @PostMapping(\"/upload\")\n    public String upload(MultipartFile multipartFile, HttpServletRequest req){\n        // 1，保证本地的文件存储位\n        File filefolder = new File(fileSavePath);\n        if (!filefolder.isDirectory()){\n            filefolder.mkdirs();\n        }\n        // 2，文件重命名\n        String returnUrlPath = \"\";\n        try {\n            String oldName = multipartFile.getOriginalFilename();\n            String newName = UUID.randomUUID().toString() + oldName.substring(oldName.lastIndexOf('.'),oldName.length());\n            // 3，返回文件访问路径\n            multipartFile.transferTo(new File(filefolder,newName));\n            returnUrlPath = req.getScheme() + \"://\" + req.getServerName() + \":\" +\n                    req.getServerPort() + servletContextPath +\"/images/\" + newName;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return JSON.toJSONString(ResultTool.failWithMessage(\"上传失败\"));\n        }\n        return JSON.toJSONString(ResultTool.successWithData(returnUrlPath));\n    }\n}\n```\n\n# 布隆过滤器\n## 依赖\n```xml\n<dependencies>\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-data-redis</artifactId>\n\t\t</dependency>\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\n\t\t</dependency>\n\t\t<dependency>\n\t\t\t<groupId>org.apache.commons</groupId>\n\t\t\t<artifactId>commons-pool2</artifactId>\n\t\t</dependency>\n\t\t<dependency>\n\t\t    <groupId>com.google.guava</groupId>\n\t\t    <artifactId>guava</artifactId>\n\t\t    <version>30.1-jre</version>\n\t\t</dependency>\n\t</dependencies>\n```\n## 过滤器源码\n```java\n/**\n * @author Wente\n * @date 2023/2/7\n * 给Redis加上一层布隆过滤器\n **/\n@Component\npublic class RedisBloomFilter {\n\n    /**\n     * \t二进制位大小（多少位）\n     */\n    private Long numBits ;\n    /**\n     * \thash函数个数\n     */\n    private Integer numHashFunctions ;\n\n    private Funnel<CharSequence> funnel = Funnels.stringFunnel(Charset.forName(\"UTF-8\")) ;\n\n    @Resource\n    private StringRedisTemplate stringRedisTemplate ;\n    @Value(\"${bf.expected-insertions}\")\n    private Long expectedInsertions;\n    @Value(\"${bf.fpp}\")\n    private Double fpp;\n\n\n    @PostConstruct\n    public void initRedisBloomFilter() {\n        this.numBits = optimalNumOfBits(expectedInsertions, fpp) ;\n        this.numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits) ;\n    }\n\n    /**\n     *  <p>\n     *  \t最佳的位数（二进制位数）\n     *  </p>\n     *  <p>时间：2021年2月7日-上午10:13:43</p>\n     * @author xg\n     * @param expectedInsertions 预期插入的数量\n     * @param fpp 错误率大于0，小于1.0\n     * @return long\n     */\n    public long optimalNumOfBits(long expectedInsertions, double fpp) {\n        if (fpp == 0) {\n            fpp = Double.MIN_VALUE;\n        }\n        return (long) (-expectedInsertions * Math.log(fpp) / (Math.log(2) * Math.log(2)));\n    }\n\n    /**\n     *  <p>\n     *  \t最佳的Hash函数个数\n     *  </p>\n     *  <p>时间：2021年2月7日-上午10:17:26</p>\n     * @author xg\n     * @param expectedInsertions 预期插入的数量\n     * @param numBits 根据optimalNumOfBits方法计算的最佳二进制位数\n     * @return int\n     */\n    public static int optimalNumOfHashFunctions(long expectedInsertions, long numBits) {\n        return Math.max(1, (int) Math.round((double) numBits / expectedInsertions * Math.log(2)));\n    }\n\n    /**存数据*/\n    public boolean put(String key, String value) {\n        byte[] bytes = Hashing.murmur3_128().hashObject(value, funnel).asBytes();\n        long hash1 = lowerEight(bytes);\n        long hash2 = upperEight(bytes);\n\n        boolean bitsChanged = false;\n        long combinedHash = hash1;\n        for (int i = 0; i < numHashFunctions; i++) {\n            long bit = (combinedHash & Long.MAX_VALUE) % numBits ;\n            // 这里设置对应的bit为1\n            stringRedisTemplate.opsForValue().setBit(key, bit, true) ;\n            combinedHash += hash2;\n        }\n        return bitsChanged;\n    }\n\n    /**判断数据是否已经存在*/\n    public boolean mightContain(String key, String value) {\n        byte[] bytes = Hashing.murmur3_128().hashObject(value, funnel).asBytes();\n        long hash1 = lowerEight(bytes);\n        long hash2 = upperEight(bytes);\n\n        long combinedHash = hash1;\n        for (int i = 0; i < numHashFunctions; i++) {\n            long bit = (combinedHash & Long.MAX_VALUE) % numBits ;\n            // 这里判断redis中对应位是否为1\n            if (!stringRedisTemplate.opsForValue().getBit(key, bit)) {\n                return false;\n            }\n            combinedHash += hash2;\n        }\n        return true;\n    }\n\n    private long lowerEight(byte[] bytes) {\n        return Longs.fromBytes(bytes[7], bytes[6], bytes[5], bytes[4], bytes[3], bytes[2], bytes[1], bytes[0]);\n    }\n\n    private long upperEight(byte[] bytes) {\n        return Longs.fromBytes(bytes[15], bytes[14], bytes[13], bytes[12], bytes[11], bytes[10], bytes[9], bytes[8]);\n    }\n}\n```\n## 相关配置\n```yml\nspring:\n  redis:\n    host: localhost\n    port: 6379\n    password: \n    database: 3 \n    lettuce:\n      pool:\n        maxActive: 8\n        maxIdle: 100\n        minIdle: 10\n        maxWait: -1\n# 自定义相关的属性配置          \nbf:\n  expected-insertions: 10001\n  fpp: 0.01     \n```","categories":["Accumulate"],"tags":["Functions"]},{"title":"JavaIO","url":"/posts/20622/","content":"> 总结了关于JavaIO的知识点\n<!--more-->\n\n# Java Input\n```java\n    String inputpath=\"D:\\\\AAA\\\\txt\\\\code.txt\";\n    File file = new File(inputpath);\n    FileReader fileReader = new FileReader(file);\n    // 使用BufferReader读取\n    BufferedReader bufferedReader = new BufferedReader(fileReader);\n    String line = null;\n    // 按行读取\n    while ((line = bufferedReader.readLine()) !=null){\n        System.out.println(line);\n    }\n    // 读取第一个字符，并且返回其Ascall码值\n    int read = bufferedReader.read(); \n```\n\n# Java Output\n```java\n    public static void main(String[] args) throws IOException {\n        String hello = \"time23\";\n        String outputStreamFilePath=\"D:\\\\AAA\\\\txt\\\\demo.txt\";\n        File file=new File(outputStreamFilePath);\n\n        FileWriter fileWriter = new FileWriter(outputStreamFilePath, true);\n        fileWriter.write(hello);\n        fileWriter.close();\n        //以FileWriter作为参数，不换行写入\n        BufferedWriter bufferedWriter = new BufferedWriter(fileWriter);\n        bufferedWriter.write(hello);\n        //以FilterWriter为参数，换行与不换行写入\n        PrintWriter printWriter = new PrintWriter(fileWriter);\n        printWriter.println(hello);\n        printWriter.print(hello);\n        printWriter.close();\n    }\n\n```\n# JavaIO的集中输入输出流的比较\n>* FileReader和Filewriter可以作为Buffer类的参数\n>* BufferedReader和BufferedWriter在内存中会自带一个8kb的字节缓冲区\n>* Buffer同样可以传入File类\n>* PrintWriter的print、println方法可以接受任意类型的参数，而BufferedWriter的write方法只能接受字符、字符数组和字符串\n>* PrintWriter不但能接收字符流，也能接收字节流。\n","categories":["JavaStudy"],"tags":["IO"]},{"title":"C-Process-API","url":"/posts/5/","content":">总结了关于C语言对进程控制的一些语句\n<!--more-->\n# 进程标识\n* getpid函数：获取调用该函数进程的进程ID。    \n* getppid函数：获取调用该函数进程的父进程ID。  \n* getuid函数：获取调用该函数进程的实际用户ID，一般在没有调用setuid函数（此\n 数不讲）进行修改进程对应的程序文件所属用户的情况下，该用户ID就等于当初运行\n 该程序时的用户ID。  \n* geteuid函数：获取调用该函数进程的有效用户ID，一般在没有调用seteuid函数进行修\n 改前，该用户ID就等于当初的运行该程序时的有效用户ID。  \n* getgid函数：获取调用该函数进程的实际组ID，一般在没有调用setgid函数进行修改\n 前，该用户组ID就等于当初运行该程序时的组ID。  \n* getegid函数：获取调用该函数进程的有效组ID，一般在没有调用setegid函数进行修改 前，该用户ID就等于当初运行该程序时的有效组ID。\n```c\n#include <sys/types.h>\n#include <unistd.h>\n#include <stdio.h>\nint main(void)\n{\n        //执行当前函数的进程ID\n        printf(\"pid  = %d\\n\", getpid());\n        //调用该函数的父进程ID\n        printf(\"ppid = %d\\n\\n\", getppid());\n\n        //调用该函数的实际用户ID\n        printf(\"uid  = %d\\n\", getuid());\n        //调用该函数的有效用户ID\n        printf(\"euid = %d\\n\\n\", geteuid());\n\n        // 调用该函数的实际组ID\n        printf(\"gid  = %d\\n\", getgid());\n        // 调用该函数的有效组ID\n        printf(\"egid = %d\\n\", getegid());\n\n        return 0;\n}\n\n```","categories":["C/CPP"],"tags":["Process"]},{"title":"C-open-write","url":"/posts/22783/","content":"> 总结了关于C语言的IO\n<!--more-->\n\n```c\n#include<stdlib.h>\n#include<string.h>\n#include<stdio.h>\nint main(int argc, char* argv[]){\n  char rootline[1024] = \"/root/os_process_shell/code/\";\n  FILE *file;\n  FILE *wfile;\n  char words[1024][1024];\n  int i = 0;\nif(argc >= 1){\n        strcat(rootline,argv[1]);\n        // open file\n        file = fopen(rootline,\"r\");\n        // 逐行读取\n        while(!feof(file)){\n        fgets(words[i],1000,file);\n        i++;\n        }\n}\n// write in txt file    \n  wfile = fopen(\"./word.txt\",\"w\");\n  int j = 0;\n  // 逐行写入\n  while(i>=0){\n        fwrite(words[j],sizeof(words[j]),1,wfile);\n        i--;\n        j++;\n}\n  return 0;\n}\n```\n<img src = \"http://xtzl.wentexl.cn/c_open_write.png\">","categories":["C/CPP"],"tags":[]},{"title":"Sqlserver-Grant","url":"/posts/20431/","content":">总结了关于权限管理的sql语句\n<!--more-->\n# 授予权限\n```sql\n-- 授予wente所有权限\ngrant all privileges on goods to wente\n\n-- 授予dbuser2 查询和修改Goods表的权限\n-- with grant option 表示是否可以把该权限授予其他用户\ngrant select,update on Goods to dbuser2 with grant option\n\n-- 授予dbuser2创建表和视图的权限\ngrant create table,create view to dbuser2\n```\n\n# 禁止权限\n```sql\n-- 禁止guest用户对Goods表进行crud的操作\ndeny select,insert,update, delete on Goods to guest\n```\n\n# 撤销权限\n```sql\n-- 撤销dbuser2对Goods表的查询和更新的权限\nrevoke select,update on Goods from dbuser2\n```\n# 查询权限信息\n```sql\n-- 查看用户名为dbuser2所拥有的权限\nExecute sp_helprotect @username = 'dbuser2'\n\n-- 查询获得某个权限的用户信息\nExecute sp_helprotect @name = 'create view'\n```\n","categories":["DataBase"],"tags":[]},{"title":"Caffeine","url":"/posts/46615/","content":"> 本文主要介绍了关于Caffeine的用法，仅限于如何使用Caffeine\n<!--more-->\n# Caffeine简介\n>Caffeine是一种在本地进行本地缓存的缓存库，可以使用它来搭建本地缓存  \n>可使用它构建本地缓存+Redis的多级缓存机制  \n>Caffeine提供了四种缓存添加策略：\n>* 手动加载\n>* 自动加载\n>* 手动异步加载\n>* 自动异步加载\n\n \n\n # 手动加载\n ```java\n  @Test\n    public void test1(){\n        Cache<String, String> cache = Caffeine.newBuilder()\n                //设置数据过期时间\n                .expireAfterWrite(10, TimeUnit.MINUTES)\n                //设置数据的最大长度\n                .maximumSize(10_000)\n                .build();\n\n        String key = \"key1\";\n\n        // 根据key查找一个缓存元素， 没有查找到的时候返回null\n                String value = cache.getIfPresent(key);\n        // 根据key查找缓存，如果缓存存在，则返回对应缓存值，如果缓存不存在则生成缓存元素,如果无法生成则返回nul\n                String value2 = cache.get(key, this::createValueByKey);\n\n        // 添加一个缓存元素\n                cache.put(\"key2\",\"xtzl\");\n                String value_key2 = cache.getIfPresent(\"key2\");\n                Assertions.assertEquals(\"xtzl\",value_key2);\n\n        // 移除一个缓存元素\n                cache.invalidate(\"key2\");\n                value_key2 = cache.getIfPresent(\"key2\");\n                Assertions.assertNull(value_key2);\n    }\n\n    // 没查到缓存之后生成缓存元素的方法,生成并自动加入到Cache中\n    private String createValueByKey(String key){\n        return key+\"_value\";\n    }\n ```\n\n # 自动加载\n ```java\n     @Test\n    public void test(){\n        LoadingCache<String, String> cache = Caffeine.newBuilder()\n                .maximumSize(10_000)\n                .expireAfterWrite(10, TimeUnit.MINUTES)\n                .build(this::createExpensiveGraph);\n        // 往缓存中存入数据\n            cache.put(\"key2\",\"value2\");\n        // 查找缓存，若存在则返回对应缓存值，如果缓存不存在则调用指定方法生成指定缓存值,  如果无法生成则返回null\n            String val_key1 = cache.get(\"key1\");\n            String val_key2 = cache.get(\"key2\");\n        // 批量查找缓存，如果缓存不存在则生成缓存元素\n            //模拟加入多个缓存元素\n            List<String> cacheKeyList= new ArrayList<String>();\n            for (int i = 1; i <= 5; i++) {\n                cache.put(\"k\" + i,\"v\" + i);\n                cacheKeyList.add(\"k\"+i);\n            }\n            Map<String, String> cacheAll = cache.getAll(cacheKeyList);\n\n            // 验证是否正常生成\n            Assertions.assertEquals(\"key1_cache_value\", val_key1);\n            Assertions.assertEquals(\"value2\",val_key2);\n            for (int i = 1; i <= 5; i++) {\n                Assertions.assertEquals(\"v\"+i,cacheAll.get(\"k\"+i));\n            }\n    }\n\n    private String createExpensiveGraph(String key){\n        return key+\"_cache_value\";\n    }\n \n ```\n\n # 手动加载与自动加载的区别\n >* 手动加载在Caffeine.newBuilder()中未指定创建缓存值的方法\n >* 手动加载将 getIfPresent() 和 get()方法区分开\n >* 手动加载在get()方法需要指定创建缓存值的方法    \n\n >总结：\n 个人感觉还是自动加载方便。因为在build我们的Cache的时候就已经指定了创建缓存值的方法\n\n# 手动异步加载\n```java\npublic class TestManualAsynchronous {\n    @Test\n    public void test() throws ExecutionException, InterruptedException {\n        AsyncCache<String, String> cache = Caffeine.newBuilder()\n                .expireAfterWrite(10, TimeUnit.MINUTES)\n                .maximumSize(10_000)\n                .buildAsync();\n\n            String key = \"key1\";\n        // 查找一个缓存元素， 没有查找到的时候返回null\n            CompletableFuture<String> key_value = cache.getIfPresent(key);\n        // 查找缓存元素，如果不存在，则异步生成对应key的缓存值\n            CompletableFuture<String> key_get_value = cache.get(key, this::createExpensiveGraph);\n        // 添加或者更新一个缓存元素\n            cache.put(key, key_get_value);\n        // 移除一个缓存元素\n        CompletableFuture<String> key3_value = cache.get(\"key3\", this::createExpensiveGraph);\n        cache.put(\"key3\",key3_value);\n        // 也要先转成同步的之后才移除\n        cache.synchronous().invalidate(\"key3\"); \n        CompletableFuture<String> key3_del = cache.getIfPresent(\"key3\");\n        // 验证\n        Assertions.assertNull(key_value);\n        // join()或者get()方法是得到字符串类型的值\n        Assertions.assertEquals(\"key1_value\",key_get_value.join()); \n        Assertions.assertNull(key3_del);\n    }\n    // 根据key创建对应的缓存元素，并自动加入到缓存Cache中\n    private String createExpensiveGraph(String key){\n        return key+\"_value\";\n    }\n}\n```\n# 自动异步加载\n```java\n    @Test\n    public void test() throws ExecutionException, InterruptedException {\n        AsyncLoadingCache<String, String> cache = Caffeine.newBuilder()\n                .maximumSize(10_000)\n                .expireAfterWrite(10, TimeUnit.MINUTES)\n                // 你可以选择: 去异步的封装一段同步操作来生成缓存元素\n                .buildAsync(this::createExpensiveGraph);\n            /** 也可以选择: 构建一个异步缓存元素操作并返回一个future\n                .buildAsync((key, executor) -> createExpensiveGraphAsync(key, executor));\n            */\n        String key = \"key1\";\n        // 查找缓存元素，如果其不存在，将会异步进行生成\n        CompletableFuture<String> key1_value = cache.get(key);\n\n        // 批量查找缓存元素，如果其不存在，将会异步进行生成\n        String [] keys = {\"k1\",\"k2\",\"k3\"};\n        List<String> keysList = Arrays.asList(keys);\n        CompletableFuture<Map<String, String>> keys_values_map = cache.getAll(keysList);\n        // 将CompletableFuture类型获取到其中的Map\n        Map<String, String> map = keys_values_map.get();\n        // 将Map中的元素提取成Set集合，元素为Entry类型，并使用Set集合的迭代器迭代遍历\n        Set<Map.Entry<String, String>> entries = map.entrySet();\n        Iterator<Map.Entry<String, String>> iterator = entries.iterator();\n        while (iterator.hasNext()){\n            Map.Entry<String, String> next = iterator.next();\n            System.out.println(next.getKey());\n            System.out.println(next.getValue());\n        }\n    }\n    private String createExpensiveGraph(String key){\n        return key+\"_value\";\n    }\n```\n# 同步和异步的差别\n>* 移除缓存元素，同步直接调用invalidate()就可移除，异步需要先使用synchronous()转成同步之后才能调用invalidate()移除元素\n>* get() 和 getIfPresent()方法在同步中直接返回的是缓存值，在异步方法中返回的是CompletableFuture类型的数据，CompletableFuture类型的数据需要执行join()或者get()方法才能获取到真正的缓存值\n\n\n# CacheLoader\n> CacheLoader共可实现6个方法\n>* load\n>* loadall\n>* asyncload\n>* asyncloadall\n>* reload\n>* asyncReload\n```java\n LoadingCache<String, Object> cache = Caffeine.newBuilder()\n        .maximumSize(10_000)\n        .expireAfterWrite(10, TimeUnit.MINUTES)\n        .build(new CacheLoader<String, Object>() {\n            @Override\n            // 调用get方法，若在缓存未命中，则生成一个缓存值\n            public @Nullable Object load(@NonNull String s) throws Exception {\n                return s + \"_value\";\n            }\n        });\n```\n\n# 注解的使用\n## 引入依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-cache</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.github.ben-manes.caffeine</groupId>\n    <artifactId>caffeine</artifactId>\n</dependency>\n```\n## 常用注解\n>- - -\n* @Cacheable：表示该方法支持缓存。当调用被注解的方法时，如果对应的键已经存在缓存，则不再执行方法体，而从缓存中直接返回。当方法返回null时，将不进行缓存操作。\n>- - -\n* @CachePut：表示执行该方法后，其值将作为最新结果更新到缓存中，每次都会执行该方法。\n>- - -\n* @CacheEvict：表示执行该方法后，将触发缓存清除操作。\n>- - -\n* @Caching：用于组合前三个注解，例如：\n```java\n@Caching(cacheable = @Cacheable(\"CacheConstants.GET_USER\"),\n         evict = {@CacheEvict(\"CacheConstants.GET_DYNAMIC\",\n         allEntries = true)})\n```\n>- - -\n# 多级缓存(二级缓存)的逻辑实现图\n>* 要求一级缓存的数据过期时间要比二级缓存短\n>* 我的项目中，Caffeine缓存时间是30s，redis缓存时间是3分钟\n<img src = \"http://xtzl.wentexl.cn/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98%E9%80%BB%E8%BE%91.png\"/>","categories":["TechStack"],"tags":["Cache"]},{"title":"Sqlserver_TSQL","url":"/posts/4967/","content":">Transction-Sql的积累，主要是与事务，流程相关的东西\n<!--more-->\n```sql\n-- 游标的使用场景:\n-- 数据表有几千万数据，需要就其中约百万数据进行更新，不能锁表。因此采用游标进行更新\n\n-- 1.游标查询\n-- 建立scroll滚动游标\n-- 定义游标,scroll是参数，cursor是固定的定义格式\ndeclare cur scroll cursor for\n\tselect * from goods join category on goods.categoryno = category.categoryno where category.categoryname = '洗发水'\n-- 打开游标\nopen cur\n-- 游标指向上面查询出来的表的第一条数据\nfetch first from cur \n-- 指向最后一条\nfetch last from cur\n-- 从上往下数，第十条数据（绝对的）\nfetch absolute 10 from cur\n-- 从当前游标所在的位置往后数的第五个数据 （相对于当前游标所在位置，是相对的）\nfetch relative 5 from cur\n-- 固定格式，关闭游标\nclose cur\ndeallocate cur\n\n\n-- 2.游标更新\ndeclare @Id char(6); -- 声明临时变量\n-- 声明更新游标\ndeclare cur_up scroll cursor for \n\t(select goodsno from goods join category on goods.categoryno = category.categoryno where category.categoryname = '咖啡') for update of saleprice;\nopen cur_up;\nfetch next from cur_up\ninto @Id;\nwhile @@FETCH_STATUS = 0\nbegin\n\tupdate goods set saleprice = saleprice *0.9 where goods.goodsno = @Id\n\t-- 切换\n\tfetch next from cur_up\n\tinto @Id\nend;\nclose cur_up\ndeallocate cur_up\n\n\n-- 触发器的使用场景：当需要删除与多表之间相连的数据，但又不想使用级联的时候\n-- 由系统调用，我们也需要表明调用的实际和规则\n\n-- 3.触发器实现商品的购买\ncreate trigger sale_trigger\non\tsalebill\nafter insert as\ndeclare @changenum int\ndeclare @change_goodsno char(6)\n\nselect @changenum = number from inserted \nselect @change_goodsno = goodsno from inserted\nbegin\n\tupdate goods set number = (number - @changenum) where goods.goodsno = @change_goodsno\nend\n\n-- 激活对应表中某个触发器,如果要激活所有的，就把触发器名改为all\nalter table salebill enable trigger sale_trigger\n\n-- 实行购买操作，向saleprice表中增加购买记录\ninsert into salebill values('gn001','s01','2022-10-25 17:18:00',2);\n\nselect * from salebill join  goods on salebill.goodsno = goods.goodsno\nselect * from goods\n\n\n-- 4.触发器实现删除类别信息的时候同时删除商品表中对应类别编号设置为其他类别\ncreate trigger category_trigger \non category \nafter delete as\ndeclare @del_categoryno char(6)\nselect @del_categoryno = categoryno from deleted\n\nbegin\n\tupdate goods set categoryno = 'cn006' where goods.categoryno = @del_categoryno\nend\n\nalter table category enable trigger category_trigger\n\n-- 执行删除类别信息的操作\ndelete from category where category.categoryno = 'cn005'\n\nselect * from category\nselect * from goods\n\n-- 5.创建触发器：实现在供应商表Supplier中删除供货商时，同时删除该供货商所供应的商品信息及商品的销售记录。\ncreate trigger supplier_trigger\non supplier \ninstead of delete as\ndeclare @sup_no char(6)\n\n-- 值\nselect @sup_no = supplierno from deleted\nbegin\n\tdelete from salebill where salebill.goodsno in \n\t(select goodsno from goods where goods.supplierno = @sup_no)\n\n\tdelete from goods where goods.supplierno = @sup_no\n\tdelete from supplier where supplier.supplierno = 'sup002'\nend\n\nalter table supplier enable trigger supplier_trigger\n\nselect * from supplier join goods on goods.supplierno = supplier.supplierno join salebill on salebill.goodsno = goods.goodsno\nselect * from salebill\n\n-- 6.创建触发器：向销售表SaleBill中插入一条记录时，这个触发器将更新商品表Goods。要求：Goods表中数量为原有数量减去销售数量\n--\t  如果库存数量小于10，则提示“该商品数量小于10，低于安全库存量，请及时进货”；如果原有数量不足，则提示“数量不足！”\n\ncreate trigger saleprint_goods\non salebill\nafter insert as \ndeclare @sale_goodsno char(6)\ndeclare @change_number int\ndeclare @now_number int\ndeclare @end_number int \n\nselect @sale_goodsno = goodsno,@change_number = number from inserted\nselect @now_number = number from goods where goodsno = @sale_goodsno\nset @end_number = @now_number - @change_number\n\nbegin\n\tif(@end_number < 10 and @end_number>=0 )\n\t\tprint('该商品数量小于10，低于安全库存量，请及时进货')\n\telse if( @end_number < 0)\n\t\tprint('数量不足')\n\telse\n\t\tupdate goods set number = @end_number where goods.goodsno = @sale_goodsno\nend\n-- 激活触发器\nalter table salebill enable trigger saleprint_goods\n-- 执行插入命令\ninsert into salebill values('gn005','s05','2022-10-26 11:16:00',1)\ninsert into salebill values('gn005','s05','2022-10-26 11:16:00',4)\ninsert into salebill values('gn007','s05','2022-10-26 11:16:00',2)\n\nselect * from salebill join goods on goods.goodsno = salebill.goodsno\n\n```","categories":["DataBase"],"tags":[]},{"title":"Sqlserver_View","url":"/posts/46353/","content":">主要讲的是视图创建的东西\n<!--more-->\n\n```sql\nuse supermarket_Insert\n-- 1.\ncreate view V_MIS as select * from student where major = 'MIS'\n\nselect * from V_MIS\n\n--2.\ncreate view V_SSG as \nselect student.sno,student.sname,goods.goodsname,goods.saleprice,salebill.number \nfrom student \njoin salebill \non student.sno = salebill.sno \njoin goods on \ngoods.goodsno = salebill.goodsno\n\n\n-- 3.\ncreate view V_AGE as \nselect *,\n\t(2020 - student.birthyear) as age\nfrom\n\tstudent\n\nselect * from V_AGE\n\n-- 4.\ncreate view V_COM as\nselect\n\tstudent.college,\n\tcount(*) counts_num,\n\tAVG(2020-student.birthyear) avg_age\nfrom \n\tstudent\ngroup by\n\tstudent.college\n\nselect * from V_COM\n\n-- 5.\ncreate view V_S_CONSUME as\nselect\n\tstudent.sno,\n\tSUM(goods.saleprice * salebill.number) cost_all,\n\tcount(distinct goods.categoryno) goods_category_counts\nfrom\n\tstudent\njoin\n\tsalebill\non\n\tstudent.sno = salebill.sno\njoin\n\tgoods\non\n\tgoods.goodsno = salebill.goodsno\ngroup by\n\tstudent.sno\n\nselect * from V_S_CONSUME\n\n\n--6 .\ncreate view V_GOOODS as \nselect\n\tgoods.categoryno,\n\tcount(*) goods_num,\n\tAVG(goods.saleprice) avg_price,\n\tmin(goods.number) min_number\nfrom\n\tgoods\ngroup by\n\tgoods.categoryno\n\t\nselect * from V_GOOODS\n\n-- 7.\ncreate view V_SU_GOOD as\nselect\n\tgoods.supplierno,\n\tsum(goods.number) goods_counts_rest_sum,\n\tAVG(goods.inprice) goods_inprice_avg,\n\tsum(case when salebill.goodsno is null then goods.number else goods.number+salebill.number end) goods_counts_all_sum\nfrom\n\tgoods\nleft join\n\tsalebill\non\n\tgoods.goodsno = salebill.goodsno\ngroup by\n\tgoods.supplierno\n\nselect * from V_SU_GOOD\n\n-- 8.\nselect \n\t*\nfrom\n\tV_COM\nwhere\n\tavg_age > 19\n\n-- 9.\nselect * from\n\tV_S_CONSUME\nwhere\n\tcost_all > 20\n\n-- 10.\nselect\n\tsupplier.suppliername,\n\tsupplier.number,\n\tsupplier.address\nfrom\n\tV_SU_GOOD\njoin\n\tsupplier\non\n\tsupplier.supplierno = V_SU_GOOD.supplierno\nwhere\n\tgoods_counts_rest_sum < 50\n\n-- 11.\ninsert into V_MIS values('s09','宋江','2000','男','CS','MIS','wx009')\n\nselect * from V_MIS\n\n-- 12.\ninsert into V_MIS values('s10','周瑜','1999','男','CS','IT','wx010')\nselect * from V_MIS\nselect * from student\n\n-- 13.\nupdate V_MIS set sname = '李欢欢' where sno = 's01'\n\n-- 14.\nupdate V_MIS set sname = '徐慧慧' where sno = 's02'\nselect * from V_MIS\n\n-- 15.\nupdate V_SSG set saleprice = 10 where sname = '力神咖啡'\nselect * from V_SSG\n\n-- 16.\ndelete from V_MIS where sno = 's09'\nselect * from V_MIS\n\n-- 17.\ndelete from V_MIS where sno = 's10'\nselect * from V_MIS\nselect * from student\n\n```","categories":["DataBase"],"tags":[]},{"title":"Sqlserver_DQL","url":"/posts/19382/","content":">关于数据查询语言的修改\n<!--more-->\n```sql\nuse supermarket;\n\n\n--1 \nselect * from goods\n\n--2 条件查询\nselect\n\t* \nfrom\n\tgoods\nwhere\n\tgoods.categoryno = 'cn002'\n\n--3 条件查询\nselect\n\t*\nfrom\n\tgoods\nwhere\n\tgoods.categoryno = 'cn001'\n\tor\n\tgoods.categoryno = 'cn002'\n\n\n--4 条件查询\nselect\n\t*\nfrom\n\tgoods\nwhere\n\tgoods.inprice > 20\nand\n\tgoods.categoryno = 'cn005'\n\n\n--5 内连接查询\nselect\n\tgoods.goodsno,\n\ts.supplierno,\n\tgoods.goodsname,\n\tgoods.number\nfrom\n\tgoods\njoin\n\tsupplier s\non\n\tgoods.supplierno = s.supplierno\nwhere\n\tgoods.number < 10\n\n\n--6 左外连接查询\nselect\n\tstu.sno\nfrom\n\tstudent stu\nleft join\n\tsalebill\non\n\tsalebill.sno = stu.sno\nwhere\n\tsalebill.goodsno is not null\n\n--7 条件查询\nselect\n\tstu.sno,\n\tstu.sname,\n\t(2022-stu.birthyear) age\nfrom\n\tstudent stu\nwhere\n\tstu.major = 'IT'\n\n--8 条件查询\nselect\n\tstu.sno,\n\tstu.sname,\n\tstu.college,\n\tstu.major,\n\t(2022- stu.birthyear) age\nfrom\n\tstudent stu\nwhere\n\t(2022- stu.birthyear) >= 22\nand\n\t(2022- stu.birthyear) <= 24\n\n--9 模糊查询\nselect\n\tstu.sno,\n\tstu.sname,\n\tstu.college\nfrom\n\tstudent stu\nwhere\n\tstu.sname like '张%'\n\n--10 排序查询\nselect\n\t*\nfrom\n\tgoods\nwhere\n\tgoods.number > 20\norder by \n\tgoods.number DESC\n\n\n--11 条件查询，排序查询\nselect\n\tgoods.goodsno,\n\tgoods.goodsname,\n\tgoods.categoryno,\n\tgoods.number\nfrom\n\tgoods\nwhere\n\tgoods.number <= 10\norder by\n\tgoods.categoryno ASC,\n\tgoods.number DESC\n\n\n\n\n--12.top的使用,解决了并列问题\nselect\n\ttop 3 *\nfrom\n\tgoods\nwhere\n\tgoods.number in (\n\t\tselect\n\t\t\ttop 3 number\n\t\tfrom\n\t\t\tgoods\n\t)\norder by goods.number DESC\n\n\n--13. 子查询\nselect\n\tgoods.goodsno,\n\tgoods.goodsname,\n\tgoods.number\nfrom\n\tgoods\njoin\n\tcategory\non\n\tgoods.categoryno = category.categoryno\nwhere\n\tcategory.categoryno = 'cn001'\nand\n\tgoods.number = (select max(number) from goods)\n\n--14.条件查询\nselect\n\tcount(*) countStu\nfrom\n\tstudent\nwhere\n\tstudent.major = 'MIS'\n\t\n\n\n--15. 分组查询\nselect\n\tstudent.college,\n\tcount(*) countAge\nfrom\n\tstudent\nwhere\n\t(2022 - student.birthyear) >= 20\ngroup by\n\tcollege\n\n--16.内连接查询\nselect\n\tgoods.goodsno,\n\tgoods.goodsname,\n\tsum(salebill.number) salecounts\nfrom\n\tsalebill\njoin \n\tgoods\non\n\tgoods.goodsno = salebill.goodsno\nwhere\n\tsalebill.happentime > CONVERT(date,'2018-01-01 00:00:00')\nand\n\tsalebill.happentime < CONVERT(date,'2019-01-01 00:00:00')\ngroup by\n\tgoods.goodsno,\n\tgoods.goodsname\n\n\n--17. having子句\nselect\n\tcollege,\n\tCOUNT(*) counts\nfrom\n\tstudent \ngroup by\n\tcollege\nhaving\n\tcount(*) > 3\n\n\n--18.派生表查询\nselect\n\tstu.sno,\n\tstu.sname,\n\tsalenum.countsnum\nfrom\n\tstudent stu,\n\t(\n\t\tselect\n\t\t\tsum(salebill.number) countsnum\n\t\tfrom\n\t\t\tsalebill\n\t\tjoin\n\t\t\tstudent\n\t\ton student.sno = salebill.sno\n\t\twhere\n\t\t\tsalebill.happentime > CONVERT(date,'2019-01-01 00:00:00')\n\t\tand\n\t\t\tsalebill.happentime < CONVERT(date,'2020-01-01 00:00:00')\n\t\tgroup by\n\t\t\tstudent.sno\n\t) salenum\nwhere\n\tsalenum.countsnum > 5\n\n-- 19.内连接查询\nselect\n\tAVG(goods.saleprice) avg_sale_price\nfrom\n\tgoods\njoin\n\tcategory\non\n\tgoods.categoryno = category.categoryno\nwhere\n\tcategory.categoryname = '咖啡'\n\n--20.相关子查询\nselect\n\tsno,\n\tsname,\n\tcollege\nfrom\n\tstudent stu\nwhere\n\tstu.college = (\n\t\tselect\n\t\t\tcollege\n\t\tfrom\n\t\t\tstudent\n\t\twhere\n\t\t\tstudent.sname = '张小红'\n\t)\n\n\n-- 21.内连接查询\nselect\t\n\tg.goodsno,\n\tg.goodsname,\n\tstu.sno,\n\tstu.sname,\n\ts.happentime,\n\ts.number\nfrom\n\tgoods g\njoin\n\tsalebill s\non\n\tg.goodsno = s.goodsno\njoin \n\tstudent stu\non\n\tstu.sno = s.sno \norder by\n\ts.happentime DESC\n\n-- 22. 内连接查询\nselect\n\tstu.sno,\n\tstu.sname,\n\tstu.college\nfrom\n\tstudent stu\njoin\n\tsalebill\non\n\tsalebill.sno = stu.sno\n\n\n--23. 内连接查询\nselect\n\tstu.sno,\n\tstu.sname,\n\tstu.college\nfrom\n\tstudent stu\njoin\n\tsalebill\non\n\tstu.sno = salebill.sno\njoin\n\tgoods\non\n\tgoods.goodsno = salebill.goodsno\njoin\n\tcategory\non\n\tgoods.categoryno = category.categoryno\nwhere\n\tcategory.categoryname = '咖啡'\n\n\n-- 24.连接查询\nselect\n\tg.goodsno,\n\tgoodsname,\n\tc.categoryname,\n\tg.saleprice,\n\tg.number\nfrom\n\tgoods g\njoin \n\tcategory c\non\n\tg.categoryno = c.categoryno\nleft join\n\tsalebill s\non\n\tg.goodsno = s.goodsno\nwhere\n\ts.happentime is null\n\n\n--24.子查询\nselect\n\tg.goodsno,\n\tgoodsname,\n\tc.categoryname,\n\tg.saleprice,\n\tg.number\nfrom \n\tgoods g,\n\tcategory c\nwhere\n\tg.categoryno = c.categoryno\nand\n\tg.goodsno not in(\n\t\tselect\n\t\t\tgoodsno\n\t\tfrom\n\t\t\tsalebill\n\t)\n\n\t\n-- 25.同26题\nselect\n\tstudent.sno,\n\tsname,\n\tcollege\nfrom\n\tstudent\njoin \n\tsalebill\non\n\tstudent.sno = salebill.sno\nwhere\n\tsalebill.goodsno = 'gn001'\n\n-- 26.用内连接查询实现\nselect\n\tstudent.sno,\n\tsname,\n\tcollege\nfrom\n\tstudent\njoin \n\tsalebill\non\n\tstudent.sno = salebill.sno\nwhere\n\tsalebill.goodsno = 'gn001'\n\n\n-- 27.用子查询实现\nselect \n\tsno,\n\tsname,\n\tcollege\nfrom \n\tstudent\nwhere\n\tsno in (\n\t\tselect\n\t\t\tsno\n\t\tfrom\n\t\t\tstudent\t\n\t\twhere\n\t\t\tbirthyear in (\n\t\t\t\t\tselect\t\n\t\t\t\t\t\tmin(birthyear)\n\t\t\t\t\tfrom\n\t\t\t\t\t\tstudent\n\t\t\t\t\tgroup by\n\t\t\t\t\t\tcollege\n\t\t\t)\n\n\t)\n\n-- 27.用派生表实现\nselect \n\tsno,\n\tsname,\n\tstuM.college\nfrom \n\tstudent stuM,\n\t(select \n\t\tmin(stuN.birthyear) as birthyear,\n\t\tstuN.college\n\t from\n\t\tstudent stuN\n\t group by\n\t\tcollege\t\n\t\t) as stuP\nwhere\n\tstuM.birthyear = stuP.birthyear\nand \n\tstuM.college = stuP.college\n\n\n--28.用内连接查询\nselect\n\tg.goodsno,\n\tg.goodsname\n\t-- SUM(s.number) as counts\nfrom\n\tgoods g\njoin\n\tsalebill s\non\n\tg.goodsno = s.goodsno\ngroup by \n\tg.goodsno,\n\tg.goodsname\n\n-- 28.派生表查询\nselect\n\tg.goodsno,\n\tgoodsname,\n\tgs.counts_num\nfrom\n\tgoods g,\n\t(\n\tselect \n\t\tsum(number) as counts_num,\n\t\tgoodsno\n\t from\n\t\tsalebill\n\tgroup by \n\t\tsalebill.goodsno\n\t) gs\nwhere\n\tg.goodsno = gs.goodsno;\n\n--29. 派生表查询\nselect\n\tstu.sno,\n\tsname,\n\tcollege\nfrom\n\tstudent stu,\n\t(\n\tselect\n\t\tsno,\n\t\tsum(number) buy_counts\n\tfrom\n\t\tsalebill\n\twhere\n\t\thappentime < convert( date,'2020-01-01 00:00:00')\n\tand\n\t\thappentime > CONVERT(date,'2019-01-01 00:00:00')\n\tgroup by\n\t\tsno\n\t)sum_number\nwhere\n\tstu.sno = sum_number.sno\n\n\n--30.派生表\nselect\n\tsup.supplierno,\n\tsup.suppliername,\n\tsup.address\nfrom\n\tsupplier sup,\n\t(\n\tselect\n\t\tsupplierno,\n\t\tsum(number) sum_number\n\tfrom\n\t\tgoods\n\tgroup by\n\t\tsupplierno\n\t) sumgoods\nwhere\n\tsumgoods.sum_number > 50\nand \n\tsup.supplierno = sumgoods.supplierno\norder by \n\tsumgoods.sum_number DESC\n\n\n\n\n\t-- 导入新的sql\n\t-- 选做1\nselect\n\ttop 1 st.college,\n\tmax(c_sum) max_sum\nfrom\n\t(\n\tselect\n\t\tstu.college college,\n\t\tsum(salebill.number) c_sum\n\tfrom\n\t\tstudent stu\n\tjoin \n\t\tsalebill\n\ton stu.sno = salebill.sno\n\tgroup by \n\t\tstu.college\n\t) cs,\n\t\tstudent st\nwhere\n\tst.college = cs.college\ngroup by\n\tst.college\norder by\n\tmax_sum DESC\n```","categories":["DataBase"],"tags":[]},{"title":"Sqlserver_DML","url":"/posts/35774/","content":">关于数据操纵语言的积累\n<!--more-->\n```sql\nuse supermarket_Insert;\n\n-- 向goods表中添加数据\ninsert into goods values('GN0001','Sup001','CN001','优乐美奶茶',2.5,3.5,100,'2019-12-20')\ninsert into goods values('GN0002','Sup002','CN001','雀巢咖啡',4,5.8,50,'2017-06-08')\ninsert into goods values('GN0005','Sup003','CN002','飘柔洗发水',15,19.8,65,'2019-05-29')\ninsert into goods values('GN0007','Sup005','CN005','小绵羊被套',120,150,28,'2019-11-22')\n\n-- 向supplier表中添加数据\ninsert into supplier values('sup001','卡夫食品','广东佛山','12348768900')\ninsert into supplier values('sup002','久润食品','广东东莞','13248768901')\ninsert into supplier values('sup003','飞鹤食品','重庆解放碑','12648768901')\ninsert into supplier values('sup004','南山日化','重庆南坪','11648768903')\ninsert into supplier values('sup005','缙云日化','重庆北培','19648768903')\n\n-- 向Category表中添加数据\ninsert into category values('CN001','咖啡','速溶咖啡，袋装咖啡，咖啡粉')\ninsert into category values('CN002','洗发水','袋装，瓶装洗发水')\ninsert into category values('CN005','床上用品','被套，枕套,床单')\n\n-- 向student表中添加数据\ninsert into student values('S01','李明','1999','男','CS','IT','wx001')\ninsert into student values('S02','徐好','1998','女','CS','MIS','wx002')\ninsert into student values('S03','伍民','1996','男','CS','MIS','wx003')\ninsert into student values('S04','闵红','1997','女','ACC','AC','wx004')\ninsert into student values('S05','张小红','1997','女','ACC','AC','wx005')\n\n-- SaleBill表中添加数据\ninsert into salebill values('GN0001','S01','2020-06-09','3')\ninsert into salebill values('GN0001','S02','2020-05-03','1')\ninsert into salebill values('GN0001','S03','2020-04-07','1')\ninsert into salebill values('GN0002','S02','2020-05-08','2')\ninsert into salebill values('GN0002','S05','2020-06-26','2')\ninsert into salebill values('GN0005','S05','2020-06-01','1')\n\n\n-- mysql的多表联合修改\nUPDATE `daily_heath` d JOIN `stu_tea` s ON d.hea_id = s.hea_id SET d.peo_id = s.peo_id;\n\n-- 2.\nupdate goods set goodsname = '雀巢咖啡条a装' where goodsname = '雀巢咖啡'\n\n-- 3.\nupdate goods set saleprice = saleprice*1.05\n\n-- 4.\nupdate category set categoryno = 'CN004' where categoryno = 'CN005'\n\n-- 5.\nupdate goods set saleprice = saleprice*0.8 \nwhere goods.goodsno in\n(\tselect\n\t\tgoodsno\n\tfrom\n\t\tsalebill\n\twhere\n\t\tsalebill.number < 3\n\tand\n\t\tsalebill.happentime < '2021-01-01'\n\tand \n\t\tsalebill.happentime > '2020-01-01'\n)\n-- 6.\nupdate goods set number = 0 where supplierno = \n( select\n\tsupplierno\n  from\n\tsupplier\n  where\n\tsupplier.suppliername = '久润食品'\n)\n\n--7. \ndelete from salebill where salebill.number < 3 and salebill.goodsno = (\n\tselect\n\t\tgoodsno\n\tfrom\n\t\tgoods\n\twhere\n\t\tgoods.goodsname = '优乐美奶茶'\n)\n\n-- 8.\ndelete from goods where producttime < '2018-01-01' \nalter table salebill add constraint PK_sale_goods foreign key(goodsno) references goods(goodsno) on delete cascade\n\n-- 9.\ndelete from salebill where goodsno in (\n\tselect\n\t\tgoodsno\n\tfrom\n\t\tgoods\n\tjoin\n\t\tsupplier\n\ton\n\t\tgoods.supplierno = supplier.supplierno\n\twhere\n\t\tsupplier.suppliername = '卡夫食品')\n\n-- 10.\ndelete from salebill where salebill.sno in (\n\tselect\n\t\tsno\n\tfrom student\n\twhere\n\t\tstudent.college = 'ACC'\n)\n\n-- 11.\ndelete from salebill\ndelete from goods\n\n--12.\ndelete from student where student.birthyear < 1997\n\nupdate goods set categoryno = 'CN001' where goodsno = 'GN0002'\n\n\nselect * from salebill\nselect * from student\nselect * from goods\nselect * from category\nselect * from supplier\n\n\n```","categories":["DataBase"],"tags":[]},{"title":"Sqlserver_DDL","url":"/posts/56248/","content":">关键数据定义语言的sql语句\n<!--more-->\n```sql\ncreate database sqlserverdatabase;\nuse sqlserverdatabase;\n\n\n-- 货品表\n\ncreate table Goods(\n\tGoodsNo varchar(15) primary key,\n\tSupplierNO char(6),\n\tCategoryNO varchar(15),\n\tGoodsName varchar(10),\n\t-- 六位数，保留一位小数\n\tInPrice\tdecimal(6,1),\n\tSalePrice decimal(6,1),\n\tNumber int,\n\tProductTime date\n);\n\n\n-- 增加保质期属性列\nalter table Goods add QGperiod int;\n-- 修改Goods表“进价”属性列为精确数值型，总共七位，保留一位小数。\nalter table Goods alter column InPrice decimal(7,1)\n-- CategoryNO为外码，对Category表的主键\nalter table Goods add constraint outsidecode foreign key(CategoryNO) references Category(CategoryNO);\n\n-- 删除外键\nalter table Gooos drop foreign key outsidecode\n\nselect * from Goods;\nDELETE FROM Goods;\n\n-- 学生表\n/*==============================================================*/\n/* Table: Student                                               */\n/*==============================================================*/\ncreate table Student (\n   SNO                  varchar(15)                  not null,\n   SName                varchar(10)          null,\n   BirthYear            int                  null,\n   Gender               char(1)              null,\n   College              varchar(10)          null,\n   Major                varchar(10)          null,\n   WeiXin               varchar(20)          not null,\n   -- 添加主键约束\n   constraint PK_STUDENT primary key (SNO)\n);\n-- 添加WeiXin唯一值约束\nalter table Student add constraint WeixinUnique unique(WeiXin);\n-- 添加check约束\nalter table Student add constraint mycheckN check(Gender = '男' or Gender = '女')\n-- 删除student表中的出生年份这一列\nalter table Student drop column BirthYear;\n-- 删除表student的唯一值约束\nalter table Student drop WeixinUnique;\n\n\nselect * from Student;\n\n\n\n-- 销售表\ndrop table SaleBill;\n/*==============================================================*/\n/* Table: SaleBill                                              */\n/*==============================================================*/\ncreate table SaleBill (\n   GoodsNO              varchar(15)              not null,\n   SNO                  varchar(15)                  not null,\n   HappenTime           date                 null,\n   Number               int                  null,\n   constraint PK_SALEBILL primary key (GoodsNO,SNO)\n)\n-- 在表SaleBill上增加数量大于0的约束。\nalter table SaleBill add constraint numlimit check(Number > 0);\n-- 将表SaleBill上数量的约束修改为0~100。\nalter table SaleBill add constraint changedlimit check(Number >=0 and Number <=100)\n\n\n\n\n-- 商品种类表\n/*==============================================================*/\n/* Table: CategoryNO                                            */\n/*==============================================================*/\ncreate table Category (\n   CategoryNO           varchar(15)          not null,\n   CategoryName         varchar(15)          null,\n   Descriptions         varchar(100)         null,\n   constraint PK_CATEGORYNO primary key (CategoryNO)\n)\n\n-- 在Category表上，按商品类别编号属性列升序 和 商品类别名属性降序建立唯一值索引。\ncreate unique nonclustered index indexMO on Category(CategoryNO ASC,CategoryName DESC);\n\n-- 供应商表\n/*==============================================================*/\n/* Table: Supplier                                              */\n/*==============================================================*/\ncreate table Supplier (\n   SupplierNO           varchar(15)          not null,\n   SupplierName         varchar(15)          null,\n   Address              varchar(20)          null,\n   TelNumber               varchar(20)          null,\n   constraint PK_SUPPLIER primary key (SupplierNO)\n)\n\n-- 在表supplier表上，按供应商号 属性列的唯一值方式建立索引。\ncreate unique nonclustered index indexNO on Supplier(SupplierNO ASC); \n-- 删除supplier上的唯一值索引。\ndrop index indexNO on Supplier;\n\n\n```","categories":["DataBase"],"tags":[]},{"title":"Sqlserver_command","url":"/posts/27698/","content":"\n关于sqlServer的一些命令的创建\n\n<!--more-->\n# JavaType-Mapping-SqlType\n<img src = \"http://xtzl.wentexl.cn/%E6%96%87%E6%A1%A3.png\"> \n\n# Transact-SQL\n## 自定义数据类型\n```sql\n    -- 创建自定义数据类型\n    1, create type\n    例： create type goodsNO from varchar(20) Not NULL\n\n    2, sp_addtype\n    例： EXEC sp_addtype comment,text,NULL\n\n    -- EXEC ： 表示执行后面的存储过程\n    -- 删除自定义数据类型\n    1, sp_droptype \n    例： EXEC sp_droptype goodsNo\n\n    -- 查看自定义的comment的数据类型的相关信息\n    2, sp_help\n    例： EXEC sp_help comment\n```\n\n## 常量或变量\n```sql\n-- 常量\n日期常量：\n    '2/14/2018'  表示 2018 年 2月 14 日\n    '2018-1-19'  表示 2018 年 1月 19 日\n    'Mar 8,2018' 表示 2018 年 3月  8 日\n\n-- 局部变量\n-- 定义\ndeclare @local1 int\ndeclare @local2 char(5), @local3 float\n-- 赋值\nset @local1 = 56 -- 只可给单个变量赋值\nselect @local2 = 'world', @local3 = '34.2'\n-- 将table1表中local3为local1的值的数据，赋值给自定义的变量local2\nselect @local2  =  local3 from table1 where local2 = @local1\n\n-- 以文本形式输出\nprint(@local2)\n-- 以表格形式输出多个变量值\nselect @local2, @local3\n```\n\n## 流程控制语句\n```sql\n-- IF语句\ndeclare @in decimal(18,2), @sale decimal(18,2)\nselect @in = Inprice,@sale = SalePrice from goods where gooodsno = 'G001'\n\nIF @in > @sale\n    print('GN001是打折商品')\nelse if @in = @sale\n    print('测试用例')\nELSE\n    print('GN001是正价商品')\n\n\n-- Case语句\ncase expression\n    when expression1 then result1\n    when expression2 then result2\n    ELSE result3\nEND\n```\n\n# 存储类型\n* varchar(10)，只能存储10个英文字符或数字，也只能存储5个汉字；\n* char(10)，只能存储10个英文字符或数字，也只能存储5个汉字；\n* nvarchar(10)，即存储10个英文字符或数字，也能存储10个汉字；\n* nchar(10)，即存储10个英文字符或数字，也能存储10个汉字\n\n# Date或者DateTime类型的年月日函数\n* year(date)\n* month(date)\n* day(date)\n* datediff(datepart,startdate,enddate):计算两个时间的差值,比如：datediff(yy,getdate(),'2008-08-08') : 表示计算年份的差值\n* getdate() 是获取当时时间，类型是datetime类型\n\n# 截取字符串\n* left('abcdefg',3) ,从左开始截取3位\n* right('asdasd',4), 从右开始截取4位\n* substr('asdadasd',2,4) 截取下标2~3的字符\n\n# 修改自增\nALTER TABLE category AUTO_INCREMENT = 1;\n\n\n\n\n\n\n\n","categories":["DataBase"],"tags":[]},{"title":"JUC","url":"/posts/30559/","content":">主要总结了关于JUC的相关知识点\n<!--more-->\n# 随记\n>* volatile ： 强制每个线程到主存去获取数据而不是去Cache\n\n## JUC辅助类\n### CountDownLatch(减少计数)\n>* 使用场景： 多个线程互相等待都执行完毕之后，统一执行主线程\n### CyclicBarrier(循环栅栏)\n>* 使用场景： 多个线程互相等待都执行完毕之后，统一执行另一线程\n### Semaphore(信号灯)\n>* 使用场景： 类似于线程池，多个线程抢夺有限个执行机会(锁的机制)\n\n# 锁\n## 无锁\n>多线程争夺资源，很乱\n## 普通锁\n>使用synchronized和ReentrantLock (都是独占锁)\n## 读写锁 ReentrantReadWriteLock\n> * 读读可以共享，支持多人读，可以提升性能\n> * 写锁还是一个线程独占的\n> **缺点:** \n>1, 造成锁饥饿，一直读却没有写\n>2, 同一线程读锁的情况下不能再写锁(可能会死锁)，但是同一线程写锁的情况下还可以去读锁\n> * 锁降级：写锁可以降级为读锁，读锁不能升级为写锁 :即同一线程读的时候不能写，但写的时候可以读\n\n\n## 锁的介绍 \n>* 自旋锁：自旋，jvm默认是10次吧，有jvm自己控制。自旋锁，它并不会放弃CPU时间片，而是通过自旋等待锁的释放，也就是说，它会不停地再次地尝试获取锁，如果失败就再次尝试，直到成功\n>* 阻塞锁：被阻塞的线程，不会争夺锁。\n>* 可重入锁： 多次进入改锁的域\n>* 读写锁\n>* 互斥锁：锁本身就是互斥的\n>* 悲观锁：不相信，这里会是安全的，必须全部上锁\n>* 乐观锁：相信，这里是安全的。\n>* 公平锁：有优先级的锁\n>* 非公平锁：无优先级的锁\n>* 偏向锁：无竞争不锁，有竞争挂起，转为轻量锁\n>* 对象锁：锁住对象\n>* 线程锁\n>* 锁粗化：多锁变成一个，自己处理\n>* 轻量级锁：CAS 实现\n>* 锁消除：偏向锁就是锁消除的一种\n>* 锁膨胀：jvm实现，锁粗化\n>* 信号量:使用阻塞锁 实现的一种策略\n\n# 阻塞队列\n * 放入  |  取出  |     取队首元素 |    触发  \n * add   | remove  |   element |    抛异常  \n * offer |  poll   |     peek  |     返回Bool  \n * put   |  take    |     无   |     处于阻塞状态，一直处于运行  \n * offer(e,time,unit) |  poll(time,unit)  这种方式的可设置阻塞时间，如果超过设置时  间，则返回Bool\n\n\n# 创建线程的多种方式：\n * 1,继承Thread类 ：参数不可传入Callable\n * 2,实现Runnable接口\n * 3,通过Callable接口\n * 4,通过线程池的方式来创建接口\n\n# Runnable（Thread默认）与Callable接口的比较\n  1,返回值（R无，C有）  \n  2,是否会抛出异常(R无，C有)  \n  3,Callable 和 Runnable都是函数式接口，都可以使用 lambada 表达式  \n  4,实现方法名称:  \n  * Runnable: run方法  \n  * Callable: call方法  \n  \n>- - -\n  Runnable接口有个实现类：FutureTask  \n  * FutureTask构造可以传递 Callable,有Callable的构造方法  \n  * FutureTask可以先单开线程去做其他事情，最后汇总，汇总只需要一次  \n  * FutureTask实际上是构造方法既能传入Callable、也可以传入Runnable  \n\n\n\n\n# 线程池\n## ThreadPoolExecutor\n## 随记\n>* 当阻塞队列和核心线程都满了之后，如果还有线程，将直接优先处理刚来的线程而不是处理阻塞队列里面的线程\n### 参数\n```Java\n// 核心线程\n>int corePoolSize, \n>- - -\n// 最大线程数量\n>int maximumPoolSize,\n>- - -\n// 存活时间及其单位\n>long keepAliveTime,\n>TimeUnit unit,\n>- - -\n//阻塞队列 : 线程排队用的\n>BlockingQueue<Runnable> workQueue,\n>- - -\n//线程工厂：用于创建线程\n>ThreadFactory threadFactory,\n>- - -\n//拒绝策略 : 该线程池无法为其他线程提供服务了\n>RejectedExecutionHandler handler\n```\n## Executors\n>阿里开发规范已经不支持使用Executors了，而使用ThreadPoolExecutor代替\n### 一池 N 线程\n```java\nExecutorService executorService = Executors.newFixedThreadPool(3);\n```\n### 一池一线程\n```java\nExecutorService executorService1 = Executors.newSingleThreadExecutor();\n```\n### 自动根据需要创建线程，可扩容，遇强则强\n```java\nExecutorService executorService2 = Executors.newCachedThreadPool();\n```\n\n### 四种拒绝策略\n>* AbortPolicy(默认):直接抛出Rejected的异常\n>* CallerRunsPolicy: 将任务回退到调用者\n>* DiscardOldestPolicy: 抛弃队列中等待最久的任务，然后将当前任务加入到队列中，尝试再次提交当前任务\n>* DiscardPlicy : 默默丢弃无法处理的任务，不予处理也不抛出任何异常，如果运行任务丢失，这将是最好的策略\n\n\n# 代码实战\n## 提交任务给线程池\n```java\n// 新建自己的线程类\nclass Mythread implements Callable<Integer> {\n\n    private CountDownLatch countDownLatch;\n\n    public Mythread(CountDownLatch countDownLatch) {\n        this.countDownLatch = countDownLatch;\n    }\n\n    @Override\n    public Integer call() throws Exception {\n        int nextInt = 0;\n        nextInt = new Random().nextInt(5);\n        countDownLatch.countDown();\n        return nextInt;\n    }\n}\n\n// 使用countDownLatch同步线程，将一个任务集丢给线程池让线程池全部执行完毕后获取其结果后统一在主线程处理\npublic class Combination {\n    public static void main(String[] args) {\n        // 3个线程计算后整合\n        CountDownLatch countDownLatch = new CountDownLatch(3);\n        // 创造任务集\n        List<FutureTask<Integer>> futureTasks = new ArrayList<>();\n        for (int i = 0; i < 3; i++) {\n            FutureTask<Integer> integerFutureTask = new FutureTask<Integer>(new Mythread(countDownLatch));\n            futureTasks.add(integerFutureTask);\n        }\n        // 创造线程池\n        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(3, 4, 30, TimeUnit.SECONDS, new ArrayBlockingQueue<>(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy());\n        // 将任务添加进线程池\n        futureTasks.forEach(threadPool::submit);\n        // 不再接收新任务\n        threadPool.shutdown();\n        try {\n            // 等待线程池所有线程执行完所有任务\n            countDownLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        int sum = 0;\n\n        for (int i = 0;i<futureTasks.size();i++){\n            try {\n                System.out.println(\"子线程生成的随机数：\"+futureTasks.get(i).get());\n                sum += futureTasks.get(i).get();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"随机数总数为：\"+sum);\n    }\n}\n```\n\n","categories":["JavaStudy"],"tags":["JUC"]},{"title":"Redis","url":"/posts/27273/","content":"> 介绍了关于Redis的相关内容\n<!--more-->\n# 依赖引入\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n```\n# yml 配置\n```yml\n# 使用的数据库（0-15），默认为0\nspring:\n    redis:\n    lettuce:\n    # 对连接池的相关配置\n      pool:\n        # 最大连接数(使用负数表示无限制)\n        max-active: 8\n        # 最大阻塞等待时间(使用负数表示无限制)\n        max-wait: -1\n        # 最大空闲连接\n        max-idle: 8\n        # 最小空闲连接数\n        min-idle: 0\n    database: 0\n    host: 120.48.77.232\n    port: 6379\n    password: redis\n    # 6s后连接超时\n    timeout: 6000\n```\n\n# Jedis和Lettuce的区别\n>* jedis和Lettuce都是Redis的客户端，它们都可以连接Redis服务器，但是在SpringBoot2.0之后默认都是使用的Lettuce这个客户端连接Redis服务器。因为当使用Jedis客户端连接Redis服务器的时候，每个线程都要拿自己创建的Jedis实例去连接Redis客户端，当有很多个线程的时候，不仅开销大需要反复的创建关闭一个Jedis连接，而且也是线程不安全的，一个线程通过Jedis实例更改Redis服务器中的数据之后会影响另一个线程；\n\n>* 但是如果使用Lettuce这个客户端连接Redis服务器的时候，就不会出现上面的情况，Lettuce底层使用的是Netty，当有多个线程都需要连接Redis服务器的时候，可以保证只创建一个Lettuce连接，使所有的线程共享这一个Lettuce连接，这样可以减少创建关闭一个Lettuce连接时候的开销；而且这种方式也是线程安全的，不会出现一个线程通过Lettuce更改Redis服务器中的数据之后而影响另一个线程的情况；\n\n\n\n# 缓存注解\n```java\n@CacheConfig\n是一个类级别的注解，允许共享缓存的名称。\n一个类可能会有多个缓存操作而这些缓存操作可能是重复的，这时候可以使用@CacheConfig.\n```\n>- - -\n```java\n@Cacheable\n* 代表从缓存中查询指定的key，如果有，从缓存中取，不再执行方法。\n* 如果没有则执行方法，并且将方法的返回值和指定的key关联起来，放入到缓存中。\n\n主要参数：\n* value : 缓存的名称，在spring配置中定义，必须指定至少一个。\n* key: 缓存的key，可以为空，如果指定要按照spel表达式编写，如果不指定，则缺省按照方法的所有参数进行组合。\n* condition: 缓存的条件，可以为空，使用spek编写，返回true或false,只有为true使才进行缓存。\n\nExample:\n@Cacheable(value=\"thisredis\", key=\"'users_'+#id\")\npublic User findUser(Integer id) {}\n```\n>- - -\n>如果在类上配置了@CacheConfig,那么此时@Cacheable中的value就会取代@CacheConfig中cacheNames。  \n>如果在类上配置了@CacheConfig(cacheNames = \" \"),在该类下的@Cacheable中可以不用配置value。\n>- - -\n```java\n@CacheEvict\n标记在方法上，方法执行完毕之后根据条件或key删除对应的缓存。\n\nExample:\n@CacheEvict(value=\"thisredis\",   key=\"'users_'+#id\",condition=\"#id!=1\")\npublic void delUser(Integer id) {}\n\n主要参数：\nallEntries : 布尔类型 表示是否需要清除缓存中的所有元素。\nkey: 需要删除的缓存的key\n\n当我们在更新数据库的数据时，要使用@CacheEvict，需要把redis的缓存清空，否则查询的数据就是redis缓存中的数据，这样就会导致数据库和缓存数据不一致的问题。（页面不能及时的同步更新后的数据）。\n\n加上@CacehEvict 就会在查询数据时发现数据时最新的，与数据库保持一致。\n```\n\n# 模板对象序列化\n> 如果不自定义序列化，则调用redisTemplate.keys(\"*\")是无法获取到键的  \n> 更无法使用redisTemplate.keys(prefix+\"*\")来获取某个前缀下的所有key值了\n```java\n    @Resource\n    private RedisConnectionFactory redisConnectionFactory;\n\n     /**\n     * 自定义Key为String类型Value为Object类型的Redis操作模板\n     * 定义redis用到的redisTemplate对象序列化\n     */\n    @Bean(name = \"redisTemplate\")\n    public RedisTemplate<String, Object> redisTemplate(){\n        RedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();\n        redisTemplate.setConnectionFactory(redisConnectionFactory);\n        // key采用String的序列化方式\n        redisTemplate.setKeySerializer(new StringRedisSerializer());\n        // hash的key也采用String的序列化方式\n        redisTemplate.setHashKeySerializer(new StringRedisSerializer());\n        return redisTemplate;\n    }\n```\n\n# 云服务器上启动Redis\n## 启动\n```sh\nnohup redis-server &\nps -ef|grep redis  #查看进程\nnetstat -antpl|grep redis #查看端口\nredis-cli -h ip -p port ping #命令查看\n```\n## 动态参数启动\n```sh\nnohup redis-serve --port 6380 & #启动，监听6380端口\n```\n","categories":["TechStack"],"tags":["Redis"]},{"title":"日常随笔","url":"/posts/10026/","content":">日常学习的一个随笔\n<!--more-->\n# 获取request对象\n```java\n ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\n```\n# 产生随机数\n```java\n System.out.println((int) (Math.random()*3));\n System.out.println(new Random().nextInt(20));\n```\n\n# 除法运算\n```java\n  // 提前将int转换问BigDecimal来计算\n    int a = 3;\n    int b = 4;\n    BigDecimal decimalA = new BigDecimal(a);\n    BigDecimal decimalB = new BigDecimal(b);\n    BigDecimal divide = decimalA.divide(decimalB, 2, BigDecimal.ROUND_HALF_UP);\n    System.out.println(divide);\n\n```","categories":["Accumulate"],"tags":["随笔"]},{"title":"VersionController","url":"/posts/8310/","content":">总结了关于Spring全家桶以及Maven依赖的版本后缀意义，以及依赖关系\n>为了预防版本冲突或者版本不一致所导致的BUG\n<!--more-->\n\n# Maven版本后缀\n>* SNAPSHOT(快照版本Snapshot)\n>* RELEASE(发布版本release)\n>* Alpha：内测版，BUG 多，开发人员开发过程中使用，希腊字母α，第一，指最初版 \n>* Beta：早期版本，有缺陷，无大 BUG，可能加入新功能，进一步开发完善。\n>* Gamma: 经 beta 版，完善修改，成为正式发布的候选版本（Release Candidate）\n>* RC：(Release Candidate)：候选版本，几乎就是正式版了，一般需要 ASF 投票通过后，才会形成正式版本。\n>* GA：（Ggeneral Availability）：发行稳定版，官方推荐使用此版本。\n>* R，RELEASE：正式版，等价于 GA。\n>- - -\n>**其他版本**  \n>Alpha：内部测试版  \nBeta：外部测试版  \nBuild：修正版  \nCorporation 或 Enterprise：企业版  \nDelux：豪华版  \nDEMO：演示版，有功能限制  \nFree：免费版  \nFull：完全版  \nFinal：正式版  \nPro(professional)：专业版  \nPlus：加强版  \nRetail：零售版  \nRelease：发行版，有时间限制  \nShareware：共享版，虽然不会要求注册但是一般也有功能限制  \nSR：修正版  \nTrial：试用版（一般有时间或者功能限制）  \n\n# SpringCloudAlibaba 与 SpringCloud 与 Springboot 的对应关系\n>![alt](http://xtzl.wentexl.cn/%E4%B8%BB%E7%89%88%E6%9C%AC.png)\n\n# SpringCloud的组件\n>![alt](http://xtzl.wentexl.cn/Cloud%E7%BB%84%E4%BB%B6.png)","categories":["Accumulate"],"tags":["version"]},{"title":"Swagger2","url":"/posts/35285/","content":"\n> 描述了关于Swagger的简介和简单使用\n<!--more-->\n# 地址：\n>http://服务器ip:端口/swagger-ui.html\n# 什么是swagger2\n>编写和维护接口文档是每个程序员的职责，根据Swagger2可以快速帮助我们编写最新的API接口文档，再也不用担心开会前仍忙于整理各种资料了，间接提升了团队开发的沟通效率。\n# 常用注解\n>* @Api：修饰整个类，描述Controller的作用\n>* @ApiOperation：描述一个类的一个方法，或者说一个接口\n>* @ApiParam：单个参数描述\n>* @ApiModel：用对象来接收参数\n>* @ApiModelProperty：用对象接收参数时，描述对象的一个字段\n>* @ApiImplicitParam：一个请求参数\n>* @ApiImplicitParams：多个请求参数\n# 具体使用\n```java\n// 标注在类上\n@Api(tags = \"ES接口模块\")\n\n// 标注在接口上\n@ApiOperation(value = \"搜索接口\",notes = \"至少传入三个参数\")\n@ApiImplicitParams({\n        @ApiImplicitParam(name = \"keyword\",value = \"搜索关键词\"),\n        @ApiImplicitParam(name = \"indexPage\",value = \"页码\" ),\n        @ApiImplicitParam(name = \"pageSize\",value = \"每页显示的条数\")\n})\n```\n\n\n\n\n\n\n\n\n# 依赖\n```xml\n  <!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui -->\n <dependency>\n      <groupId>io.springfox</groupId>\n      <artifactId>springfox-swagger-ui</artifactId>\n      <version>2.9.2</version>\n  </dependency>\n  <!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 -->\n  <dependency>\n      <groupId>io.springfox</groupId>\n      <artifactId>springfox-swagger2</artifactId>\n      <version>2.9.2</version>\n      <scope>compile</scope>\n  </dependency>\n\n```","categories":["TechStack"],"tags":["Swagger2"]},{"title":"JSTL 表达式","url":"/posts/9859/","content":"<!--more-->\n# JSTL\n##\t1. 概念：JavaServer Pages Tag Library  JSP标准标签库\n\t\t* 是由Apache组织提供的开源的免费的jsp标签\t\t<标签>\n\n##\t2. 作用：用于简化和替换jsp页面上的java代码\n\n##\t3. 使用步骤：\n\t\t1. 导入jstl相关jar包\n\t\t2. 引入标签库：taglib指令：  <%@ taglib %>\n\t\t3. 使用标签\n\n##\t4. 常用的JSTL标签\n\t\t1. if:相当于java代码的if语句\n\t\t\t1. 属性：\n\t            * test 必须属性，接受boolean表达式\n\t                * 如果表达式为true，则显示if标签体内容，如果为false，则不显示标签体内容\n\t                * 一般情况下，test属性值会结合el表达式一起使用\n       \t\t 2. 注意：\n\t       \t\t * c:if标签没有else情况，想要else情况，则可以在定义一个c:if标签\n\t\t2. choose:相当于java代码的switch语句\n\t\t\t1. 使用choose标签声明         \t\t\t相当于switch声明\n            2. 使用when标签做判断         \t\t\t相当于case\n            3. 使用otherwise标签做其他情况的声明    \t相当于default\n\n\t\t3. foreach:相当于java代码的for语句\n\n##\t5. 练习：\n\t\t* 需求：在request域中有一个存有User对象的List集合。需要使用jstl+el将list集合数据展示到jsp页面的表格table中\n\n\n\n\n\n# 三层架构：软件设计架构\n##\t1. 界面层(表示层)：用户看的得界面。用户可以通过界面上的组件和服务器进行交互\n##\t2. 业务逻辑层：处理业务逻辑的。\n##\t3. 数据访问层：操作数据存储文件。","categories":["JavaStudy"],"tags":["JSYL表达式"]},{"title":"EL 表达式","url":"/posts/5361/","content":">总结了关于EL表达式的相关知识\n<!--more-->\n>EL 表达式\n\n#\t1. 概念：Expression Language 表达式语言\n#\t2. 作用：替换和简化jsp页面中java代码的编写\n#\t3. 语法：${表达式}\n#\t4. 注意:\n>\tjsp默认支持el表达式的。如果要忽略el表达式\n##\t1. 设置jsp中page指令中：isELIgnored=\"true\" 忽略当前jsp页面中所有的el表达式\n##\t2. \\${表达式} ：忽略当前这个el表达式\n\n\n#\t5. 使用：\n##\t\t1. 运算：\n\t\t\t* 运算符：\n\t\t\t\t1. 算数运算符： + - * /(div) %(mod)\n\t\t\t\t2. 比较运算符： > < >= <= == !=\n\t\t\t\t3. 逻辑运算符： &&(and) ||(or) !(not)\n\t\t\t\t4. 空运算符： empty\n\t\t\t\t\t* 功能：用于判断字符串、集合、数组对象是否为null或者长度是否为0\n\t\t\t\t\t* ${empty list}:判断字符串、集合、数组对象是否为null或者长度为0\n\t\t\t\t\t* ${not empty str}:表示判断字符串、集合、数组对象是否不为null 并且 长度>0\n##\t\t2. 获取值\n\t\t\t1. el表达式只能从域对象中获取值\n\t\t\t2. 语法：\n###\t\t\t1. ${域名称.键名}：从指定域中获取指定键的值\n\t\t\t\t\t* 域名称：\n\t\t\t\t\t\t1. pageScope\t\t--> pageContext\n\t\t\t\t\t\t2. requestScope \t--> request\n\t\t\t\t\t\t3. sessionScope \t--> session\n\t\t\t\t\t\t4. applicationScope --> application（ServletContext）\n\t\t\t\t\t* 举例：在request域中存储了name=张三\n\t\t\t\t\t* 获取：${requestScope.name}\n\n###\t\t\t\t2. ${键名}：表示依次从最小的域中查找是否有该键对应的值，直到找到为止。\n\n\n\n##\t\t\t\t3. 获取对象、List集合、Map集合的值\n\t\t\t\t\t1. 对象：${域名称.键名.属性名}\n\t\t\t\t\t\t* 本质上会去调用对象的getter方法\n\n\t\t\t\t\t2. List集合：${域名称.键名[索引]}\n\n\t\t\t\t\t3. Map集合：\n\t\t\t\t\t\t* ${域名称.键名.key名称}\n\t\t\t\t\t\t* ${域名称.键名[\"key名称\"]}\n\n\n##\t\t3. 隐式对象：\n\t\t\t* el表达式中有11个隐式对象\n\t\t\t* pageContext：\n\t\t\t\t* 获取jsp其他八个内置对象\n\t\t\t\t\t* ${pageContext.request.contextPath}：动态获取虚拟目录","categories":["JavaStudy"],"tags":["EL表达式"]},{"title":"SpringSecurity-Web 权限","url":"/posts/21484/","content":"> 总结了关于SpringSecurity的Web权限控制方面的知识点\n<!--more-->\n>* 登录接口/login如果是GET方式，则表示访问登录页面，如果是POST方式，则表示提交表单，执行登录逻辑\n>* 默认SpringSecurity的过滤器链的优先级高于自定义的过滤器的优先级\n>* Spring Security中的FilterInvocation ：通过Spring Security 封装，可以安全的拿到HttpServletRequest 和 HttpServletResponse对象\n\n\n# 设置登录的用户名和密码\n## 通过配置文件\n```yml\nspring:\n  security:\n    user:\n      name: Wente\n      password: wente695\n```\n\n## 自定义编写实现类\n> 从数据库中获取账户和密码，验证的时候是通过用户名获取到数据库的数据\n```java\n@Configuration\npublic class SecuriryConfig extends WebSecurityConfigurerAdapter {\n    @Resource\n    private UserDetailsService userDetailsService;\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.userDetailsService(userDetailsService).passwordEncoder(password());\n    }\n    @Bean\n    PasswordEncoder password(){return new BCryptPasswordEncoder();}\n}\n```\n**Service端**\n```java\n  @Override\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\n        List<GrantedAuthority> auths = AuthorityUtils.commaSeparatedStringToAuthorityList(\"role\");\n        return new User(\"mary\",new BCryptPasswordEncoder().encode(\"123\"),auths);\n    }\n```\n# 基于角色或者权限进行访问控制\n## hasAuthority 方法\n> 在配置类设置当前访问地址有哪些权限\n> 配置类中设置权限\n```java\n   .antMatchers(\"/test/index\").hasAnyAuthority(\"admins\")// 当前登录用户只有具有admins权限的才能访问这个路径\n```\n> 服务端配置权限\n```java\n  List<GrantedAuthority> auths = AuthorityUtils.commaSeparatedStringToAuthorityList(\"admins\");\n```\n## hasAnyAuthority方法\n```java\n   .antMatchers(\"/test/index\").hasAnyAuthority(\"admins,mannager\")// 当前登录用户只有具有admins,或者mannager的都可以\n```\n## hasRole方法\n> 但是在服务类里面添加角色权限的时候，必须要加一个ROLE_前缀\n>hasanyRole方法在配置类中多个角色用逗号隔开\n```java\n .antMatchers(\"/test/index\").hasRole(\"sale\") // 设置什么角色可以访问\n```\n>- - -\n```java\n  List<GrantedAuthority> auths = AuthorityUtils.commaSeparatedStringToAuthorityList(\"admins,ROLE_sale\");\n```\n>- - -\n\n# 基于注解配置SpringSecurity\n## 设置权限\n> 开启注解配置Security方式\n```java\n// prePostEnabled是表示支持事后验证的方式\n@EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true)\n```\n>接口类\n```java\n//@Secured({\"ROLE_sale\",\"ROLE_mannager\"})\n@PreAuthorize(\"hasAnyAuthority('admins')\")\n//@PostAuthorize(\"hasAnyAuthority('admins')\") // 在方法执行之后再做权限验证\n    public String update(){\n        return \"hello updata\";\n    }\n```\n## 过滤注解\n```java\n@PostFilter // 方法对返回数据进行过滤\n@PreFillter // 对传入方法的数据进行过滤\n```\n> 参数使用\n```java\n// 表示只返回的数据对象中的username是admin的对象\n@PostFilter(\"filterObject.username == 'admin'\")\n// 表示只传入的数据对象中的username属性是admin的对象\n@PreFilter(\"filterObject.username == 'admin'\")\n```\n# 用户注销\n> href的/logout是自带的，不需要自己去编写\n> 登出后再去访问需要登录的方法的请求就会被拦截，自动跳到登陆页面去\n ```xml\n  <a href=\"/logout\">退出</a>\n ```\n\n# 登录逻辑流程图\n> <img src = \"http://xtzl.wentexl.cn/login.png\">\n\n# 鉴权逻辑流程图\n> <img src = \"http://xtzl.wentexl.cn/auth.png\">\n","categories":["SpringSecurity"],"tags":[]},{"title":"boot_Security.md","url":"/posts/29525/","content":"> 主要是针对于SpringSecurity进行总结,主要采用的是SpringBoot + SpringSecurity\n<!--more-->\n# 核心要点\n>* 引入依赖之后访问方法都要先登录，登录用户名默认是user，密码在控制台\n\n# 依赖引入\n```xml\n   <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-security</artifactId>\n    </dependency>\n```\n# 两个重要接口：\n##  UserDetailsServic 接口: 查询数据库用户名和密码的过程\n* 创建类继承UsernamePasswordAuthenticationFilter\n* 创建类实现UserDetailsService,编写查询数据过程，返回User对象，这个User对象是安全框架提供对象。\n## User对象的两种构造\n### 简单构造\n只需要传入username，password，authoritities即可\n### 完全构造\n除了上面三个参数，还需要如下几个\n* isAccountNonExpired() // 用户是否过期\n* isAccountNonLocked() // 用户是否被锁定\n* isCredentialsNonExpired() // 用户密码是否过期\n* isEnabled() // 用户是否被禁用\n\n## PasswordEncoder 接口：数据加密接口，用于返回User对象里面密码加密\n\n# 配置类\n\n\n","categories":["SpringSecurity"],"tags":["SpringSecurity"]},{"title":"SpringAop","url":"/posts/21566/","content":">介绍了关于SpringBoot的相关知识点\n<!--more-->\n# 注意点\n- 环绕通知的返回类型必须和被代理方法的返回类型相同\n- 注解作为pointcut且标注在类上，要使用@within来指定，如果标注在方法上就使用@annotion来指定\n- 从Spring5.7之后，通知的顺序发生了改变\n# 通知\n## 执行顺序\n>环绕通知 -> 前置通知 -> 方法逻辑 -> 返回通知(无异常) -> 后置通知 -> 环绕通知\n><img src = \"http://xtzl.wentexl.cn/%E9%80%9A%E7%9F%A5%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F.png\">\n## 注解\n>* 环绕通知 @Around(\"testCut()\")\n>* 前置通知 @Before(\"testCut()\")\n>* 返回通知 @AfterReturning(value = \"testCut()\", returning = \"result\")\n>* 异常通知 @AfterThrowing(value = \"testCut()\", throwing = \"e\")\n>* 后置通知 @After(\"testCut()\")\n\n# 优先级\n> 环绕通知可以决定切点方法内的业务逻辑是否执行  \n> 如果选择执行切点的话，则使用joinPoint.proceed();  \n> 环绕通知的返回值就是最终返回给前端的返回值  \n> 即便执行了业务逻辑代码，若配置了环绕通知，返回给前端的仍然是环绕通知的return\n\n# 代码演示\n## 自定义注解\n```java\n// 自定义注解\n//@Documented注解，是被用来指定自定义注解是否能随着被定义的java文件生成到JavaDoc文档当中。\n@Documented\n@Retention(RetentionPolicy.RUNTIME) // 在运行时可被虚拟机保留,通过反射可以读取到它\n@Target(ElementType.METHOD) // 限定了只能使用在方法上面\npublic @interface AspectTest {\n    // 里面可以放一些成属性\n}\n```\n## 自定义切面\n```java\n@Aspect\n@Component\npublic class AspectTest {\n\n    /**\n     * 这里的路径填自定义注解的全路径\n     */\n    @Pointcut(\"@annotation(campus.epidemic.prevention.aspect.Annotations.AspectTest)\")\n    public void testCut() {\n\n    }\n\n    // 前置通知\n    @Before(\"testCut()\")\n    public void cutProcess(JoinPoint joinPoint) {\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n        Method method = signature.getMethod();\n        System.out.println(\"注解方式AOP开始拦截, 当前拦截的方法名: \" + method.getName());\n    }\n\n    // 环绕通知\n    @Around(\"testCut()\")\n    public Object testCutAround(ProceedingJoinPoint joinPoint) throws Throwable {\n        System.out.println(\"注解方式AOP拦截开始进入环绕通知.......\");\n        // 这里的proceed是指的指定切点(接口方法)的返回值\n        Object proceed = joinPoint.proceed();\n        System.out.println(\"准备退出环绕......\");\n        return proceed;\n    }\n\n    /**\n     * returning属性指定连接点方法返回的结果放置在result变量中\n     * @param joinPoint 连接点\n     * @param result    返回结果\n     */\n    // 返回通知：必须无异常的时候才能执行\n    @AfterReturning(value = \"testCut()\", returning = \"result\")\n    public void afterReturn(JoinPoint joinPoint, Object result) {\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n        Method method = signature.getMethod();\n        System.out.println(\"注解方式AOP拦截的方法执行成功, 进入返回通知拦截, 方法名为: \" + method.getName() + \", 返回结果为: \" + result.toString());\n    }\n\n\n    // 异常通知： 有异常的时候抛出\n    @AfterThrowing(value = \"testCut()\", throwing = \"e\")\n    public void afterThrow(JoinPoint joinPoint, Exception e) {\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n        Method method = signature.getMethod();\n        System.out.println(\"注解方式AOP进入方法异常拦截, 方法名为: \" + method.getName() + \", 异常信息为: \" + e.getMessage());\n    }\n\n    //后置通知:无论是否有异常都必须执行\n    @After(\"testCut()\")\n    public void after(JoinPoint joinPoint) {\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n        // 方法名\n        Method method = signature.getMethod();\n        System.out.println(\"注解方式AOP执行的方法 :\" + method.getName() + \" 执行完了\");\n    }\n\n}\n```\n\n## AOP实战切面\n```java\n/**\n * @author Wente\n * @date 2023/8/11\n * 结果封装AOP类\n **/\n@Aspect\n@Component\n@Order(1)\n@Slf4j\npublic class ResultWrappingAspect {\n\n    /**\n     * 指定注解标注的类才需要进行Result的封装\n     */\n    @Pointcut(\"@within(recruit.toc.common.annotions.ResultWrapper)\")\n    public void controller() {\n    }\n\n    /**\n     * 环绕通知\n     */\n    @Around(value = \"controller()\")\n    public String aroundAdvice(ProceedingJoinPoint joinPoint) {\n            log.info(\"执行了环绕通知\");\n            Result<Object> resultBack = new Result<>();\n        try {\n            String resultJson = (String)joinPoint.proceed();\n            Object parse = JSONObject.parse(resultJson);\n            resultBack.setCode(200);\n            resultBack.setMessage(\"http访问成功\");\n            resultBack.setData(parse);\n        } catch (Throwable e) {\n            log.info(\"环绕通知执行原方法出现异常\");\n            e.printStackTrace();\n        }\n        return JSON.toJSONString(resultBack);\n    }\n    /**\n     * 返回通知：日志记录\n     */\n    @AfterReturning(pointcut = \"controller()\",returning = \"result\")\n    public void afterReturningAdvice(JoinPoint joinPoint,Object result){\n        log.info(\"开始执行返回通知...\");\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n        String name = signature.getMethod().getName();\n        log.info(\"方法名为：\"+name);\n        log.info(\"返回类型为: \"+signature.getReturnType().toString());\n        log.info(\"返回数据为： \"+JSON.toJSONString(result));\n        log.info(\"返回通知结束...\");\n    }\n\n    /**\n     * 异常通知\n     * @param ex 原方法抛出的异常\n     */\n    @AfterThrowing(pointcut = \"controller()\", throwing = \"ex\")\n    public String afterThrowing(Exception ex) {\n        log.info(\"执行了异常通知\");\n        Result<Object> resultBack = new Result<>();\n        resultBack.setCode(500);\n        resultBack.setMessage(ex.getMessage());\n        resultBack.setData(ex.getCause());\n        return JSON.toJSONString(resultBack);\n    }\n\n}\n\n```","categories":["SpringBoot"],"tags":["SpringAop"]},{"title":"Transaction","url":"/posts/43132/","content":"> 该文主要介绍了关于SpringBoot的事务管理的相关知识点\n<!--more-->\n# 核心\n>* Spring并不直接管理事务，而是通过各种事务管理器来调用特定平台的事务实现\n>* spring统一管理事务，把不同的数据库访问技术的事务处理统一起来\n>* 已经commit的事务是不能rollback的\n\n\n# 常用的事务管理器\n>* DataSourceTransactionManager：用于JDBC的持久化支持，也可用于IBATIS\n>* HibernateTransactionManager：用于Hibernate3的持久化支持\n>* JpaTransactionManager：用于Java持久化API的持久化支持\n>* JtaTransactionManager：主要用于分布式事务的支持\n\n# 事务的传播行为ProPagation\n>**事务传播行为是指多个拥有事务的方法在嵌套调用时的事务控制方式**  \n>优秀博文:http://t.csdn.cn/TgggY  \n> **重点：**\n>* PROPAGATION_REQUIRED : 表示当前方法必须运行在事务中，若当前存在事务，则在原有事务中运行，否则创建一个新的事务。\n>- - -\n>* PROPAGATION_REQUIRES_NEW :  新建事务，如果当前存在事务，把当前事务挂起。\n>- - -\n>* PROPAGATION_SUPPORTS : 如果当前有事务，则使用事务，如果当前没有事务，就以非事务方式执行\n>- - -\n>* Propagation.NOT_SUPPORTED :  以非事务方式执行操作，如果当前存在事务，就把当前事务挂起\n>- - -\n>- - -\n> **次要:**\n>* PROPAGATION_MANDATORY ：表示该方法必须在事务中运行，若当前事务不存在则抛异常。举例来说，一个service方法调用了两个dao方法，那么在执行其中的一个dao方法时，都要求已经启动了事务，否则需要抛异常。\n>- - -\n>* PROPAGATION_NESTED :表示若当前已存在一个事务，那么该方法将在嵌套事务中运行。嵌套事务可以独立于当前事务进行提交或回滚，若当前事务不存在，则该传播行为与PROPAGATION_REQUIRED一样。举例来说，一个service方法中调用了某dao方法，并且根据该dao方法执行的成功或失败区分了两套处理逻辑，这时候若dao执行失败，它只要保证不对数据库数据有任何影响（通过rollback）就可以了，不需要回滚整个service方法，故这个dao方法需要在嵌套事务中运行。\n>- - -\n>* PROPAGATION_NEVER : 表示当前方法不应该运行在事务中，若当前已经有一个事务在运行，则抛异常。这种适用于在某些dao操作中，它要求之前的事务已经结束，而它本身的操作结果不会受到其他dao操作结果的影响（比如被其他操作所rollback）。\n>- - -\n>* PROPAGATION_NOT_SUPPORTED : 表示当前方法不应该运行在事务中，若当前已经有一个事务在运行，则将其挂起。\n\n# 事务并发可能导致的错误\n>* 脏读：某事务读取了其他事务未提交的数据后，其他事务又将其数据回滚，导致该事务使用了无效的数据。\n>- - -\n>* 不可重复读：某事务执行两次相同的查询操作，但是由于在这两次操作中间存在其他事务更新了数据，从而导致两次查询的结果不一致。\n>- - -\n>* 幻读 ：事务 A 根据条件查询得到了 N 条数据，但此时事务 B 删除或者增加了 M 条符合事务 A 查询条件的数据，这样当事务 A 再次进行查询的时候真实的数据集已经发生了变化，但是A却查询不出来这种变化，因此产生了幻读。\n>- - -\n\n# Spring提供的事务隔离isolation \n>若通过相关互斥机制保证事务的绝对隔离，则会很大程度影响并发的性能，最差情况就相当于事务是串行地执行。为了尽可能避免这些问题、权衡性能以及提高事务隔离的灵活性，Spring定义了五种隔离级别，以允许应用程序自己决定所能接受的、被其他事务所影响的程度。\n>- - -\n>* ISOLATION_DEFAULT : 使用底层数据库默认的隔离级别。\n>- - -\n>* ISOLATION_READ_UNCOMMITTED : 允许读取未提交的数据，这可能导致脏读、不可重复读和幻读。\n>- - -\n>* ISOLATION_READ_COMMITTED ：允许读取已提交的数据，这可以避免脏读，但是还是可能导致不可重复读和幻读。\n>- - -\n>* ISOLATION_REPEATABLE_READ : 对同一字段的多次读取结果是一致的，除非由本事务自己更新，这可以避免不可重复读和脏读，但是还是可能导致幻读。\n>- - -\n>* ISOLATION_SERIALIZABLE：完全按照ACID所要求的，可以避免脏读、不可重复读和幻读。注意：这种事务隔离级别的效率最差，因为它经常需要将事务相关的表进行加锁，锁粒度大。\n>- - -\n>![事务](http://xtzl.wentexl.cn/%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E8%A7%84%E5%88%99.png)\n\n\n","categories":["SpringBoot"],"tags":["Transaction"]},{"title":"Seata","url":"/posts/63021/","content":"> 介绍了分布式中关于Seata分布式事务的知识\n<!--more-->\n# Seata重点\n>* 必须先启动Nacos后启动Seata\n\n\n# Seata介绍\n>* 1 + 3 的组件模型\n>* 分布式事务处理过程的-ID+三组件模型\n>* Transaction ID XID : 全局唯一的事务ID\n\n# Seata术语(三组件)\n## TC (Transaction Coordinator) - 事务协调者\n>维护全局和分支事务的状态，驱动全局事务提交或回滚。\n\n## TM (Transaction Manager) - 事务管理器\n>定义全局事务的范围：开始全局事务、提交或回滚全局事务。\n\n## RM (Resource Manager) - 资源管理器\n>管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回\n滚。\n\n![seata](http://xtzl.wentexl.cn/Seata.png)\n>- - -\n\n# BASE理论 \n>BASE理论是对CAP的一种解决思路，包含三个思想：\n>- - -\n>* Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n>* Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。\n>* Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。\n>- - -\n>而分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论：\n>- - -\n>* AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。  \n>* CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态\n\n# 分布式事务解决方案\n>Seata提供了四种不同的分布式事务解决方案：\n>- - -\n>* XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入\n>* TCC模式：最终一致的分阶段事务模式，有业务侵入\n>* AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式\n>* SAGA模式：长事务模式，有业务侵入  \n\n**对比**\n![compare](http://xtzl.wentexl.cn/%E5%AF%B9%E6%AF%94.png)","categories":["SpringCloudAlibaba"],"tags":["Seata"]},{"title":"Nacos","url":"/posts/33695/","content":">总结了关于Nacos注册、配置的相关知识\n<!--more-->\n# Nacos\n>* Nacos 就是注册中心 + 配置中心的组合\n>* 等价于 Nacos = Eureka + Config + Bus\n>* AP架构和CP架构都支持，可切换（C: 一致性 A：可用性  P:分区容错性）\n>* startup.cmd -m standalone  单机启动命令\n\n# 依赖引入\n> 父工程pom：\n```xml\n     <!--spring cloud alibaba 2.1.0.RELEASE-->\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.1.0.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n\n```\n> 子工程pom：\n```xml\n        <!--SpringCloud ailibaba nacos -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n```\n\n# Nacos注册中心\n## 服务端Yml配置\n```yml\nserver:\n  port: 9002\n\nspring:\n  application:\n    name: nacos-payment-provider\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 #配置Nacos地址\n        # 换成nginx的1111端口，做集群\n        #server-addr: 192.168.111.144:1111\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: '*'\n\n```\n## 客户端Yml配置\n```yml\nserver:\n  port: 83\n\n\nspring:\n  application:\n    name: nacos-order-consumer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n\n\nservice-url:\n  nacos-user-service: http://nacos-payment-provider\n```\n\n## 客户端Controller层\n> 由于在配置yml的时候，已经在service-url.nacos-user-service中配置过了，所以直接可用@Value注解进行引入\n```java\n  @Value(\"${service-url.nacos-user-service}\")\n    private String serverURL;\n```\n# Nacos 配置中心\n## 核心\n>* Nacos的Config配置自带动态刷新\n>* DataId必须按官方给定的格式命名\n## 新增依赖\n```xml\n     <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n        </dependency>\n\n```\n## yml配置\n>**bootstrap的优先级是高于application的**\n\n> bootstrap.yml\n```yml\nserver:\n  port: 3377\n\nspring:\n  application:\n    name: nacos-config-client\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 #服务注册中心地址\n      config:\n        server-addr: localhost:8848 #配置中心地址\n        file-extension: yaml #指定yaml格式的配置\n```\n>application.yml\n```yml\nspring:\n  profiles:\n    active: dev\n```\n## 在Nacos端的配置文件名格式如下(设置DataId):\n>${spring.application.name}-${spring.profile.active}.${spring.cloud.nacos.config.file-extension}  \n> 例如: nacos-config-client-dev.yaml\n\n## 分组管理\n![分组](http://xtzl.wentexl.cn/%E5%88%86%E7%BB%84%E7%AE%A1%E7%90%86.png)\n>* yml中设置分组,意为选择DEV环境下的配置生效\n```yml\nconfig:\n    group: DEV_GROUP\n```\n>* 不同的组别可以存在DataId相同的配置\n## 命名空间NameSpace\n>* yml文件配置命名空间\n```yml\nconfig:\n    namespace: f2009b56-a85a-487a-afeb-0927aa03a199\n```\n# 切换Nacos的数据库\n>*  Nacos自带一个derby数据库，但是要统一使用mysql数据库\n>*  sql执行脚本在nacos的安装路径中conf目录下\n>* sql执行之后，需要修改conf下application.properties,(mysql8)修改如下\n```txt\nspring.datasource.platform=mysql\ndb.num=1\ndb.url.0=jdbc:mysql://127.0.0.1:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC\ndb.user.0=root\ndb.password.0=root\n```\n","categories":["SpringCloudAlibaba"],"tags":["Nacos"]},{"title":"Sentinel","url":"/posts/60668/","content":"> 总结了Sentinel服务降级、服务熔断的有关知识\n<!--more-->\n# 重点\n>* 实例重启后如果进入sentinel的web界面，则必须先调用一个任意的方法才能被检测到\n>* fallback管的是运行异常，blockHandler管的是配置违规\n>* 当fallback和blockHandler同时起效的时，优先起效的是blockHandler方法\n>* 自带负载均衡\n\n\n# 依赖引入\n```xml\n    <!--SpringCloud ailibaba nacos -->\n    <dependency>\n        <groupId>com.alibaba.cloud</groupId>\n        <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n    </dependency>\n    <!--SpringCloud ailibaba sentinel-datasource-nacos 后续sentinel做持久化用到-->\n    <dependency>\n        <groupId>com.alibaba.csp</groupId>\n        <artifactId>sentinel-datasource-nacos</artifactId>\n    </dependency>\n    <!--SpringCloud ailibaba sentinel -->\n    <dependency>\n        <groupId>com.alibaba.cloud</groupId>\n        <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n    </dependency>\n```\n# 服务端 yml 配置\n```yml\nserver:\n  port: 8401\n\nspring:\n  application:\n    name: cloudalibaba-sentinel-service\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 #Nacos服务注册中心地址\n    sentinel:\n      transport:\n        # 8080会监控8401查看是否健康\n        dashboard: localhost:8080 #配置Sentinel dashboard地址\n        # 默认是8719端口号,如果被占用了会自动+1\n        # 指定应用与Sentinel控制台交互的端口，应用本地会起一个该端口占用的HttpServer\n        port: 8719\n\n\n      datasource:\n        ds1:\n          nacos:\n            server-addr: localhost:8848\n            dataId: ${spring.application.name}\n            groupId: DEFAULT_GROUP\n            data-type: json\n            rule-type: flow\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: '*'\n\n```\n# 流控规则\n>* QPS: 每秒的请求数，一般指每秒查询率\n>* 单机阈值: 请求数的多少\n## PostMan测试\n![postman](http://xtzl.wentexl.cn/PostMan.png)\n\n## 流控效果\n### 预热\n>* ColdFactor冷加载因子默认是3\n>* 请求QPS从 threshold/3 开始，经预热时长之后，QPS才会逐渐达到指定QPS值\n>* 预热主要是为了保护系统\n### 快速失败\n>* 只要不满足流控规则，直接让该请求失败\n### 排队等等\n>* 只要每个请求的等待时间不超过设定的超时时间，则每个请求都排队等待响应\n>* 而处理的速度，根据流控规则的单机阈值来决定\n>* 其中超时时间的单位是ms\n>* 如果请求超时，则报错\n\n## 流控模式\n### 关联\n![connect](http://xtzl.wentexl.cn/%E5%85%B3%E8%81%94.png)\n### 直接\n>* 仅仅针对于一个方法而言\n\n# 降级与熔断策略\n>* 官网讲解\n![熔断](http://xtzl.wentexl.cn/%E5%AE%98%E7%BD%91%E7%86%94%E6%96%AD.png)\n\n## RT:慢调用比例\n>* 注意：Sentinel默认RT最大时间为4900毫秒，可通过-Dcsp.sentinel.statistic.max.rt=xxx修改  \n>* 慢调用比例 = 慢调用请求数/请求总数\n>* 在单位统计时长内，如果慢调用比例大于阈值，且请求数大于最小请求数值，则触发熔断\n>* 经过一个熔断时长后，进入探测恢复状态（HALF-OPEN）阶段，即接下来的一个请求响应时间小于rt(200ms),则熔断结束，否则会再次被熔断。\n>* 慢调用不是异常，如果异常的话是不会进行服务降级而是直接报错\n![慢比例](http://xtzl.wentexl.cn/%E6%85%A2%E6%AF%94%E4%BE%8B1.png)\n\n>- - -\n\n## 异常比例\n>* 当单位统计时长内，请求数目大于设置的最小请求数目（5），并且异常的比例大于阈值（0.07），则接下来的熔断时长（3s，时间窗口的值）内请求会自动被熔断。  \n>* 经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]。\n>![异常](http://xtzl.wentexl.cn/%E5%BC%82%E5%B8%B8%E6%AF%94%E4%BE%8B1.8.4.png)\n\n>- - -\n\n## 异常数\n>* 异常数一般都是按分钟统计的\n>* 单位统计时长内，异常数达到设定的异常数则进入服务熔断，调用服务降级的函数\n>* 服务熔断之后，经过一个熔断时长之后，才会进入探测恢复状态\n>![异常数](http://xtzl.wentexl.cn/%E5%BC%82%E5%B8%B8%E6%95%B01.8.4.png)\n\n\n# 热点监控\n>* 在web界面自定义热点规则，当请求违背了热点规则之后，则执行blocakHandler所指的的方法\n>* @SentinelResource 的value属性只要保持唯一性就好，一般与GetMapping的value保持一致\n>* 运行异常不属于热点监控的范围，热点监控只管是否违背热点规则，运行异常也就不会走blockHandler这个方法\n## Controller层\n```java\n    @GetMapping(\"/testHotKey\")\n    @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\")\n    public String testHotKey(@RequestParam(value = \"p1\", required = false) String p1,\n                             @RequestParam(value = \"p2\", required = false) String p2) {\n        int age = 10 / 0;\n        return \"------testHotKey\";\n    }\n    // 兜底的方法\n    public String deal_testHotKey(String p1, String p2, BlockException exception) {\n        //sentinel系统默认的提示：Blocked by Sentinel (flow limiting)\n        return \"------deal_testHotKey,o(╥﹏╥)o\";\n    }\n```\n## Web界面配置\n> * 该图表示监控携带第0个参数的请求，窗口时长内的请求数不能超过1次，资源名为@SentinelResource的Value值\n>* 参数例外项：当指定参数为一特定值的时候，阈值有所不同\n![热点规则](http://xtzl.wentexl.cn/%E5%8F%82%E6%95%B0%E4%BE%8B%E5%A4%96.png)\n\n\n\n# Sentinel 自定义限流处理逻辑\n>* 违反我们自己配置的流控规则才需要blockHandler\n>* 在配置流控规则的时候，资源标识最好只使用@SentinelResource注解的Value属性作为唯一标识\n## @SentinelResource\n>- - -\n>* (value = \"byResource\",blockHandler = \"handleException\")\n>* value是唯一标识，blockHandler是指定处理方法(兜底方法)的方法名\n>- - -\n>* (value = \"customerBlockHandler\",   \nblockHandlerClass = CustomerBlockHandler.class, blockHandler = \"handlerException2\")\n>* blockHandlerClass指定处理类，blockHandler指定类中的哪个方法\n>* 注意在写Handler类的方法的时候，所有方法都必须是static的，且handler类无须加入容器\n>- - -\n >* 其中属性exceptionsToIgnore = {IllegalArgumentException.class}，表示忽略IllegalArgumentException这个异常属性，但是这个忽略异常属性，仅仅指的是在Java层面，也就是fallback方法不响应该异常，但是Sentinel仍然会检测到该异常\n\n # Sentinele同样支持Open-feign\n >修改yml支持Open-feign\n ```yml\n # 激活Sentinel对Feign的支持\nfeign:\n  sentinel:\n    enabled: true\n ```\n >- - -\n ```java\n@FeignClient(value = \"nacos-payment-provider\", fallback = PaymentFallbackService.class)\n ```\n > 其中，service层分为接口+实现类，上面的注解标注在接口，fallback指向实现类\n\n# Sentinel持久化\n## 依赖引入\n```xml\n        <dependency>\n            <groupId>com.alibaba.csp</groupId>\n            <artifactId>sentinel-datasource-nacos</artifactId>\n        </dependency>\n```\n## YML配置\n> 将Sentinel配置进Nacos中\n```yml\nspring:\n  cloud:\n     sentinel: \n        datasource:\n          ds1:\n            nacos:\n              server-addr: localhost:8848\n              dataId: ${spring.application.name}\n              groupId: DEFAULT_GROUP\n              data-type: json\n              rule-type: flow\n```\n\n> 需要手动写进Nacos\n>* 在Nacos中需要新建一个配置文件s\n>* 配置文件名DataId就是Sentinel的实例服务名\n>* 配置文件的内容是Json格式\n```json\n[\n    {\n        \"resource\": \"/rateLimit/byUrl\",\n        \"limitApp\": \"default\",\n        \"grade\": 1,\n        \"count\": 1,\n        \"strategy\": 0,\n        \"controlBehavior\": 0,\n        \"clusterMode\": false\n    }\n]\n```\n**解释如下:**\n![json](http://xtzl.wentexl.cn/json.png)","categories":["SpringCloudAlibaba"],"tags":["Sentinel"]},{"title":"MQ-Notes","url":"/posts/44276/","content":"> 总结了关于消息中间件MQ 的知识点\n<!--more-->\n# 核心:四大天王\n>* RabbitMQ\n>* RocketMQ\n>* ActiveMQ\n>* Kafka\n\n# 引入依赖\n```xml\n        <!--添加消息总线RabbitMQ支持来实现广播-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-bus-amqp</artifactId>\n        </dependency>\n```\n# client和Config端都需要添加yml的MQ的相关支持\n```yml\n#rabbitmq相关配置\nrabbitmq:\n  host: localhost\n  port: 5672\n  username: guest\n  password: guest\n\n```\n# 只需要发送一次，则client端处处生效\n> **中心Config端 多增加如下MQ配置，include改为:bus-refresh**\n```yml\n##rabbitmq相关配置,暴露bus刷新配置的端点\nmanagement:\n  endpoints: #暴露bus刷新配置的端点\n    web:\n      exposure:\n        include: 'bus-refresh'\n\n```\n\n# 运维发送全体通知和精确通知\n> * 全体通知：  \n> localhost:3344/actuator/bus-refresh  \n> 其中，3344指的是中心Config端的端口号\n>- - -\n>* 精确通知：  \n>localhost:3344/actuator/bus-refresh/config-client:3366  \n>其中，config-client指的是config的服务名称，3366是实例的端口号\n> - - -\n\n> 以上是利用RabbitMQ来实现动态刷新Config的优化\n>- - -\n# SpringCloud Stream\n> **重点**  \n>* 凡是涉及到监控、刷新的，必须要引入actuator这个依赖\n>* 消费端不同的组可以存在重复消费\n>* 消费端同一个组不能存在重复消费\n>* 不做处理的默认每个接收的实例都是一个组\n>* 消费端group属性十分重要，因为这个属性既可以解决重复消费，又可以解决消息持久化\n>- - -\n> **核心设计思想**  \n>*  SpringCloud Stream是一个构建消息驱动微服务的框架，应用程序通过inputs或者 outputs来与SpringCloud Stream中的binder进行交互，我们可以通过配置来binding ，而 SpringCloud Stream 的binder负责与中间件交互\n>*  SpringCloud Stream由一个中间件中立的核组成，应用通过SpringCloud Stream插入的input(相当于消费者consumer，它是从队列中接收消息的)和output(相当于生产者producer，它是发送消息到队列中的)通道与外界交流\n>*  Binder是SpringCloud Stream的一个抽象概念，是应用与消息中间件之间的粘合剂，目前SpringCloud Stream实现了Kafka和RabbitMQ的binder通过binder，可以很方便的连接中间件，可以动态的改变消息的destinations（对应于 Kafka的topic，RabbitMQ的exchanges），这些都可以通过外部配置项来做到，甚至可以任意的改变中间件的类型但是不需要修改一行代码\n\n## 架构图1\n![alt](http://xtzl.wentexl.cn/%E7%BC%96%E7%A0%81API.png)\n## 架构图2\n![alt](http://xtzl.wentexl.cn/SCS%E6%9E%B6%E6%9E%84%E5%9B%BE2.png)\n\n## Stream的yml文件配置\n> **消息生产者(生产端)：**\n```yml\nserver:\n  port: 8801\n\nspring:\n  application:\n    name: cloud-stream-provider\n  cloud:\n    stream:\n      binders: # 在此处配置要绑定的rabbitmq的服务信息；\n        defaultRabbit: # 表示定义的名称，用于于binding整合\n          type: rabbit # 消息组件类型\n          environment: # 设置rabbitmq的相关的环境配置\n            spring:\n              rabbitmq:\n                host: localhost\n                port: 5672\n                username: guest\n                password: guest\n      bindings: # 服务的整合处理\n        output: # 这个名字是一个通道的名称\n          destination: studyExchange # 表示要使用的Exchange名称定义\n          content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain”\n          default-binder: defaultRabbit  # 设置要绑定的消息服务的具体设置\n\neureka:\n  client: # 客户端进行Eureka注册的配置\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n  instance:\n    lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒）\n    lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒）\n    instance-id: send-8802.com  # 在信息列表时显示主机名称\n    prefer-ip-address: true     # 访问的路径变为IP地址\n\n```\n>- - -\n> **消息接收者(消费端)**\n```yml\nserver:\n  port: 8803\n\nspring:\n  application:\n    name: cloud-stream-consumer\n  cloud:\n    stream:\n      binders: # 在此处配置要绑定的rabbitmq的服务信息；\n        defaultRabbit: # 表示定义的名称，用于于binding整合\n          type: rabbit # 消息组件类型\n          environment: # 设置rabbitmq的相关的环境配置\n            spring:\n              rabbitmq:\n                host: localhost\n                port: 5672\n                username: guest\n                password: guest\n      bindings: # 服务的整合处理\n        input: # 这个名字是一个通道的名称\n          destination: studyExchange # 表示要使用的Exchange名称定义\n          content-type: application/json # 设置消息类型，本次为对象json，如果是文本则设置“text/plain”\n          default-binder: defaultRabbit # 设置要绑定的消息服务的具体设置\n          group: atguiguA\n\neureka:\n  client: # 客户端进行Eureka注册的配置\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n  instance:\n    lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒）\n    lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒）\n    instance-id: receive-8803.com  # 在信息列表时显示主机名称\n    prefer-ip-address: true     # 访问的路径变为IP地址\n\n```\n\n## 业务层配置\n> **消息生产者(生产端)：**  \n> 仅仅是发送消息到消息队列而已\n> 其中关键注解是： @EnableBinding(Source.class)\n```java\n@RestController\npublic class SendMessageController\n{\n    @Resource\n    private IMessageProvider messageProvider;\n\n    @GetMapping(value = \"/sendMessage\")\n    public String sendMessage()\n    {\n        return messageProvider.send();\n    }\n\n}\n------------------------下面是Service层-------------------------------\n@EnableBinding(Source.class) //定义消息的推送管道\npublic class MessageProviderImpl implements IMessageProvider\n{\n    @Resource\n    private MessageChannel output; // 消息发送管道\n\n    @Override\n    public String send()\n    {\n        String serial = UUID.randomUUID().toString();\n        output.send(MessageBuilder.withPayload(serial).build());\n        System.out.println(\"*****serial: \"+serial);\n        return null;\n    }\n}\n```\n\n> **消息接收者(消费端)：**  \n> 从消息队列中取得信息\n> 其中关键注解是: @EnableBinding(Sink.class)\n```java\n@Component\n@EnableBinding(Sink.class)\npublic class ReceiveMessageListener {\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @StreamListener(Sink.INPUT)\n    public void input(Message<String> message) {\n        System.out.println(\"port:\" + serverPort + \"\\t接受：\" + message.getPayload());\n    }\n\n}\n```\n# 消息持久化\n> 消息持久化主要是依靠yml配置中binder下的input下的group属性，当停机之后如果消息队列中有消息在流通，配置了group属性的实例，重启之后仍然能够收到消息，如果没配置的话，将会错过消息","categories":["MessageQueue"],"tags":["MQ","SpringCloud-Stream"]},{"title":"Config","url":"/posts/8012/","content":"> 主要总结和介绍了Config配置组件的使用\n<!--more-->\n> 要测试的话，也要在Windows的host文件做修改：127.0.0.1 config-3344.com\n> 测试链接：http://config-3344.com:3344/main/config-dev.yml\n# 主启动类注解引入\n```java\n@EnableConfigServer\n```\n# 依赖引入\n```xml\n   <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-config-server</artifactId>\n        </dependency>\n```\n# 中心Config的yml 配置\n```yml\nserver:\n  port: 3344\n\nspring:\n  application:\n    name:  cloud-config-center #注册进Eureka服务器的微服务名\n  cloud:\n    config:\n      server:\n        git:\n          uri: https://gitee.com/mx0425/springcloud-config.git #GitHub上面的git仓库名字\n          ####搜索目录\n          search-paths:\n            - springcloud-config\n      ####读取分支\n      label: master\n\n#服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n\n```\n# Client端Config的yml配置\n```yml\nserver:\n  port: 3355\n\nspring:\n  application:\n    name: config-client\n  cloud:\n    #Config客户端配置\n    config:\n      label: main #分支名称\n      name: config #配置文件名称\n      profile: dev #读取后缀名称   上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml\n      uri: http://localhost:3344 #配置中心地址k\n\n#服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n```\n# Client端手动版动态刷新\n>**Controller层**\n```java\n类名上添加注解\n@RefreshScope\n```\n```yml\n# 暴露监控端点: 实现动态刷新用的\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n\n```\n>* **localhost:3355/actuator/refresh** \n>* 此时需要发一个如上的固定的post请求来刷新，这种方式只能针对单个的端口，下例就是3355这个端口进行刷新。\n>- - -\n>* 这样显然有**弊端**：假如有多个微服务客户端3355/3366/3377。。。。每一个都要手动去刷新岂不是很麻烦？？  \n>- - -\n>**优化**: 通过广播，一次通知，处处生效  \n>**广播设计思想**: 广播通知的是中心config  \n\n> 具体优化思想，见博文 Cloud_MQ\n\n\n","categories":["SpringCloud"],"tags":["SpringCloudConfig"]},{"title":"GateWay","url":"/posts/4296/","content":">对服务网关GateWay的知识总结\n<!--more-->\n# 核心与注意点\n>* GateWay作为网关也需要注册进注册中心\n>* 路由、断言、过滤器\n>* 网关不能部署在Tomcat、Jetty等Servlet容器里，只能打成jar包执行\n>* ​依赖于netty和WebFlux \n>* GateWay不能加Web的起步依赖的jar包\n\n# 架构图\n![alt](http://xtzl.wentexl.cn/%E6%9E%B6%E6%9E%84%E5%9B%BE.png)\n# 依赖导入\n```xml\n      <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-gateway</artifactId>\n        </dependency>\n```\n# 第一种配置方法：yml配置\n>* 获取当地时区 ZonedDateTime.now();\n```yml\nserver:\n  port: 9527\n\nspring:\n  application:\n    name: cloud-gateway\n  cloud:\n    gateway:\n      discovery:\n        locator:\n          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由\n      routes:\n       #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名\n        - id: payment_routh\n          #uri: http://localhost:8001          #匹配后提供服务的路由地址\n          uri: lb://cloud-payment-service #匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/get/**         # 断言，路径相匹配的进行路由\n         #payment_route    #路由的ID，没有固定规则但要求唯一，建议配合服务名\n        - id: payment_routh2\n         # uri: http://localhost:8001          #匹配后提供服务的路由地址\n          uri: lb://cloud-payment-service #匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/lb/**         # 必须是真正提供服务的方法 \n         #- After=2020-05-13T21:55:10.016+08:00[Asia/Shanghai]\n         # -Before\n         # -Between=2020-05-13T21:55:10.016+08:00[Asia/Shanghai],2021-05-13T21:55:10.016+08:00[Asia/Shanghai]\n         #- Cookie=username,milo\n         #- Header=X-Request-Id, \\d+  # 请求头要有X-Request-Id属性并且值为整数的正则表达式\n\neureka:\n  instance:\n    hostname: cloud-gateway-service\n  client: #服务提供者provider注册进eureka服务列表内\n    service-url:\n      register-with-eureka: true\n      fetch-registry: true\n      defaultZone: http://eureka7001.com:7001/eureka\n\n```\n\n# 第二种配置方法：Config配置\n> 当访问/guonei的时候，自动转发到http://news.baidu.com/guonei\n```java\n   @Bean\n    public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder)\n    {\n        RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes();\n        routes.route(\"path_route_atguigu\",\n                r -> r.path(\"/guonei\")\n                        .uri(\"http://news.baidu.com/guonei\")).build();\n        return routes.build();\n    }\n\n```\n# yml配置的时候，断言选项\n![断言](http://xtzl.wentexl.cn/GateWay%E6%96%AD%E8%A8%80.png)\n\n# curl开发\n>*  判断是否携带名为X-Request-Id的请求头，且其值必须是一个大于0的整数  \n>* -Header=X-Request-Id, \\d+   \n>* curl http://localhost:9527/payment/lb -H \"X-Request-Id:123\"\n>- - -\n>* 判断请求是否携带cookie名为username，值为milo\n>*  -Cookie = username,milo\n>* curl http://localhost:9527/payment/lb --cookie \"username=123\"\n\n# 自定义过滤器\n> 主要是要实现GlobalFilter,Ordered这两个接口，而且要加入容器\n\n**放行**\n```java\nreturn chain.filter(exchange);\n```\n**拦截**\n```java\nreturn exchange.getResponse().setComplete();\n```\n```java\n@Component\n@Slf4j\npublic class MyLogGateWayFilter implements GlobalFilter,Ordered\n{\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain)\n    {\n        log.info(\"***********come in MyLogGateWayFilter:  \"+new Date());\n        String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\");\n        if(uname == null)\n        {\n            log.info(\"*******用户名为null，非法用户，o(╥﹏╥)o\");\n            exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);\n            return exchange.getResponse().setComplete();\n        }\n        return chain.filter(exchange);\n    }\n    @Override\n    public int getOrder()\n    {\n        return 0;\n    }\n}\n```","categories":["SpringCloudAlibaba"],"tags":["GateWay"]},{"title":"JavaUtils","url":"/posts/13372/","content":">主要介绍了Java的各种工具类\n<!--more-->\n# IdUtil\n>* 主要介绍了各种id生成策略\n>* 生成的Id是用不重复的 \n>* String serialNumber = IdUtil.simpleUUID();\n\n# TimeUnit\n>* TimeUnit.DAYS //天  \n>* TimeUnit.HOURS //小时  \n>* TimeUnit.MINUTES //分钟  \n>* TimeUnit.SECONDS //秒  \n>* TimeUnit.MILLISECONDS //毫秒  \n>* TimeUnit.NANOSECONDS //毫微秒  \n>* TimeUnit.MICROSECONDS //微秒  \n>- - -\n>**转换：**\n>* public long toMillis(long d)    //转化成毫秒  \n>* public long toSeconds(long d)  //转化成秒  \n>* public long toMinutes(long d)  //转化成分钟  \n>* public long toHours(long d)    //转化成小时  \n>* public long toDays(long d)     //转化天   \n>- - -\n>**延时：** \n>* TimeUnit.SECONDS.sleep( 5 );\n>* TimeUnit.HOURS.sleep(1);\n\n# ZoneDateTime\n>* ZoneDateTime.now();可以获得当前时间串，在gateway中可以配置使用\n\n# 产生随机数的2种方法\n>两者均是左开右闭\n```java\n// 产生1~3的随机数\n System.out.println((int) (Math.random()*3) +1);\n // 产生0~20的随机数\n System.out.println(new Random().nextInt(20));\n```\n# UUID\n**随机数的生成**\n>* UUID.randomUUID().toString()","categories":["JavaStudy"],"tags":["JavaUtils"]},{"title":"Hystrix","url":"/posts/64571/","content":">Hystrix属于服务降级部分，这里将会详细介绍关于Hystrix的相关知识\n<!--more-->\n# Hystrix介绍\n>Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等。  \n>Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。  \n>- - -\n>“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控(类似熔断保险丝)，向调用方返回—个符合预期的、可处理的备选响应(FallBack)。  \n>而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。\n\n# Hystrix核心\n> * 服务降级\n> * 服务熔断\n> * 接近实时的监控\n\n# 依赖导入\n```xml\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n        </dependency>\n```\n>- - -\n# 服务降级----------------\n# 服务提供端8001设置fallbcakMethod兜底\n>- - -\n>主启动类添加注解，开启断路器功能\n```java\n@EnableCircuitBreaker\n```\n>- - -\n> 解释：  \n>* 业务层添加。如果paymentInfo_TimeOut()在规定的3s内执行失败，则立即访问   paymentInfo_TimeOutHandler()方法作为fallbackMethod方法  \n> * 只要是当前服务不可用了，马上做服务降级\n> * 如果是在服务端配置的服务降级，不能通过80端口回调，只能自测\n```java\n    @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\",\n    commandProperties = {\n        @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\",value=\"3000\")})\n    public String paymentInfo_TimeOut(Integer id)\n    {\n        try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); }\n        return \"线程池:  \"+Thread.currentThread().getName()+\" id:  \"+id+\"\\t\"+\"O(∩_∩)O哈哈~\"+\"  耗时(秒): 5\";\n    }\n\n    public String paymentInfo_TimeOutHandler(Integer id)\n    {\n        return \"线程池:  \"+Thread.currentThread().getName()+\"  8001系统繁忙或者运行报错，请稍后再试,id:  \"+id+\"\\t\"+\"o(╥﹏╥)o\";\n    }\n\n```\n\n# 客户端80设置fallbackMethod\n>主启动类添加注解  \n> 其中@EnableHystrix中也包含了@EnableCircuitBreaker\n```java\n@EnableHystrix\n```\n>- - -\n>客户端yml中的配置  \n\n```yml\nfeign:\n  hystrix:\n  #如果处理自身的容错就开启。开启方式与生产端不一样。\n    enabled: true \n```\n>通用fallback方法 :  \n\n> 若单个方法有具体指明fallback方法，则使用其具体的方法\n```java\n// hystrix 全局fallback方法标注在Controller的类头\n@DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\")\npublic class OrderFeignController{}\n```\n\n# 客户端80解决代码冗余和膨胀\n> 这样写的话，就不需要在Controller层进行指定了\n> 这样写的优先级仍然大于DefaultProperties的优先级\n```java\n// 在service层的注解添加fallback\n@FeignClient(value = \"cloud-provider-hystrix-payment\",fallback = PaymentFallbackServiceImpl.class)\n```\n```java\n// 书写service层的实现类\n@Component\npublic class PaymentFallbackServiceImpl implements PaymentFeignService {}\n```\n>- - -\n# 服务熔断-----------------------------------\n>## 核心\n> * 服务降级--熔断--慢慢恢复调用电路  \n>- - -\n\n\n> # 服务端\n> ## Controller层\n```java\n  //====服务熔断\n    @GetMapping(\"/payment/circuit/{id}\")\n    public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id)\n    {\n        String result = paymentService.paymentCircuitBreaker(id);\n        log.info(\"****result: \"+result);\n        return result;\n    }\n```\n>## Serice层\n\n```java\n //=====服务熔断\n    @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\",commandProperties = {\n        // 是否开启断路器v\n        @HystrixProperty(name = \"circuitBreaker.enabled\",value = \"true\"),\n        // 请求次数\n        @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"),\n         // 时间窗口期，在这个时间以内，请求次数达到多少后跳闸\n        @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"),\n        // 失败率达到多少后跳闸\n        @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\"),\n    })\n    public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id)\n    {\n        if(id < 0)\n        {\n            throw new RuntimeException(\"******id 不能负数\");\n        }\n        // 使用工具包生成流水号\n        String serialNumber = IdUtil.simpleUUID();\n\n        return Thread.currentThread().getName()+\"\\t\"+\"调用成功，流水号: \" + serialNumber;\n    }\n    public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id)\n    {\n        return \"id 不能负数，请稍后再试，/(ㄒoㄒ)/~~   id: \" +id;\n    }\n\n```\n\n# Hystrix断路器总结\n## 熔断需要依靠断路器\n![断路器](http://xtzl.wentexl.cn/%E6%96%AD%E8%B7%AF%E5%99%A8.png)\n\n## 断路器开启或关闭的条件\n>* 当满足一定的阀值的时候(默认10秒内超过20个请求次数)\n>* 当失败率达到一定的时候( 默认10秒内超过50%的请求失败)\n>* 到达以上阀值，断路器将会开启\n>* 当开启的时候，所有请求都不会进行转发\n>* 一段时间之后(默认是5秒)，这个时候断路器是半开状态，会让其中-一个请求进行转发。\n>* 如果成功，断路器会关闭，若失败，继续开启。\n\n# HystrixDashboard\n## 监控图详解\n![监控图](http://xtzl.wentexl.cn/%E7%9B%91%E6%8E%A7%E5%9B%BE.png)\n## 监控数据详解\n![监控数据](http://xtzl.wentexl.cn/%E7%9B%91%E6%8E%A7%E5%9B%BE%E6%95%B0%E6%8D%AE.png)","categories":["SpringCloud"],"tags":["Hystrix"]},{"title":"OpenFeign","url":"/posts/40393/","content":">主要记录了关于OpenFeign服务调用的知识\n<!--more-->\n\n# 核心\n>* 微服务接口 + @FeignClient\n>* Feign自带负载均衡配置项，默认支持Ribbon\n>* OpenFeign默认等待1秒钟，之后将会报超时错误\n>* 面向接口编程\n>* 主要就是在80端口多了一层Service\n>* 在Service层这里直接使用注解而不使用RestTemplate\n>* 更加方便和简洁\n>* @FeignClient()接口类中，使用@RequestParam时必须指定value\n>* Feign和热部署有可能会冲突，且在使用的时候，要注意接口层的参数是否有在请求体内的，如果没表明是否在请求体，会导致调用失败，如果在请求体，就要更换httpclient的依赖，否则可能会出现Get请求被自动转成Post请求的情况\n\n\n# 依赖引入\n```xml\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\n        </dependency>\n```\n# 主启动类\n```java\n@EnableFeignClients\n```\n# 80端微服务接口\n**Serice端**\n```java\n@Component\n@FeignClient(value = \"cloud-payment-service\")\npublic interface PaymentFeignService\n{\n    // 这里面的GetMapping是指的是服务实例中的方法的路径，并且会自动将获取到的路径变量加到路径中去\n    @GetMapping(value = \"/payment/get/{id}\")\n    public CommonResult<Payment> getPaymentById(@PathVariable(\"id\") Long id);\n}\n```\n**Controller端**\n```java\npublic class OrderFeignController\n{\n    @Resource\n    private PaymentFeignService paymentFeignService;\n    @GetMapping(value = \"/consumer/payment/get/{id}\")\n    public CommonResult<Payment> getPaymentById(@PathVariable(\"id\") Long id)\n    {\n        return paymentFeignService.getPaymentById(id);\n    }\n\n}\n```\n\n# 设置超时时间\n```yml\n#设置feign客户端超时时间(OpenFeign默认支持ribbon)\nribbon:\n  #指的是建立连接所用的时间，适用于网络状况正常的情况下, 两端连接所用的时间\n  ReadTimeout: 5000\n  #指的是建立连接后从服务器读取到可用资源所用的时间\n  ConnectTimeout: 5000\n```\n# 设置OpenFeign的日志\n## 自定义Config类，加入Bean设置日志级别\n```java\n@Configuration\npublic class FeignConfig\n{\n    @Bean\n    Logger.Level feignLoggerLevel()\n    {\n        return Logger.Level.FULL;\n    }\n}\n```\n## 在yml配置中设置日志的监控接口\n```yml\nlogging:\n  level:\n    # feign日志以 debug 级别监控 com.atguigu.springcloud.service.PaymentFeignService 接口，debug级别会直接在控制台console中打印出来\n    xtzl.ljw.service.PaymentFeignService: debug\n```\n","categories":["SpringCloud"],"tags":["OpenFeign"]},{"title":"Sleuth","url":"/posts/15024/","content":"> 分布式请求链路跟踪  :   \n> 总结了Springcloud-Sleuth的相关知识\n<!--more-->\n# zipkin  \n>* 安装使用jar包，然后直接敲 java -jar xxx.jar 这个命令就好\n>* 图形化界面端口号9411  \n\n**链路图:**\n![链路图](http://xtzl.wentexl.cn/Sleuth%E5%9B%BE.png)\n>* span 表示链路来源：通俗来说 span 就是一次请求信息\n>* Trance 类似于树结构的Span集合，表示一条调用链路，存在唯一标识\n\n**依赖引入**\n```xml\n     <!--包含了sleuth+zipkin-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-zipkin</artifactId>\n        </dependency>\n```\n**yml配置**\n> yml解释：\n>* base-url: 监控的数据需要发到9411上去  \n>* 采样率一般0.5就够了，表示只需要一半的数据就好\n```yml\nspring:\n    zipkin:\n        base-url: http://localhost:9411\n    sleuth:\n        sampler:\n        #采样率值介于0到1之间，1则表示全部采集\n        probability: 1\n```\n\n","categories":["SpringCloud"],"tags":["Sleuth"]},{"title":"Ribbon","url":"/posts/49475/","content":"> 整理了关于Ribbon负载均衡的相关知识\n<!--more-->\n# 核心\n>* 主要核心就是负载均衡\n\n# 依赖引入\n```xml\n    <dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>\n      <version>2.2.1.RELEASE</version>\n      <scope>compile</scope>\n    </dependency>\n```\n# Ribbon的核心组件IRule七种负载均衡的选择方式\n>- - -\n>(出厂默认)RoundRobinRule： 轮询，轮流访问不同的实例\n>- - -\n>RandomRule : 随机，随机访问不同的实例\n>- - -\n>RetryRule:  \n先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内进行重试，获取可用的服务。\n>- - -\n>WeightedResponseTimeRule:  \n对RoundRobinRule的扩展，响应速度越快的实例选择权重就越大，越容易被选择。\n>- - -\n>BestAvailableRule:  \n会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务。\n>- - - \n>AvailabilityFilteringRule:  \n先过滤掉故障实例，再选择并发较小的实例。\n>- - -\n>ZoneAvoidanceRule:  \n>默认规则，复合判断server所在区域的性能和server的可用性选择服务器。\n>- - -\n# Ribbon修改负载均衡的方式\n> **一定不能在主配置类可以扫到的包下，必须新建一个主配置类扫不到的包**\n> 注意点：  \n> * 注解里的服务名要小写\n> * 配置类名不能是MyRule，否则报错\n```java\n// IRule配置类添加\n@Configuration\npublic class MySelfRule {\n    @Bean\n    public IRule myrule(){\n        // 修改为随机方式\n        return new RandomRule(); \n    }\n}\n\n//80端口主运行类注解添加\n//其中name表示的是微服务名称\n@RibbonClient(name = \"cloud-payment-service\",configuration = MySelfRule.class)\n```\n# Ribbon的轮询算法\n> rest接口的第几次请求数 % 服务器集群实例数量 = 实际调用的服务器(实例)的下标\n```java\n// 获取指定服务的所有实例集合\n List<ServiceInstance> instances = discoveryClient.getInstances(\"consul-provider-payment\");\n 例如：\n instances[0]=127.0.0.1:8001\n instances[1]=127.0.0.1:8002\n\n```\n\n\n\n","categories":["SpringCloud"],"tags":["Ribbon"]},{"title":"Consul","url":"/posts/29713/","content":">总结了关于Consul注册中心的相关知识点\n<!--more-->\n# 小知识\n>* 启动consul可以配置环境变量\n>* consul agent -dev 命令来启动consul\n>* Consul的首页： http://localhost:8500\n\n# 依赖导入\n```xml\n   <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-consul-discovery</artifactId>\n        </dependency>\n```\n# application.yml 配置\n```yml\n###consul服务端口号\nserver:\n  port: 8006\n\nspring:\n  application:\n    name: consul-provider-payment\n  ####consul注册中心地址\n  cloud:\n    consul:\n      host: localhost\n      port: 8500\n      discovery:\n        #hostname: 127.0.0.1\n        service-name: ${spring.application.name}\n\n```\n# 主启动类\n```java\n@SpringBootApplication\n@EnableDiscoveryClient\n```\n\n","categories":["SpringCloud"],"tags":["Consul"]},{"title":"GitWords","url":"/posts/33301/","content":">记录了git的常用命令\n<!--more-->\n# Git颜色\n>* 红褐色：创建之后没有add，没提交，不在版本控制范围之内，这时候文件是红褐色的，需要先add文件；\n>* 绿色：add之后是文件绿色的，没有提交（commit）;\n>* 蓝色：原本拉取过来之后就有一个文件，改动过后没有提交（commit）是蓝色的，提交之后，变成正常颜色。\n# Git常用操作命令\n>* git ls-files 查看暂存区文件\n>- - -\n>* git init 初始化仓库\n>- - -\n>* git add . 添加所有文件进暂存区\n>- - -\n>* git commit 提交到本地仓库\n>- - -\n>* git push 推送到远程仓库\n>- - -\n>* git pull 从远程仓库拉取最新代码\n>* git pull origin main // 从origin远程仓库拉取分支main的代码到本地的当前分支\n>* git pull -rebase\n>- - -\n>* git checkout -b master 新建一个master分支\n>- - -\n>* git branch -al 查看所有本地分支\n>- - -\n>* git checkout 本地分支名 切换到其他的本地分支\n>- - -\n>* git remote add origin git@github.com:xxxx/xx.git //origin是自定义的远程库的名字，这是给本地仓库添加远程仓库\n>- - -\n>* git remote rm origin 与远程仓库解绑\n>- - -\n>* git remote -v 查看远程仓库的相关信息\n>- --\n>* git push -u origin master  //把当前分支master推送到远程；远程库是空的，所以第一次push加上-u参数；不仅推送了且两个master分支相关联，后续push命令简化git push origin master\n>* git push origin master:main //把本地的master分支上传到origin远程仓库的main分支去\n>* git push origin main // 当且仅当本地分支和远程分支名相同的时候可以直接这样push\n>- - -\n>* git clone git@github.com:lengnuann/L.git xtzl/ljw/ 克隆指令将远程仓库的代码克隆到本地的xtzk/ljw这个文件夹之下\n>- - -\n>* git log 查看日志\n>- - -\n>* git branch --set-upstream-to origin/main master 关联分支，将远程仓库的main分支和master相关联，如果执行失败，先去IDEA的Git下的Pull中获取分支，多刷新一下\n>- - -\n>* git stash 暂存工作区的内容\n>- - -\n>* git stash pop 恢复暂存的工作区内容\n>- - -\n>* git stash list 查询工作区所有stash的列表\n>- - -\n>* git stash apply 例如：git stash apply stash@{2} 表示指定stash@{2}这个暂存版本，如果不指定，则git stash pop默认恢复最新的一次stash\n>- - -\n>* git stash clear 清空stash\n>- - -\n>* git branch --set-upstream-to=gitee/master master :关联远程分支与本地分支，第二个master指的是第本地分支，gitee/master，指的是gitee设置远程仓库名，中的远程分支master,其中远程仓库必须有该分支\n>- - -\n>* git reset --hard 6b2b7aa ：强制回退到某个版本，将不会保存原来的代码（慎用！！！）\n>- - -\n>* git branch  --track  experimental  origin/experimental ：同样是追踪分支\n>* git branch -m master main 将matser分支更名为main分支 \n>- - - \n>* git config --global push.default simple  //设置默认行为为simple。 Git2.0以后\n >- - -\n >* git config --global push.default matching //设置默认行为为matching。Git2.0以前\n>- - -\n>* git config --global user.name  userName\n>- - -\n>* git config --global user.email email\n >- - -\n >* git reflog // 查看版本信息\n\n# 三种新建项目绑定gitee的远程仓库方式\n# git clone\n> 可以直接git clone远程仓库，就默认绑定clone的那个分支和本地的master分支了\n\n# git remote add -f url\n> 添加 -f 参数相当于执行一次git fetch操作，将会把远程的同名分支都绑定到本地的分支\n> 然后输入 git pull origin master,即可将远程origin的仓库中的master分支绑定拉取到当前分支，如果本地分支没有远程分支已有的分支，则自动在本地创建，但是这样做的弊端就是每次都要手动选择拉取远程仓库的哪一个分支\n\n# git remote add url \n> 执行完这个之后需要手动再执行一次 git fetch\n> git fetch 之后，会自动将远程仓库的同名分支与本地仓库进行匹配绑定，如果本地没有分支，则自动在本地新建同名分支并绑定。\n\n# 两个独立仓库的合并\n>直接用IDEA的拉取就行，建议之间rebase\n> 即便是远程仓库和本地仓库并没有历史相同版本点，也可以进行合并  \n>git pull origin master –allow-unrelated-histories\n> 如果合并失败，就只能使用rebase了\n> git pull --rebase origin master","categories":["Accumulate"],"tags":["git"]},{"title":"LinuxWords","url":"/posts/17418/","content":">总结了一些关于linux的操作命令\n<!--more-->\n\n># SCP命令\n>## 将本地linux服务器的文件拷贝到远程的linux服务器上\n```linux\nscp  /root/file1.txt  username@202.202.146.245:/home/S12004060119/\n```\n>## 将远程linux的文件拷贝到自己的linux本地服务器\n```linux\nscp  username@202.202.146.245:/home/S12004060119/file.txt /root/sh/\n```\n>## 把本地Windows系统的文件夹传到远程linux服务器上\n```linux\nscp -P 22 -r E:\\weixin\\ S12004060119@202.202.146.245:/home/S12004060119/\n```\n># 快捷键\n>Ctrl+l  ：清屏  \nCtrl+o ：执行当前命令，并选择上一条命令  \nCtrl+s ：阻止屏幕输出  \nCtrl+q ：允许屏幕输出  \nCtrl+c ：终止命令  \nCtrl+z ：挂起命令  \nCtrl+d ：输入结束，即EOF的意思，或者注销linux系统\n\n\n# 基本命令\n>* pwd命令  \n>查看当前用户所在的路径\n>* passwd命令  \n>格式： passwd 用户名\n>给用户指定密码\n>* init 命令  s\n>Int 3：字符界面\n>Int 5：图形界面\n>* set nu 命令  \n>set nu表示设置行号\n>set nonu表示取消行号\n>* cat命令  复制文件  \n>Cat file1.txt>>file2.txt\n>* cp复制  \n>cp file1.txt /*/*/*\n>* mv命令  \n>mv a b 实现重命名  \n>mv 文件名 移动目的地后的文件名  \n>mv 文件名 修改后的文件名\n\n# 文件权限管理命令\n## 权限表示\n>- - -\n><img src = \"http://xtzl.wentexl.cn/S.png\"/>\n\n\n## chmod\n>- - -\n>核心就是chmod，命令格式为：chmod [-R] 权限值 文件名, -R 表示参数以递归方式对子目录和文件进行修改\n>- 用户字母含义\n>   - u 表示该文件的拥有者\n>   - g 表示与该文件的拥有者属于同一用户组的用户\n>   - o 表示其他以外的人\n>   - a 表示所有人\n>- 权限字母含义\n>   - r 表示可读权限\n>   - w 表示可写入权限\n>   - x 表示可执行文件\n>- 设定权限方式\n>   - '+' 表示增加权限\n>   - '-' 表示取消权限\n>   - '=' 只设定=号后的权限\n>- - -\n## chown\n>chown 更改文件的拥有者，语法：chown 选项 用户名:组名 文件名\n>- 常用选项\n>   - -c 若该文件拥有者确实已经更改，才显示其更改动作\n>   - -f 若该文件拥有者无法被更改也不要显示错误讯息 \n>   - -v 显示拥有者变更的详细资料\n>- - -\n## chgrp\n>chgrp 更改文件的用户组\n>- 常用选项\n>   - -R 递归处理，将指定目录下的所有文件及子目录一并处理\n>   - -v 显示指令执行过程\n>   - –reference 把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同\n\n\n## 使用案例\n>* chmod u-r test.txt 取消当前用户的对text.txt可读权限\n>* chmod g-rwx test.txt 使text文件的所属组没有权限\n>* chmod a+rwx test.txt 给所有用户都赋予text.txt的所有权限\n>* chmod u=w text.txt 只给text.txt文件可写权限\n\n# 运行类命令\n- nohup java -jar app1.jar &   \n  - nohup是一个命令，用于运行一个进程，并使该进程忽略任何挂起的挂断信号（SIGHUP）。这样，即使用户注销或关闭终端，该进程也会继续运行。\n  - &是一个特殊的字符，用于将命令放在后台运行。在命令的末尾添加&时，该命令会在后台运行，这意味着该命令不会占用终端，并且您可以立即执行其他命令。\n\n- kill <进程ID>\n\n- ps 两种参数格式不同罢了\n  - ps -ef\n  - ps aux \n\n- top -p <PID>，根据进程的PID去查询该进程所占内存的情况\n  - 显示行包括进程ID（PID）、用户（USER）、优先级（PR）、调度策略（SCHED）、虚拟内存大小（VIRT）、物理内存大小（RES）、共享内存大小（SHR）、状态（S）、CPU占用百分比（%CPU）、内存占用百分比（%MEM）和运行时间（TIME+）等。\n\n# 常用目录\n- nginx\n  - nginx.conf : /etc/nginx/nginx.conf\n  - nginx: /usr/local/sbin/nginx\n\n- logs\n  - nginx的errorlog : /var/log/nginx/nginx.log\n# SSH加密\n> 验证服务器使用的非对称加密，主机和从机建立连接之前，会判断从机的公钥是否跟主机中存储的从机的公钥相同，如果相同的情况下，才允许建立连接\n# 非对称加密原理\n> <img src=\"http://xtzl.wentexl.cn/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\"/>\n# 对称加密原理\n> 加密和解密使用同一个密钥，主机使用这个密钥加密，从机也使用这个密钥解密\n\n# 查日志常用命令\n## tail\n## cat\n## less\n## vim\n\n# Nginx反向代理配置图\n<img src=\"http://xtzl.wentexl.cn/nginx%E9%85%8D%E7%BD%AE.png\">","categories":["Accumulate"],"tags":["linux"]},{"title":"IDEA_Hotkeys","url":"/posts/10025/","content":"> IDEA的使用快捷键\n<!--more-->\n>**IDEA使用的快捷键**   \n\n>ctrl + D：复制上一行  \n>- - -\n>Ctrl+D: 同时也可以表示结束输入  \n>- - -\n>Shift + alt +↑（↓） ：上下移动某一行  \n>- - -\n>ctrl+/ ：注释  \n>- - -\n>ctrl+r : 查找和替换  \n>- - -\n>ctrl+alt+t: 抓异常快捷键  \n>- - -\n>shift连按两次：查询  \n>- - -\n>ctrl+alt+b：通过接口查看其实现类 \n>- - - \n>alt+insert+fn : 生成getter和setter方法  \n>- - -\n>ctrl+f: 搜索查看  \n>- - -\n>ctrl+a：一键全选  \n>- - -\n>shift+home:选中单行  \n>- - -\n>Ctrl+i:  选择实现方法  \n>- - -\n>Ctrl+Q: 查看上下文信息\n>- - -\n>shift+tab:取消缩进\n>- - -\n>Ctrl+alt+B: 显示实现类\n>- - -\n>Ctrl+shift+n : 查找类或者文件 \n>- - -\n>Ctrl + O : 快速重写\n>- - -\n>Ctrl + P : 查看参数\n>- - -\n>- - -\n>**调试**\n>* F8单步调试。不进入函数内部\n>- - -\n>* F7 单步调试 进入函数肉部\n>- - -\n>* Shift+F7 选择要进入的函数\n>- - -\n>* Shift+F8 跳出函数\n>- - -\n>* Alt+F9 运行到断点\n>- - -\n>* Alt+F8 执行表达式查看结果\n>- - -\n>* F9继续执行，进入下一个断点或执行完程序\n>- - -\n>* Ctr|+F8 设置/取消当前行断点\n>- - -\n>* Ctrl+Shift+F8 查看断点\n>- - -","categories":["Accumulate"],"tags":["Hotkeys"]},{"title":"Eureka","url":"/posts/57702/","content":">关于EureKa的知识笔记：Eureka的服务注册与发现\n<!--more-->\n# 小知识\n> * Eureka不用自己注册自己\n> * 注意启动顺序，服务端必须先启动才能检索到客户端\n> * 集群配置：互相注册，相互守望\n> * 配置host之后记得在cmd使用ipconfig /flushdns刷新一下\n> * 大坑！！！:配置集群之后，直接点击链接是访问不了的！！多了一层路径！必须要手动输入地址!\n> * defaultZone如果有多个url，不同的url通过逗号隔开\n\n># 依赖引入\n>## 服务注册端 server\n```xml\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>\n        </dependency>\n```\n>## 客户端 client\n```xml\n         <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n```\n\n># 单机版在Application.yml中配置\n>## 单机版在server端中的yml配置\n```yml\neureka:\n instance:\n   hostname: localhost  #eureka服务端的实例名字\n client:\n   register-with-eureka: false    #表示不向注册中心注册自己\n   fetch-registry: false   #表示自己就是注册中心，职责是维护服务实例，并不需要去检索服务\n   service-url:\n     #设置与eureka server交互的地址查询服务和注册服务都需要依赖这个地址\n     defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n\n```\n>## 单机版在client端的yml配置\n```yml\neureka:\n  client:\n    #表明自己需要注册进Eureka中\n    register-with-eureka: true\n    #是否从EurekaServer抓取已有信息，默认为true。\n    #单节点无所谓，集群的话必须设置为true才能配合ribbon使用负载均衡\n    fetch-registry: true\n    service-url:\n      #设置与eureka server交互的地址查询服务和注册服务都需要依赖这个地址\n      #单机指向自己\n      defaultZone: http://localhost:7001/eureka\n\n```\n\n\n> # 集群版在Application.xml中的配置\n> ## 在Client端的yml配置\n>- - -\n> 最主要的在于defalutZone的变化  \n> eureka7001.com是host文件配置的主机名\n> \n```yml\neureka:\n  client:\n    register-with-eureka: true\n    fetch-registry: true\n    service-url:\n    #集群指向所以注册中心的eureka\n      defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka\n```\n>## 在Server端的yml配置\n```yml\neureka:\n  instance:\n    hostname: eureka7002.com  #eureka服务端的实例名字\n  client:\n    register-with-eureka: false\n    fetch-registry: false\n    service-url:\n    #集群指向其他eureka\n      defaultZone: http://eureka7001.com:7001/eureka\n```\n\n># 在主运行类中的注解标识\n>## Server端使用的主键\n```java\n@EnableEurekaServer\n```\n>## Client端使用的注解\n```java\n@EnableEurekaClient\n```\n\n># 服务发现\n> 将服务信息放到到注册中心去  \n> 通过服务发现来活动该服务的信息\n```java\n    // Controller 添加\n    @Resource\n    private DiscoveryClient discoveryClient;\n    \n    // 主运行类添加\n    @EnableDiscoveryClient\n```\n\n# Instance配置\n```yml\n  instance:\n    # 微服务下实例名称修改\n    instance-id: payment8002\n    # 显示IP地址\n    prefer-ip-address: true\n```\n># Eureka的自我保护机制\n>自我保护机制:默认情况下EurekaClient定时向EurekaServer端发送心跳包  \n如果Eureka在server端在一定时间内(默认90秒)没有收到EurekaClient发送心跳包 ,便会直接从服务注册列表中剔除该服务  \n>但是在短时间( 90秒中)内丢失了大量的服务实例心跳,\n这时候EurekaServer会开启自我保护机制,不会剔除该服务(该现象可能出现在网络不通的情况使得 EurekaClient为出现宕机  \n>此时如果换做别的注册中心如果一定时间内没有收到心跳会将剔除该服务,这样就出现了严重失误,因为客户端还能正常发送心跳只是网络延迟问题，而保护机制是为了解决此问题而产生的)\n\n># 关闭Eureka的自动保护机制\n>server端\n```yml\n## Server端的yml中设置关闭自我保护机制，保证不可用服务被及时踢除\neureka:\n  server:\n     enable-self-preservation: false\n     eviction-interval-timer-in-ms: 2000\n```\n>client端设置心跳响应时间\n```yml\neureka:\n  instance:\n#    Eureka客户端向服务端发送心跳的时间间隔，单位为秒(默认是30秒)\n   lease-renewal-interval-in-seconds: 1\n#    Eureka服务端在收到最后一次心跳后等待时间上限，单位为秒(默认是90秒)，超时将剔除服务\n   lease-expiration-duration-in-seconds: 2\n```\n","categories":["SpringCloud"],"tags":["Eureka"]},{"title":"Summary","url":"/posts/42402/","content":">介绍和总结整个SpringCloud的理论体系\n# SpringCloud架构图\n![SpringCloud架构图](http://xtzl.wentexl.cn/SpringCloud%E6%9E%B6%E6%9E%84%E5%9B%BE.png)\n\n<!--more-->\n# 注册中心的异同点\n>## **CAP**\n>- - -\n>**解释**：  \n>C :(强一致性):   对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。  \n>A :(可用性):     非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应)  \n>P :(分区容错性): 当出现网络分区后，系统能够继续“履行职责”。\n>- - -\n>* 分布式系统理论上不可能选择CA架构，只能选择CP或者AP 架构。\n>* CAP理论关注粒度是数据，而不是整个系统的设计策略\n>* AP(Eureka) ; CP(Consul) ; HA(高可用，也是Eureka)  \n>![CAP](http://xtzl.wentexl.cn/SpringCloud/CAP.png)\n\n\n# SpringCloud总图\n![总图](http://xtzl.wentexl.cn/SpringCloud.png)\n\n\n","categories":["SpringCloud"],"tags":[]},{"title":"Dependencies","url":"/posts/18669/","content":"> 该博文主要记录了在Cloud微服务开发中常用的依赖\n\n# 父工程\n```xml\n<!-- 统一管理jar包版本 -->\n    <properties>\n        <maven.compiler.source>8</maven.compiler.source>\n        <maven.compiler.target>8</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n        <junit.version>4.12</junit.version>\n        <log4j.version>1.2.17</log4j.version>\n        <lombok.version>1.16.18</lombok.version>\n        <mysql.version>5.1.47</mysql.version>\n        <druid.version>1.1.16</druid.version>\n        <mybatis.spring.boot.version>1.3.0</mybatis.spring.boot.version>\n    </properties>\n\n    <!-- 1、只是声明依赖，并不实际引入，子项目按需声明使用的依赖 -->\n    <!-- 2、子项目可以继承父项目的 version 和 scope -->\n    <!-- 3、子项目若指定了 version 和 scope，以子项目为准 -->\n    <dependencyManagement>\n        <dependencies>\n            <!--spring boot 2.2.2-->\n            <dependency>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-dependencies</artifactId>\n                <version>2.2.2.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <!--spring cloud Hoxton.SR1-->\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-dependencies</artifactId>\n                <version>Hoxton.SR1</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n            <!--spring cloud alibaba 2.1.0.RELEASE-->\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>2.1.0.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n\n<!-- 以上依赖不能出现在子工程 -->\n\n\n            <dependency>\n                <groupId>mysql</groupId>\n                <artifactId>mysql-connector-java</artifactId>\n                <version>${mysql.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.alibaba</groupId>\n                <artifactId>druid</artifactId>\n                <version>${druid.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.mybatis.spring.boot</groupId>\n                <artifactId>mybatis-spring-boot-starter</artifactId>\n                <version>${mybatis.spring.boot.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>junit</groupId>\n                <artifactId>junit</artifactId>\n                <version>${junit.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n                <version>${log4j.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.projectlombok</groupId>\n                <artifactId>lombok</artifactId>\n                <version>${lombok.version}</version>\n                <optional>true</optional>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n```\n\n# 子工程\n```xml\n\n    <dependencies>\n        <dependency>\n            <groupId>log4j</groupId>\n            <artifactId>log4j</artifactId>\n        </dependency>\n        \n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid</artifactId>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web -->\n        <dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/com.alibaba/druid -->\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid-spring-boot-starter</artifactId>\n            <version>1.2.8</version>\n        </dependency>\n        <!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-jdbc</artifactId>\n        </dependency>\n           <!-- https://mvnrepository.com/artifact/org.projectlombok/lombok -->\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n     </dependencies>\n```\n# 通用工程依赖\n```xml\n <dependencies>\n        <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <!-- https://mvnrepository.com/artifact/cn.hutool/hutool-all -->\n        <dependency>\n            <groupId>cn.hutool</groupId>\n            <artifactId>hutool-all</artifactId>\n            <version>5.1.0</version>\n        </dependency>\n</dependencies>\n\n```","categories":["SpringCloud"],"tags":["dependencies"]},{"title":"Configuration_header","url":"/posts/65104/","content":">在Web开发中，该博文对常用配置类的配置头进行了总结\n<!--more-->\n# Web开发常用配置头的总结\n\n>## Mabatis的 Mapper.xml 配置头\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"xtzl.ljw.Dao.PaymentMapper\">\n</mapper>\n``` \n \n>## Bean.xml 配置头\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n</beans>\n\n```","categories":["Accumulate"],"tags":["Configuration_header"]},{"title":"Mabtis && MybatisPlus","url":"/posts/31024/","content":">总结了Mabtis和plus的一些小细节的知识\n<!--more-->\n\n# Mabatis&&Plus 小知识总结\n\n## type-aliases-package\n### type-aliases-package作用\n>在Mybatis的mapper.xml文件中resultType的type或者paramterType会返回自定义entity  \n此时可以用全类名名来指定这些实体。\n### type-aliases-package配置\n```yml\nmybatis:\n    type-aliases-package=xtzl.ljw.entities\n```\n\n## 指定Mapper路径\n```yml\nmybatis:\n    mapper-locations: classpath:mapper/*.xml\n```\n## useGeneratedKeys\n>在使用useGeneratedKeys=\"true\"后返回值是1，期待返回实体主键\n>insert方法返回值依然是修改行数  \n需要从传入的实体中取对应属性值。  \n\n比如user表对应User类，主键是id\n那么int i =insertUser（user）;  \n方法执行后 i 还是1\n\n但是user.getId();得到的值就是主键了\n>- - -\n>一般来说需要和 keyProperty=\"id\" 联用，意为指定主键\n\n# MybatisPlus配置\n## 接口配置\n### Mapper父类\n```java\n@Mapper\npublic interface stuTeaMapper extends BaseMapper<StuTea> {}\n```\n### Service父类接口\n```java\npublic interface StuTeaService extends IService<StuTea>\n```\n### Service父类实体\n```java\n@Service\npublic class StuTeaServiceImpl extends ServiceImpl<stuTeaMapper,StuTea> implements StuTeaService {}\n```\n> - - -\n## yml配置\n```yml\n# mybatis_plus配置\nmybatis-plus:\n  mapper-locations: classpath:/mapper/*.xml\n  configuration:\n    #将数据库的带下划线给去掉然后映射到实体类的属性上去\n    map-underscore-to-camel-case: true\n    # 可返回自增长的主键\n    use-generated-keys: true\n```\n\n# MybatisPlus方法总结\n## 方法总图\n<img src = \"http://xtzl.wentexl.cn/mybatisPlus%E5%B0%81%E8%A3%85%E5%87%BD%E6%95%B0.png\"/>\n\n## QueryWrpper\n>* allEq(Map params,null2isNull)，其中的null2isNull的意思是，如果Map参数集合里有参数的值为null，那在实际sql中是强制这个字段为Null，或者是忽略这个字段的判断条件\n>* nested()\n## UpdateWrapper\n","categories":["TechStack"],"tags":["Mabtis"]},{"title":"JavaNorms","url":"/posts/17711/","content":"> 在学习过程中，对一些常见的开发格式和开发规范，以及一些规范类进行了整理和总结\n<!--more-->\n\n# 规范类:\n## POJO 类\n```markdown\n\"Plain Ordinary Java Object\"，简单普通的java对象。主要用来指代那些没有遵循特定的java对象模型，约定或者框架的对象。\n\nPOJO的内在含义是指那些:\n有一些private的参数作为对象的属性，然后针对每一个参数定义get和set方法访问的接口。\n没有从任何类继承、也没有实现任何接口，更没有被其它框架侵入的java对象。\n```\n\n## JavaBean\n```markdown\nJavaBean 是一种JAVA语言写成的可重用组件。JavaBean符合一定规范编写的Java类，不是一种技术，而是一种规范。大家针对这种规范，总结了很多开发技巧、工具函数。符合这种规范的类，可以被其它的程序员或者框架使用。\n它的方法命名，构造及行为必须符合特定的约定:\n    · 所有属性为private。\n    · 这个类必须有一个公共的缺省构造函数。即是提供无参数的构造器。\n    · 这个类的属性使用getter和setter来访问，其他方法遵从标准命名规范。\n    · 这个类应是可序列化的。实现serializable接口。\n\n因为这些要求主要是靠约定而不是靠实现接口，所以许多开发者把JavaBean看作遵从特定命名约定的POJO\n```\n# Rest风格详情介绍\n>* GET （常用于查询）\n>- - -\n>* POST（常用于保存）\n>- - -\n>* PUT（常用于更新修改）\n>- - -\n>* DELETE（常用于删除）\n\n## 传统风格: RequestMapping\n><![传统风格](http://xtzl.wentexl.cn/CT.png)  \n## Restful风格: 增删改查\n![Rest](http://xtzl.wentexl.cn/Rest%E9%A3%8E%E6%A0%BC.png)\n## 两种模式的区别：\n>**风格与规则的区别：**  \n>Restful风格要简洁了很多，并且把行为都隐藏了  \n风格是一种约定俗成的方式，这种约定并不是一定要遵守的，可以不去使用这种约定，即也可以使用传统风格。而规范呢是一种大家必须遵守的规则，你如果不按照这个规范来书写代码，那么就不被允许运行。  所以被叫做REST风格，而不是叫做REST规范。  \n\n\n","categories":["JavaStudy"],"tags":["JavaNorms"]},{"title":"Annotation","url":"/posts/54839/","content":"> 注解的使用\n<!--more-->\n\n# 常用注解的解释与使用\n\n## 与 SQL 有关的注解\n### @Param\n首先明确这个注解是为SQL语句中参数赋值而服务的。    \n\n @Param的作用就是给参数命名，比如在mapper里面某方法A（int id）  \n 当添加注解后A（@Param(\"userId\") int id）  \n 也就是说外部想要取出传入的id值，只需要取它的参数名userId就可以了。  \n 将参数值传如SQL语句中，通过#{userId}进行取值给SQL的参数赋值\n\n```SQL\nmapper:\npublic User selectUser(@Param(\"userName\") String name,@Param(\"password\") String pwd);\n\nxml:\n<select id=\"selectUser\" resultMap=\"User\">  \n   select * from user  where user_name = #{userName} and user_password=#{password}  \n</select>\n可发现，userName为映射名，相当于起的是个别名\n\n注意点：  \n·当使用了@Param注解来声明参数的时候，SQL语句取值使用#{}，${}取值都可以。\n·当不使用@Param注解声明参数的时候，必须使用的是#{}来取参数。使用${}方式取值会报错。\n·不使用 @Param注解时，参数只能有一个，并且是Javabean。在SQL语句里可以引用JavaBean的性，而且只能引用JavaBean的属性。\n\n\n实际上：\n即便是不使用这个注解，也可以直接通过#{}去访问NewUser的成员变量，也是可以的，但是也只能有一个参数，这个参数就只能是NewUser这个JavaBean对象\n    <insert id=\"insertN\" parameterType=\"xtzl.boot.bean.NewUser\">\n        insert into user (username,password,sex,status) values (#{username},#{password},#{sex},#{status})\n    </insert>\n\n```\n### @TableField\n>@TableField(exist = false) 注解加载bean属性上，表示当前属性不是数据库的字段，但在项目中必须使用，这样在新增等使用bean的时候，mybatis-plus就会忽略这个，不会报错。\n```java\n    // 插入\n    @TableField(fill = FieldFill.INSERT)\n    private LocalDateTime createTime;\n    // 插入或更新的时候填充字段\n    @TableField(fill = FieldFill.INSERT_UPDATE)\n    private LocalDateTime updateTime;   \n\nDEFAULT ：默认不处理\nINSERT ： 插入操作时进行填充字段\nUPDATE ：更新操作时填充字段\nINSERT_UPDATE ：插入和更新操作时填充字段\n\n\n```\n# Spring有关注解\n## @EnableWebSecurity\n>**EnableWebSecurity注解有两个作用**\n>* 1: 加载了WebSecurityConfiguration配置类, 配置安全认证策略。\n>* 2: 加载了AuthenticationConfiguration, 配置了认证信息。\n## @PostConstruct\n> 该注解主要用于初始化的时候使用，标注了该注解的方法，将会在所在类的依赖注入之后执行    \n> 类的构造方法是造本类的依赖注入之前就会执行\n## @ControllerAdvice\n>@ControllerAdvice就是@Controller 的增强版。@ControllerAdvice主要用来处理全局数据，一般搭配@ExceptionHandler、@ModelAttribute以及@InitBinder使用。可以指定某个包下的所有Controller，也可以自定义注解，指定包含了自定义注解的Controller\n>- - -\n## @ModelAttribute\n>表示此方法会在执行目标Controller方法之前执行\n## @InitBinder\n>@ControllerAdvice结合@InitBinder还能实现请求参数预处理，即将表单中的数据绑定到实体类上时进行一些额外处理。\n### 使用\n```java\n@InitBinder\n    public void initBinder(WebDataBinder dataBinder){\n        /*\n         * 创建一个字符串微调编辑器\n         * 参数{boolean emptyAsNull}: 是否把空字符串(\"\")视为 null\n         */\n        StringTrimmerEditor trimmerEditor = new StringTrimmerEditor(true);\n        /*\n         * 注册自定义编辑器\n         * 接受两个参数{Class<?> requiredType, PropertyEditor propertyEditor}\n         * requiredType：所需处理的类型\n         * propertyEditor：属性编辑器，StringTrimmerEditor就是 propertyEditor的一个子类\n         */\n        dataBinder.registerCustomEditor(String.class, trimmerEditor);\n        //日期格式的字符串转换成Date对象\n       dataBinder.registerCustomEditor(Date.class, new CustomDateEditor(new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"), false));\n        \n   dataBinder.addValidators(paramVOValidator);\n\n}\n```\n## @ExceptionHandler\n>@ControllerAdvice最常见的使用场景就是全局异常处理。比如文件上传大小限制的配置，如果用户上传的文件超过了限制大小，就会抛出异常,此时可以通过@ControllerAdvice结合@ExceptionHandler定义全局异常捕获机制\n## 批注\n>这三个注解都可以在普通的Controller类上使用,ControllerAdvice只是作用范围可以自定义(默认全部)\n>- - -\n\n","categories":["Accumulate"],"tags":["Annotation"]},{"title":"Maven","url":"/posts/35182/","content":"\n> 关于Maven的一些小知识点\n<!--more-->\n\n# 直接手动从中央仓库下载依赖\n>## 地址：https://www.mvnrepository.com/\n>## 下载格式\n```markdown\n    mvn dependency:get -DremoteRepositories=https://mvnrepository.com/artifact/org.projectlombok/lombok -DgroupId=org.projectlombok -DartifactId=lombok -Dversion=1.18.12\n\n特别注意： 等号后面一定不能留空格，否则会出现找不到坐标的错误\n\n```\n# 坐标\n>注：groupId 在新建项目的时候可以自行指定，以便于在项目中新建通用模块之后导入其他模块\n> - - - \n> groupId和artifactId是maven管理项目包时用作区分的字段，就像是地图上的坐标。  \nartifactId：artifactId一般是项目名或者模块名。  \ngroupId：groupId分为几个字段，例如cn.com.fullstack，前面的com叫【域】，后面的是你自己起的域名。\n>- - -\n>groupId一般分为多个段，这里我只说两段，第一段为域，第二段为公司名称。  \n域又分为org、com、cn等等许多，其中org为非营利组织，com为商业组织。  \n举个apache公司的tomcat项目例子：这个项目的groupId是org.apache，它的域是org（因为tomcat是非营利项目），公司名称是apache，artigactId是tomcat。","categories":["TechStack"],"tags":["maven"]},{"title":"Notes","url":"/posts/52648/","content":"\n> SpringCould的学习随堂笔记\n\n<!--more-->\n\n# SpringCould 随堂笔记\n\n>## 父工程框架  \n  \n> ### 父工程统一管理Jar包\n```xml\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <maven.compiler.source>12</maven.compiler.source>\n    <maven.compiler.target>12</maven.compiler.target>\n    <junit.version>4.12</junit.version>\n    <lombok.version>1.18.10</lombok.version>\n    <log4j.version>1.2.17</log4j.version>\n    <mysql.version>8.0.21</mysql.version>\n    <druid.version>1.0.9</druid.version>\n    <mybatis.spring.boot.version>2.2.2</mybatis.spring.boot.version>\n  </properties>\n```\n>### 必要依赖\n```xml\n    <dependencies>\n      <!--spring boot 2.2.2-->\n      <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-dependencies</artifactId>\n        <version>2.2.2.RELEASE</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n      <!--spring cloud Hoxton.SR1-->\n      <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-dependencies</artifactId>\n        <version>Hoxton.SR1</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n      <!--spring cloud alibaba 2.1.0.RELEASE-->\n      <dependency>\n        <groupId>com.alibaba.cloud</groupId>\n        <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n        <version>2.1.0.RELEASE</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n\n```\n\n\n>## 子工程application配置文件\n### 数据源配置\n```yml\n  datasource:\n    type: com.alibaba.druid.pool.DruidDataSource\n    driver-class-name: org.gjt.mm.mysql.Driver\n    url: jdbc:mysql://localhost:3306/db2019?useUnicode=true&characterEncoding=utf-8&useSSL=false\n    username: root\n    password: root\n\n```\n### 唯一标识\n```yml\nspring:\n  application:\n    name: cloud-payment-service\n```\n## Devtools 开启热部署\n> 注：电脑不太行不建议开启，太锤子卡了\n>1. 导入jar包\n>2. 引spring-boot-maven-plugin插件\n>3. 在IDEA的Compile中调设置.\n>4. 重启IDEA\n\n\n## RestTemplate\n> 可用 订单80端口去调用8001端口的服务进行操作\n```java\n  @Bean\n    public RestTemplate getRestTemplate(){\n        return new RestTemplate();\n    }\n```\n> ### 两种方式：\n```java\n  // 第一种是写死的，第二种是URL为集群的服务名\n  // 微服务可能有多个端口\n   // public static final String PAYMENT_URL=\"http://localhost:8001\";\n    public static final String PAYMENT_URL=\"http://CLOUD-PAYMENT-SERVICE\";\n    @Resource\n    private RestTemplate restTemplate;\n\n    // GET请求实际上调用了POST请求\n    @GetMapping(\"/consumer/payment/create\")\n    public CommonResult<Payment> create(Payment payment){\n        return restTemplate.postForObject(PAYMENT_URL+\"/payment/create\",payment,CommonResult.class);\n    }\n\n    @GetMapping(\"/consumer/payment/get/{id}\")\n    public CommonResult<Payment> getPayment(@PathVariable(\"id\") Long id){\n        System.out.println(id);\n        log.info(String.valueOf(id));\n        return restTemplate.getForObject(PAYMENT_URL+\"/payment/get/\"+id,CommonResult.class);\n    }\n\n坑： 此处我使用@Pathgram 无法获取到路径变量\n```\n**细节**  \n>在微服务的Controller中，涉及到POST请求，一定不要忘记加@RequstBody这个注解，当80端口的请求到微服务端口的方法时\n```java\n    @PostMapping(\"/payment/create\")\n    public CommonResult create(@RequestBody Payment payment){\n    }\n```\n# 负载均衡\n> 微服务没被写死端口号的时候\n> 在配置类里面必须加 @LoadBalanced 才行\n> @LoadBalanced赋予RestTemplate负载均衡的能力:轮班值日\n```java\n    @Bean\n    @LoadBalanced\n    public RestTemplate getRestTemplate(){\n        return new RestTemplate();\n    }\n```\n>**RestTemplate返回对象选择**\n![RestTemplate返回](http://xtzl.wentexl.cn/restTemplate%E8%BF%94%E5%9B%9E%E5%AF%B9%E8%B1%A1.png)\n\n","categories":["SpringCloud"],"tags":[]},{"title":"CppFunctions","url":"/posts/12049/","content":"> 总结了C++常用函数\n\n<!-- more-->\n\n># C++ 函数总结\n\n>## 判断大小写\n```Cpp\n//用来判断一个字符是否为字母，如果是字符则返回非零，否则返回零。\n 1.isalpha()\n\n//用来判断一个字符是否为数字或者字母，也就是说判断一个字符是否属于a~z||A~Z||0~9。是返回非零，不是返回0。\n2.isalnum()\n\n//用来判断一个字符是否为小写字母，也就是是否属于a~z。是返回非零，不是返回0。\n3.islower()\n\n//用来判断一个字符是否为大写字母。是返回非零，不是返回0。\n4.isupper()\n\n//a为字符时，如果a是小写字母则将其转换为大写字母，否则不变。a为数字则将其按ASCLL码转换为对应字符。（其实即使a是字符，输入之后还是会将其转换为int类型）\n5. char c = toupper(a)\n\n//a为字符时，如果a是大写字母则将其转换为小写字母，否则不变。a为数字则将其按ASCLL码转换为对应字符。\n6.char c=tolower(a)\n\n//用来判断一个字符是否为数字，如果是数字则返回非零，否则返回零。\n7.isdigit()\n\n//将数字转换为字符串，这里注意如果是浮点型数转字符，会将精度范围内小数点后的数全部显示出来\n8.to_string()\n//数字转字符串：例如：\nfloat b = 2.;\ns = to_string(b);\ncout << s<<\" \"<<s.size();\n输出为：2.000000 8\n```\n\n# 字符串\n> ## 字符串的一些常用操作\n```Cpp\n  // count删了之后只替换一个字符\n  str.replace(index,count,instead) ->void\n  // 重载很多，startIndex默认为0，从字符串下标为0开始找\n  str.find(tagetStr,startIndex) -> first_index\n\n```\n> ## 字符串的复制和拼接\n  ```Cpp\n  strcpy函数进行字符串的复制\n  //将 first_name 复制给 full_name\n  strcpy(full_name, first_name);   \n\n------------------------------------------------------------------------\n\n  strcat()函数进行字符串的拼接\n  //将 last_name 拼接在 full_name 之后\n  strcat(full_name, last_name);   \n\n  // 字符与字符串之间可以用 + 来连接\n  string s; char ch;\n  s = s + ch;\n  ```\n\n## 字符串与整数的转换\n```Cpp\n// nums为字符串，stoi函数存在于头文件<string>中\nint k = stoi(nums);\n\n// num为整数，to_string函数也在string中\nstring s=to_string(num)\n```\n\n## 字符与整数的互换\n```Cpp\n// 字符转整数，直接强转\nchar c='8' ;\nint a ;\na =(int) (c - '0') ;\n\n// 整数转字符\nint b;\nchar c;\nc = b + '0'\n\n```\n\n# algorithm 函数中的reverse\n```Cpp\nreverse无返回值\n\nstr.begin()是指向str的第一个元素\nstr.end()是指向最后一个元素的后一个位置\n\n1.reverse(str.begin(),str.end()) 反转整个字符串\n \t \n2.reverse(vector.begin(),vector.end()) 反转向量\n \n3.reverse(a,a+strlen(a)) 反转数组\n```","categories":["C/CPP"],"tags":["functions"]},{"title":"CppHeadFiles","url":"/posts/56443/","content":"> 介绍与总结了C++的常用头文件\n\n<!-- more -->\n# C++头文件总结\n## 多函数头文件\n```markdown\n1.include<iostream> 输入输出流，得调用这个头文件才能使用cin,cout\n\n2.#include<iomanip> 可以调用一些函数，如fixed()<<setprecision()等\n\n3.#include<cmath> 用于调用一些数学函数\n\n4.#include<string> 调用这个头文件才可以调用字符串类型的变量\n\n5.#include<algorithm> 用于调用各种函数，如sort()\n\n```\n\n## 数据结构头文件\n```markdown\n#include<list> : 列表 \n\n#include<map> ： map集合\n\n#include<queue> : 队列\n\n#include<vector> : 不定长数组\n\n#include<stack> : 栈\n\n```\n\n","categories":["C/CPP"],"tags":[]},{"title":"CppLei","url":"/posts/20863/","content":">介绍了C++中常用的类型、关键字\n<!-- more -->\n\n# C++常用类型及其关键字整理\n>* 在C++中，指针和数组都是采用的引用传递，普通结构体，类，和其他基础类型都是采用的值传递\n>* 只有加了&才能让其他类型的数据使用引用传递\n>* 如果是指针传递，指针变量本身没加&就仍然是值传递，但是指针指向的地址上的改变是形参和实参一致的\n>## Bool 类型\n```cpp\nbool 变量是 值保存  真或者假这个值 （TRUE 或者 FAUSE），1表示真，0 表示假。在Ｃ语言中所有的非零值都为真所以给bool变量赋值，赋值为0则为0。赋值为非0 则为1。\n```\n>## Cout 关键字\n```cpp\nCout<<“sadasd”<< endl\n```\n>## Cin： 输入\n```cpp\nCin >> n;\n\nCin.getline(arrchar,20);\n\n// 直接使用string库函数中的getline可以得到一个字符串输入s\nvoid main() {s\n\tint A;\n\tint B;\n\tstring str;\n\n\t// 可接收一个包含空格的字符串，并赋值给str,最好将getline先在前面\n\tgetline(cin, str);\n\t// cin遇到空格和回车都会执行结束\n\tcin >> A;\n\tcin >> B;\n\n\tint C = A + B;\n\tcout << C;\n\tcout << str;\n}\n\n注：getline()函数中的arrchar是表示的字符数组，20表示的是最多输入19个字符，或者遇到回车结束\n```\n>## const 类型\n```Cpp\nconst int max =500;\nconst static int arr[] = {1,2,3,4}\t\n注：const关键字主要是用来声明常量的，定义之后不能改变了\n```\n>## string 关键字\n```Cpp\nstring s1=”asd”;\n\nstring s2=”asdasd”;\n\nString s= s1+s2; // 字符串的拼接\n\n类比java的input.nextline（获取输入的整个一行）\ngetline(cin,s);// 获取输入的整个一行并赋值给字符串变量s\n\ns.length() // 获取字符串的长度，会包括空格\n\nS.substr(start,counts); // 从下标为start开始取，一共取counts个字符\n\nS.substr(start); // 从下标为start开始取，取遍整个字符串后面的所有字符\n```\n>## 结构体\n```Cpp\n    struct stu{\n        string name;\n        int age;\n    }\n\n    void main(){\n        stu a[10];\n    }\n\n    注:结构体可以直接用名字进行引用\n```\n>## &的引用\n```markdown\n    可在自定义的函数的参数前加一个&，main函数直接传参数，便可在地址上修改参数的值\n```\n>## Pair类型\n```cpp\n    定义和初始化：\n    pair<int,int> data;\n\n    pair<int,int> p2(p1); // 用已经有的pair对象p1来初始化p2\n    \n    pair<int,double> p3(1,1.2); \n\n    pair<int,int> p4 ;  //没有写初始化值，自动初始化为(0,0)\n\n注：每个pair可以存储两个值，这两个值可以是不同的数据类型，存储的值可以是基本数据类型，也可以是自己定义的数据类型\n```\n\n>## 可变数组 Vectory\n```cpp\n   vector <int> arr; \n\tarr.resize(10); // 给该数组分配十个空间\n\tarr[0] = 1;\n\tarr.push_back(20); // 将20放到数组的最后\n\tvector <int> arr2 (10,3); // 给开辟10个空间，给每个空间都初始化为3\n\t// 使用arr[0]=1,这样的方式赋值的时候，一定是已经给数组分配过空间了的，否则编译失败\n\t// 但是使用pushback的话，可以先不分配空间\n\n\t// 迭代器自动遍历整个数组\n\t// arr.end()的位置是在数组的最后一个元素的下一个位置\n\tfor (auto p = arr2.begin(); p != arr2.end(); p++) {\n\t\tcout << *p << \" \";\n\t\tcout << *p << endl;\n\t}\n\n```\n\n>## set集合 ： 存储不含重复元素的集合\n```cpp\n\n    set<int> sarr; \n\tsarr.insert(1); // 给集合添加元素 1\n\tsarr.insert(2); // 给集合添加元素 2\n\tsarr.insert(3); // 给集合添加元素 3\n\n\tsarr.find(3); // 返回值是指针，在集合中寻找有没有3\n\n\tif (sarr.find(1)==sarr.end()) { // 指针指向最后一个元素的下一个位置\n\t\t// 查找失败，集合中没有\n\t\tcout << \"集合中没有这个元素\" << endl ;\n\t}\n\telse {\n\t\t// 找到了\n\t\tcout << *sarr.find(1) << endl;\n\t}\n\tsarr.erase(2);// 从集合中删除 2 这个元素\n\n\t// set集合的遍历\n\tfor (auto p = sarr.begin(); p != sarr.end(); p++) {\n\t\tcout << *p << endl;\n\t}\n\n```\n\n>## map集合 ： 存储键值对的集合\n```cpp\n    map<string,int> mymap;\n\t//添加元素\n\tmymap[\"xt\"] = 3; \n\tmymap[\"zl\"] = 4;\n\tmymap.insert({ \"xxx\",4 });\n\tfor (auto p = mymap.begin(); p != mymap.end(); p++) {\n\t\t// first 表示的是键，second 表示的是值\n\t\t// p代指map集合中的一个元素，实际上是个指针，指向结构体\n\t\tcout << p->first << \" : \" << p->second << endl;\n\t}\n\n```\n\n>## 栈 stack ：先入后出\n```cpp\n    stack<int> sta;\n\tsta.push(1);\n\tsta.push(2);\n\n\t// 打印栈顶元素\n\tcout << sta.top() << endl;\n\tsta.pop(); // 出栈且无返回值\n\tsta.size(); // 获取栈的长度\n```\n>## 队列：先入后出\n```cpp\n    queue<int>qu;\n\t// 入队\n\tqu.push(1);\n\tqu.push(2);\n\tqu.push(3);\n\t// 出队\n\tqu.pop();\n\t// 获取队首\n\tqu.front();\n\t// 获取队尾\n\tqu.back();\n\t// 长度\n\tqu.size();\n    // 入队            \n    pos.emplace(x);\n```\n>## bitset数组\n```cpp\n定义：类似一个字符数组，直接输出的话，是一个二进制数，如果按照数组输出的话，和直接输出相反\n\nbitset<5> b;\t\t // 表示5个二进制位，初始化为0 ： 00000\n\tbitset<5> b(3);\t    // 1是无符号数，输出b为 ：00011 , 此时括号里的数就是二进制数所表示的十进制数\n\tbitset<5> b(\"111\"); //111是字符串，表示在b的低3位是1 : 00111\n\tstring s; int pos, n;\n\tbitset<5>b(s, pos, n);// 类似于上面那个，但是这个是截取部分s然后作为参数，从下标为pos开始，读取n个字符\n    \n    // 下面的是返回为bool类型的函数 ： \n\tb.any(); // 是否有 1\n\tb.none(); //是否不存在1\n\tb.count();//1的个数\n\tb.size();//b中的元素个数\n\tb.test(3);//下标为3的元素是不是 1 \n    \n    // 操作函数\n\tb.flip(); // 所有位取反\n\tb.flip(i); // 第i为取反\n\tb.reset(); // 所有位归零\n\tb.reset(i);// 第i位归零\n\t\n\tunsigned long long1=b.to_ulong();// 转换成unsignedlong的类型\n```\n\n>## sort排序\n```cpp\n    vector<int> arr3(10); // 先分配十个空间\n\n\t// 默认为升序\n\tsort(arr3.begin(), arr3.end()); // 从begin到end这部分进行排序，左开右闭[ )，因为end所在的位置是没有数据的\n\t\n\tvector<int> arr4(10);\n\tsort(arr4.begin(), arr4.end(), cmp); // begin的是x，end的是y\n\n// cmp自定义排序\n// 返回1就顺序不变，如果返回0就会自动交换位置，实际上就是利用了快速排序的原理\n    bool cmp(int x, int y) { \n\t    return x > y; //降序\n    }\n\n// swap交换\n    swap(a[1],a[2]); // 表示把a数组中的下标为1和2的元素位置进行交换\n\n```\n","categories":["C/CPP"],"tags":["grammer","cpp"]},{"title":"Markdown 教程","url":"/posts/33206/","content":"\n> Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。\n> Markdown 语言在 2004 由约翰·格鲁伯（英语：John Gruber）创建。\n> Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。\n> Markdown 编写的文档后缀为 `.md`, `.markdown`。\n\n<!-- more -->\n末尾连续两次空格是换行\n\n# 标题\n👆 看起来就像上面这个。Markdown 标题有两种格式。\n\n## 使用 `=` 和 `-` 标记一级和二级标题\n`=` 和 `-` 标记语法格式如下：\n```markdown\n我展示的是一级标题\n=================\n\n我展示的是二级标题\n-----------------\n```\n\n## 使用 `#` 号标记\n使用 `#` 号可表示 1-6 级标题，一级标题对应一个 `#` 号，二级标题对应两个 `#` 号，以此类推。\n```markdown\n# 一级标题\n## 二级标题\n### 三级标题\n#### 四级标题\n##### 五级标题\n###### 六级标题\n```\n\n# 段落样式\nMarkdown 段落没有特殊的格式，直接编写文字就好，段落的换行是使用两个以上空格加上回车。\n当然也可以在段落后面使用一个空行来表示重新开始一个段落。\n\n## 字体\nMarkdown 可以使用以下几种字体：\n> *斜体文本*\n> **粗体文本**\n> ***粗斜体文本***\n```markdown\n*斜体文本*\n_斜体文本_\n\n**粗体文本**\n__粗体文本__\n\n***粗斜体文本***\n___粗斜体文本___\n```\n\n## 分隔线\n可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。\n也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：\n> - - -\n> 我\n> - - -\n> 裂\n> - - -\n> 开\n> - - -\n> 了\n>\n> - - -\n```markdown\n***\n* * *\n*****\n- - -\n----------\n```\n\n## 删除线\n如果段落上的文字要添加删除线，只需要在文字的两端加上两个波浪线 `~~` 即可，实例如下：\n> RUNOOB.COM\n> GOOGLE.COM\n> ~~BAIDU.COM~~\n```markdown\nRUNOOB.COM\nGOOGLE.COM\n~~BAIDU.COM~~\n```\n\n## 下划线\n下划线可以通过 HTML 的 `<u>` 标签来实现：\n> <u>带下划线文本</u>\n```html\n<u>带下划线文本</u>\n```\n\n## 脚注\n脚注是对文本的补充说明。Markdown 脚注的格式如下:\n```markdown\n[^要注明的文本]\n```\n以下实例演示了脚注的用法：\n> 阿米娅[^阿米娅]\n```markdown\n创建脚注格式类似这样 [^阿米娅]\n[^阿米娅]: 博士，您还有很多事情需要处理。现在还不能休息哦。\n```\n\n# Markdown 列表\nMarkdown 支持有序列表和无序列表。\n无序列表使用星号(`*`)、加号(`+`)或是减号(`-`)作为列表标记：\n> * 第一项\n> * 第二项\n> * 第三项\n```markdown\n* 第一项\n* 第二项\n* 第三项\n\n+ 第一项\n+ 第二项\n+ 第三项\n\n- 第一项\n- 第二项\n- 第三项\n```\n有序列表使用数字并加上 `.` 号来表示，如：\n> 1. 第一项\n> 2. 第二项\n> 3. 第三项\n```markdown\n1. 第一项\n2. 第二项\n3. 第三项\n```\n\n## 列表嵌套\n列表嵌套只需在子列表中的选项添加四个空格即可：\n1. 第一项：\n    - 第一项嵌套的第一个元素\n    - 第一项嵌套的第二个元素\n2. 第二项：\n    - 第二项嵌套的第一个元素\n    - 第二项嵌套的第二个元素\n\n\n```markdown\n1. 第一项：\n    - 第一项嵌套的第一个元素\n    - 第一项嵌套的第二个元素\n2. 第二项：\n    - 第二项嵌套的第一个元素\n    - 第二项嵌套的第二个元素\n```\n\n# Markdown 区块\nMarkdown 区块引用是在段落开头使用 `>` 符号 ，然后后面紧跟一个空格符号：\n> 这是一个区块\n```markdown\n> 这是一个区块\n```\n另外区块是可以嵌套的，一个 `>` 符号是最外层，两个 `>` 符号是第一层嵌套，以此类推：\n> 最外层\n> > 第一层嵌套\n> >\n> > > 第二层嵌套\n```markdown\n> 最外层\n> > 第一层嵌套\n> > > 第二层嵌套\n```\n\n## 区块中使用列表\n区块中使用列表实例如下：\n> 区块中使用列表\n> 1. 第一项\n> 2. 第二项\n> + 第一项\n> + 第二项\n> + 第三项\n```markdown\n> 区块中使用列表\n> 1. 第一项\n> 2. 第二项\n> + 第一项\n> + 第二项\n> + 第三项\n```\n\n## 列表中使用区块\n如果要在列表项目内放进区块，那么就需要在 `>` 前添加四个空格的缩进。\n区块中使用列表实例如下：\n* 第一项\n  > 菜鸟教程\n  > 学的不仅是技术更是梦想\n* 第二项\n```markdown\n* 第一项\n    > 菜鸟教程\n    > 学的不仅是技术更是梦想\n* 第二项\n```\n\n# Markdown 代码\n如果是段落上的一个函数或片段的代码可以用反引号把它包起来（\\`），例如：\n`printf()` 函数\n```markdown\n`printf()` 函数\n```\n## 代码区块\n代码区块使用 4 个空格或者一个制表符（Tab 键）。\n也可以用 ``` 包裹一段代码，并指定一种语言（也可以不指定）：\n实例如下：\n```javascript\n$(document).ready(function () {\n    alert('RUNOOB');\n});\n```\n\n# Markdown 链接\n链接使用方法如下：\n> [链接名称](#链接地址)\n> 或者直接使用链接地址\n> <https://github.com/Yue-plus>\n```markdown\n[链接名称](链接地址)\n<https://github.com/Yue-plus>\n```\n\n## 高级链接\n可以通过变量来设置一个链接，变量赋值在文档末尾进行：\n> 这个链接用 `1` 作为网址变量 [Google][1]\n> 这个链接用 `mysite` 作为网址变量 [Yue_plus][mysite]\n```markdown\n这个链接用 1 作为网址变量 [Google][1]\n这个链接用 mysite 作为网址变量 [Yue_plus][mysite]\n然后在文档的结尾为变量赋值（网址）\n\n  [1]: http://www.google.com/\n  [mysite]: https://github.com/Yue-plus\n```\n\n# Markdown 图片\nMarkdown 图片语法格式如下：\n```markdown\n![alt 属性文本](图片地址)\n![alt 属性文本](图片地址 \"可选标题\")\n```\n开头一个感叹号 !\n接着一个方括号，里面放上图片的替代文字\n接着一个英文括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 'title' 属性的文字。\n> ![罗德岛集结](https://ak.hypergryph.com/upload/images/20190228/118078295785f64dac736c6ade50bb76.jpg \"罗德岛集结\")\n```markdown\n![罗德岛集结](https://ak.hypergryph.com/upload/images/20190228/118078295785f64dac736c6ade50bb76.jpg \"罗德岛集结\")\n```\n当然，你也可以像网址那样对图片网址使用变量:\n```markdown\n这个链接用 `2` 作为网址变量 [凯尔希][2].\n然后在文档的结尾为变量赋值（网址）\n\n[2]: https://ak.hypergryph.com/upload/images/20190228/143666074a406ecaa6cd4271dc7c5127.jpg\n```\nMarkdown 还没有办法指定图片的高度与宽度，如果需要的话，也可以使用普通的 `<img>` 标签。\n> <img src=\"https://ak.hypergryph.com/assets/index/images/ak/common/story/item_infected.png\" width=\"200px\">\n```html\n<img src=\"https://ak.hypergryph.com/assets/index/images/ak/common/story/item_infected.png\" width=\"200px\">\n```\n\n# Markdown 表格\nMarkdown 制作表格使用 `|` 来分隔不同的单元格，使用 `-` 来分隔表头和其他行。\n语法格式如下：\n\n| 表头   | 表头   |\n| ------ | ------ |\n| 单元格 | 单元格 |\n| 单元格 | 单元格 |\n\n```markdown\n|  表头   | 表头  |\n|  ----  | ----  |\n| 单元格  | 单元格 |\n| 单元格  | 单元格 |\n```\n\n可以设置表格的对齐方式：\n\n`-:` 设置内容和标题栏居右对齐。\n`:-` 设置内容和标题栏居左对齐。\n`:-:` 设置内容和标题栏居中对齐。\n\n| 左对齐 | 右对齐 | 居中对齐 |\n| :-----| ----: | :----: |\n| 单元格 | 单元格 | 单元格 |\n| 单元格 | 单元格 | 单元格 |\n\n# Markdown 高级技巧\n##支持的 HTML 元素\n不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。\n目前支持的 HTML 元素有：`<kbd>` `<b>` `<i>` `<em>` `<sup>` `<sub>` `<br>`等，如：\n> 使用 <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Del</kbd> 重启电脑\n```markdown\n使用 <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Del</kbd> 重启电脑\n```\n\n## 转义\nMarkdown 使用了很多特殊符号来表示特定的意义，如果需要显示特定的符号则需要使用转义字符，Markdown 使用反斜杠转义特殊字符：\n> \\*\\* 正常显示星号 \\*\\*\n```markdown\n**文本加粗** \n\\*\\* 正常显示星号 \\*\\*\n```\nMarkdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号：\n```markdown\n\\   反斜线\n`   反引号\n*   星号\n_   下划线\n{}  花括号\n[]  方括号\n()  小括号\n#   井字号\n+   加号\n-   减号\n.   英文句点\n!   感叹号\n```\n\n## 数学公式\n当需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。如：\n\n> 参考 [使用 `hexo-filter-mathjax` 过滤器来显示数学公式](https://github.com/Yue-plus/hexo-theme-arknights#数学公式)\n\n> 可以在行内包含数学公式： $i\\hbar\\frac{\\partial}{\\partial t}\\psi=-\\frac{\\hbar^2}{2m}\\nabla^2\\psi+V\\psi$ 注意单 `$` 内部不能有空格！\n> $$\n> \\begin{eqnarray\\*}\n> \\nabla\\cdot\\vec{E}&=&\\frac{\\rho}{\\epsilon_0}\\\\\\\\\n> \\nabla\\cdot\\vec{B}&=&0\\\\\\\\\n> \\nabla\\times\\vec{E}&=&-\\frac{\\partial B}{\\partial t}\\\\\\\\\n> \\nabla\\times\\vec{B}&=&\\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t}\\right)\\\\\\\\\n> \\end{eqnarray\\*}\n> $$\n\n```markdown\n可以在行内包含数学公式： $i\\hbar\\frac{\\partial}{\\partial t}\\psi=-\\frac{\\hbar^2}{2m}\\nabla^2\\psi+V\\psi$ 注意单 `$` 内部不能有空格！\n$$\n\\begin{eqnarray\\*}\n\\nabla\\cdot\\vec{E}&=&\\frac{\\rho}{\\epsilon_0}\\\\\\\\\n\\nabla\\cdot\\vec{B}&=&0\\\\\\\\\n\\nabla\\times\\vec{E}&=&-\\frac{\\partial B}{\\partial t}\\\\\\\\\n\\nabla\\times\\vec{B}&=&\\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t}\\right)\\\\\\\\\n\\end{eqnarray\\*}\n$$\n```\n\n[^阿米娅]: 博士，您还有很多事情需要处理。现在还不能休息哦。\n\n[1]: http://www.google.com/\n[mysite]: https://github.com/Yue-plus","categories":[],"tags":["Markdown"]}]